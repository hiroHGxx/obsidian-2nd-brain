---
title: "【Google Opal完全攻略】コンテンツ全自動化ワークフロー構築講座┃完全ロードマップ | Fujin"
source: "https://brain-market.com/u/fujin_metaverse/a/b1kjNzMjMgoTZsNWa0JXY"
author:
  - "[[Brain]]"
published:
created: 2026-02-07
description: "Brain(ブレイン)は、自分が持っている知識やノウハウを有料販売し、収益化することができるプラットフォームです。レビュー機能により、良いコンテンツが可視化されるため、学ぶ側は質の高い学びを得ることができる仕組みが整っています。"
tags:
  - "clippings"
---
【Google Opal完全攻略】コンテンツ全自動化ワークフロー構築講座┃完全ロードマップ

Rating 0 of 5

Rating 0.5 of 5Rating 1 of 5

Rating 1.5 of 5Rating 2 of 5

Rating 2.5 of 5Rating 3 of 5

Rating 3.5 of 5Rating 4 of 5

Rating 4.5 of 5Rating 5 of 5

4.6 (19件)

この記事を書いた人

[![](https://image.brain-market.com/store/2c3ee6b2d75f14d0123e3e9e6b6995d1.jpeg)](https://brain-market.com/u/fujin_metaverse)[Fujin](https://brain-market.com/u/fujin_metaverse)---

目次

- 	- [1\. 衝撃の事実をお伝えします](https://brain-market.com/u/fujin_metaverse/a/#toc_1_1)
- [2\. なぜ、あなたのAI作業は自動化できていないのか？](https://brain-market.com/u/fujin_metaverse/a/#toc_2_0)
	- [2-1. Google Opalがもたらす「並列処理」という革命](https://brain-market.com/u/fujin_metaverse/a/#toc_2_1)
	- [2-2. なぜ「n8n」ではなく「Opal」一択なのか？](https://brain-market.com/u/fujin_metaverse/a/#toc_2_2)
	- [2-3. 本講座で手に入る「最強のスキル」](https://brain-market.com/u/fujin_metaverse/a/#toc_2_3)
	- [2-4. 講座のコンテンツ内容](https://brain-market.com/u/fujin_metaverse/a/#toc_2_4)
	- [2-5. 【購入者限定】総額15万円相当の「豪華10大特典」🎁](https://brain-market.com/u/fujin_metaverse/a/#toc_2_5)
	- [2-6. 価格について](https://brain-market.com/u/fujin_metaverse/a/#toc_2_6)
	- [2-7. さあ、準備はいいですか？](https://brain-market.com/u/fujin_metaverse/a/#toc_2_7)
- [3\. 特典を一気に受け取れる購入者通信](https://brain-market.com/u/fujin_metaverse/a/#toc_3_0)
- [4\. 【環境構築】Google最強AIを最安で使い倒す裏技のような方法](https://brain-market.com/u/fujin_metaverse/a/#toc_4_0)
	- [4-1. 【真実】Google One（個人版）vs Google Workspace（事業用）](https://brain-market.com/u/fujin_metaverse/a/#toc_4_1)
	- [4-2. 「Google AI Premium」の罠](https://brain-market.com/u/fujin_metaverse/a/#toc_4_2)
	- [4-3. 月額1,600円でプロ環境を手に入れる「裏技」](https://brain-market.com/u/fujin_metaverse/a/#toc_4_3)
	- [4-4. 今回のOpal講座には必須ではないですが...](https://brain-market.com/u/fujin_metaverse/a/#toc_4_4)
	- [4-5. 注意点もあります](https://brain-market.com/u/fujin_metaverse/a/#toc_4_5)
	- [4-6. Xserverドメイン × Workspace 開通ロードマップ](https://brain-market.com/u/fujin_metaverse/a/#toc_4_6)
	- [4-7. 【STEP 1】Xserverでの「ドメイン取得」の最適解](https://brain-market.com/u/fujin_metaverse/a/#toc_4_7)
	- [4-8. 【STEP 2】Google Workspace「Business Starter」の申し込み手順](https://brain-market.com/u/fujin_metaverse/a/#toc_4_8)
	- [4-9. 【STEP 3】最難関「DNSレコード設定（TXTレコード）」の突破法](https://brain-market.com/u/fujin_metaverse/a/#toc_4_9)
	- [4-10. 【STEP 4】Gmail開通と初期セキュリティ設定](https://brain-market.com/u/fujin_metaverse/a/#toc_4_10)
	- [4-11. Google Workspaceで早期アクセス機能をオンにする](https://brain-market.com/u/fujin_metaverse/a/#toc_4_11)
	- [4-12. Opalへのログイン](https://brain-market.com/u/fujin_metaverse/a/#toc_4_12)
- [5\. 【AI時代の思考法】業務を「ワークフロー」にするために押さえておくべきこと](https://brain-market.com/u/fujin_metaverse/a/#toc_5_0)
	- [5-1. なぜ、あなたのAIコンテンツは「無価値」になるのか？](https://brain-market.com/u/fujin_metaverse/a/#toc_5_1)
	- [5-2. 何を自動化すべきなのかを明確にしよう](https://brain-market.com/u/fujin_metaverse/a/#toc_5_2)
	- [5-3. 【特典】業務仕分けスプレッドシート](https://brain-market.com/u/fujin_metaverse/a/#toc_5_3)
	- [5-4. 【特典解説】「業務仕分けスプレッドシート」の使い方](https://brain-market.com/u/fujin_metaverse/a/#toc_5_4)
	- [5-5. 「ナレッジ資本」の重要性](https://brain-market.com/u/fujin_metaverse/a/#toc_5_5)
	- [5-6. 【特典】Opalワークフロー設計GPTの使い方](https://brain-market.com/u/fujin_metaverse/a/#toc_5_6)
	- [5-7. Opalが得意なのは「並列処理」である](https://brain-market.com/u/fujin_metaverse/a/#toc_5_7)
	- [5-8. AI自動化のためのマインドセット](https://brain-market.com/u/fujin_metaverse/a/#toc_5_8)
- [6\. 【基本操作】Opalで自動化を始めよう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_0)
	- [6-1. Opalのやさしい始め方](https://brain-market.com/u/fujin_metaverse/a/#toc_6_1)
	- [6-2. Opalにはテンプレートが用意されている](https://brain-market.com/u/fujin_metaverse/a/#toc_6_2)
	- [6-3. AIにワークフローを作ってもらおう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_3)
	- [6-4. 「ノード」を理解しよう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_4)
	- [6-5. ノードを繫げよう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_5)
	- [6-6. EditorモードとAppモード](https://brain-market.com/u/fujin_metaverse/a/#toc_6_6)
	- [6-7. 【実践】ワークフローを起動してみよう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_7)
	- [6-8. 実際に動いているワークフローを見てみよう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_8)
	- [6-9. ★超重要テクニック「再開」の方法](https://brain-market.com/u/fujin_metaverse/a/#toc_6_9)
	- [6-10. 生成された記事を見てみよう](https://brain-market.com/u/fujin_metaverse/a/#toc_6_10)
	- [6-11. 画面操作の仕方](https://brain-market.com/u/fujin_metaverse/a/#toc_6_11)
- [7\. 【基礎知識】ノードの役割を理解しよう](https://brain-market.com/u/fujin_metaverse/a/#toc_7_0)
	- [7-1. インプットノードについて](https://brain-market.com/u/fujin_metaverse/a/#toc_7_1)
	- [7-2. ジェネレートノードの全種類 徹底解説](https://brain-market.com/u/fujin_metaverse/a/#toc_7_2)
	- [7-3. 【特典】プレミアムリスナー限定のFujin式スライド生成Gemを配布します](https://brain-market.com/u/fujin_metaverse/a/#toc_7_3)
	- [7-4. アウトプットノードの選び方と落とし穴](https://brain-market.com/u/fujin_metaverse/a/#toc_7_4)
	- [7-5. 【コラム】3分でわかる！「RAG（ラグ）」ってよく聞くけど何？](https://brain-market.com/u/fujin_metaverse/a/#toc_7_5)
	- [7-6. 【まとめ】ノードを制する者は、AI時代を制す](https://brain-market.com/u/fujin_metaverse/a/#toc_7_6)
- [8\. 【応用知識】ノードの詳細設定を使いこなそう](https://brain-market.com/u/fujin_metaverse/a/#toc_8_0)
	- [8-1. 「Advanced Settings（詳細設定）」とは？](https://brain-market.com/u/fujin_metaverse/a/#toc_8_1)
	- [8-2. インプットノードで入れることができるデータ](https://brain-market.com/u/fujin_metaverse/a/#toc_8_2)
	- [8-3. インプットにはYouTube動画も入れられる](https://brain-market.com/u/fujin_metaverse/a/#toc_8_3)
	- [8-4. ジェネレートノードの詳細設定](https://brain-market.com/u/fujin_metaverse/a/#toc_8_4)
	- [8-5. GeminiノードのSystem Instruction](https://brain-market.com/u/fujin_metaverse/a/#toc_8_5)
	- [8-6. GeminiノードのReview with User](https://brain-market.com/u/fujin_metaverse/a/#toc_8_6)
	- [8-7. Plan & Executeノードの3つのモード](https://brain-market.com/u/fujin_metaverse/a/#toc_8_7)
	- [8-8. Deep Researchノードの要約モード](https://brain-market.com/u/fujin_metaverse/a/#toc_8_8)
	- [8-9. 画像と動画生成ノードの縦横比設定方法](https://brain-market.com/u/fujin_metaverse/a/#toc_8_9)
	- [8-10. Output Nodesの詳細設定](https://brain-market.com/u/fujin_metaverse/a/#toc_8_10)
- [9\. 【実践】音声データからコンテンツを無限に生み出す、Fujin式最強AIワークフロー公開します](https://brain-market.com/u/fujin_metaverse/a/#toc_9_0)
	- [9-1. テンプレートの使い方](https://brain-market.com/u/fujin_metaverse/a/#toc_9_1)
	- [9-2. 毎日の発信を支える「全自動コンテンツ生成ワークフロー」の全体像](https://brain-market.com/u/fujin_metaverse/a/#toc_9_2)
	- [9-3. インプットと文字起こし](https://brain-market.com/u/fujin_metaverse/a/#toc_9_3)
	- [9-4. ブログ記事生成 AIにナレッジを渡す方法](https://brain-market.com/u/fujin_metaverse/a/#toc_9_4)
	- [9-5. 【超重要】太字とカギカッコの「バグ」回避テクニック](https://brain-market.com/u/fujin_metaverse/a/#toc_9_5)
	- [9-6. タイトル生成とサムネイル 画像比率の指定方法](https://brain-market.com/u/fujin_metaverse/a/#toc_9_6)
	- [9-7. X（旧Twitter）ポスト生成 140字の制限とナレッジの重要性](https://brain-market.com/u/fujin_metaverse/a/#toc_9_7)
	- [9-8. 字幕（SRT）ファイル生成 動画制作を超時短する](https://brain-market.com/u/fujin_metaverse/a/#toc_9_8)
	- [9-9. 並列処理の強力さ](https://brain-market.com/u/fujin_metaverse/a/#toc_9_9)
	- [9-10. 出力結果のデザインをよくする方法](https://brain-market.com/u/fujin_metaverse/a/#toc_9_10)
	- [9-11. ワークフローは人によって全然違う](https://brain-market.com/u/fujin_metaverse/a/#toc_9_11)
- [10\. 【実践】YouTube字幕自動化！高精度SRTファイル自動生成ワークフロー](https://brain-market.com/u/fujin_metaverse/a/#toc_10_0)
	- [10-1. 「最強字幕生成」ロジック](https://brain-market.com/u/fujin_metaverse/a/#toc_10_1)
	- [10-2. なぜ公式サイトのGeminiではなく、Opalなのか？](https://brain-market.com/u/fujin_metaverse/a/#toc_10_2)
	- [10-3. SRTファイル生成のデバッグ方法](https://brain-market.com/u/fujin_metaverse/a/#toc_10_3)
	- [10-4. SRTファイル化からPremiere Proへの連携](https://brain-market.com/u/fujin_metaverse/a/#toc_10_4)
	- [10-5. 動画制作の未来は「半自動化」にある](https://brain-market.com/u/fujin_metaverse/a/#toc_10_5)
- [11\. 【実践】ショート動画台本作成を完全自動化！ゼロからのワークフロー構築術](https://brain-market.com/u/fujin_metaverse/a/#toc_11_0)
	- [11-1. まずはテスト環境を作ろう](https://brain-market.com/u/fujin_metaverse/a/#toc_11_1)
	- [11-2. ノードのプロンプトの書き方](https://brain-market.com/u/fujin_metaverse/a/#toc_11_2)
	- [11-3. データの「整形」がAIの理解度を左右する](https://brain-market.com/u/fujin_metaverse/a/#toc_11_3)
	- [11-4. ジャンルが違っても使えるのか？](https://brain-market.com/u/fujin_metaverse/a/#toc_11_4)
	- [11-5. 「メタ・プロンプト戦略」](https://brain-market.com/u/fujin_metaverse/a/#toc_11_5)
	- [11-6. 生成されたシステムプロンプトの確認](https://brain-market.com/u/fujin_metaverse/a/#toc_11_6)
	- [11-7. Opalへの実装をしてみよう](https://brain-market.com/u/fujin_metaverse/a/#toc_11_7)
	- [11-8. 【重要】エラーの原因を特定しよう](https://brain-market.com/u/fujin_metaverse/a/#toc_11_8)
	- [11-9. PDF読み込みの「罠」](https://brain-market.com/u/fujin_metaverse/a/#toc_11_9)
	- [11-10. ワークフロー、ついに完成。](https://brain-market.com/u/fujin_metaverse/a/#toc_11_10)
	- [11-11. 「@」をうまく活用しよう！](https://brain-market.com/u/fujin_metaverse/a/#toc_11_11)
	- [11-12. 完成したノードをメインワークフローに組み込んでみる](https://brain-market.com/u/fujin_metaverse/a/#toc_11_12)
	- [11-13. エラーの対処法とブラッシュアップの方法](https://brain-market.com/u/fujin_metaverse/a/#toc_11_13)
- [12\. 【最新版】Gemini 3 ProとNano Banana Proに対応したFujin式最強AIワークフローがやばすぎる](https://brain-market.com/u/fujin_metaverse/a/#toc_12_0)
	- [12-1. ナレッジのアップデートもしてます](https://brain-market.com/u/fujin_metaverse/a/#toc_12_1)
	- [12-2. クリック率を支配する「タイトル生成」のプロンプト革命](https://brain-market.com/u/fujin_metaverse/a/#toc_12_2)
	- [12-3. サムネイル生成のコツ](https://brain-market.com/u/fujin_metaverse/a/#toc_12_3)
	- [12-4. 「プロのサムネイルデザイナー」につくってもらう](https://brain-market.com/u/fujin_metaverse/a/#toc_12_4)
	- [12-5. 「Nano Banana Pro」による画像生成フローの全貌と運用ロジック](https://brain-market.com/u/fujin_metaverse/a/#toc_12_5)
	- [12-6. 「3枚同時生成」システムでガチャを自動化する](https://brain-market.com/u/fujin_metaverse/a/#toc_12_6)
	- [12-7. ショート動画のジレンマ。映像どうする？](https://brain-market.com/u/fujin_metaverse/a/#toc_12_7)
	- [12-8. VEO 3などの動画生成AIの可能性とコストの壁](https://brain-market.com/u/fujin_metaverse/a/#toc_12_8)
	- [12-9. 入力素材は「独り言」で十分](https://brain-market.com/u/fujin_metaverse/a/#toc_12_9)
	- [12-10. X、Threads、そして図解生成もできるようにしたい](https://brain-market.com/u/fujin_metaverse/a/#toc_12_10)
	- [12-11. 自動化でクリエイティブを加速せよ](https://brain-market.com/u/fujin_metaverse/a/#toc_12_11)
- [13\. 【革命】Opalワークフローを超簡単に組む方法](https://brain-market.com/u/fujin_metaverse/a/#toc_13_0)
	- [13-1. Opalのワークフロー設計、まだ手動でやってるの？](https://brain-market.com/u/fujin_metaverse/a/#toc_13_1)
	- [13-2. 【特典】「Fujin式Opalワークフロー設計Gem」とは？](https://brain-market.com/u/fujin_metaverse/a/#toc_13_2)
	- [13-3. 【衝撃】Geminiの中に「Opal」がやってきた！](https://brain-market.com/u/fujin_metaverse/a/#toc_13_3)
	- [13-4. 日本語化と微調整のテクニック](https://brain-market.com/u/fujin_metaverse/a/#toc_13_4)
	- [13-5. いざ実践！AIエージェントを動かしてみる](https://brain-market.com/u/fujin_metaverse/a/#toc_13_5)
	- [13-6. 驚愕のアウトプット品質](https://brain-market.com/u/fujin_metaverse/a/#toc_13_6)
	- [13-7. まとめ：今すぐ「作る側」に回ろう](https://brain-market.com/u/fujin_metaverse/a/#toc_13_7)
- [14\. 【最新】Nano Banana Proでサムネイル一撃3枚生成ワークフロー](https://brain-market.com/u/fujin_metaverse/a/#toc_14_0)
	- [14-1. Nano Banana Pro（Gemini 3 Pro Image）の実力](https://brain-market.com/u/fujin_metaverse/a/#toc_14_1)
	- [14-2. 【検証】最新ワークフローでサムネイル自動生成に挑む](https://brain-market.com/u/fujin_metaverse/a/#toc_14_2)
	- [14-3. ステップ①ワークフローの構築と調整](https://brain-market.com/u/fujin_metaverse/a/#toc_14_3)
	- [14-4. ステップ②タイトル入力から生成スタート](https://brain-market.com/u/fujin_metaverse/a/#toc_14_4)
	- [14-5. ステップ③衝撃の結果確認](https://brain-market.com/u/fujin_metaverse/a/#toc_14_5)
	- [14-6. YouTube運用を変える「サムネ3枚同時生成」の威力](https://brain-market.com/u/fujin_metaverse/a/#toc_14_6)
	- [14-7. ワークフロー自体をコンテンツ化・資産化する](https://brain-market.com/u/fujin_metaverse/a/#toc_14_7)
- [15\. 【並列処理の限界】15体のAIエージェントによる「超並列ブレインストーミング」システム](https://brain-market.com/u/fujin_metaverse/a/#toc_15_0)
	- [15-1. 限界突破のワークフロー](https://brain-market.com/u/fujin_metaverse/a/#toc_15_1)
	- [15-2. 検証してみる](https://brain-market.com/u/fujin_metaverse/a/#toc_15_2)
	- [15-3. AIエージェントは「チーム」でこそ輝く](https://brain-market.com/u/fujin_metaverse/a/#toc_15_3)
	- [15-4. Opal並列処理の最大値](https://brain-market.com/u/fujin_metaverse/a/#toc_15_4)
- [16\. 【応用】悪魔的成約率「ニューロセールスレター」生成システム](https://brain-market.com/u/fujin_metaverse/a/#toc_16_0)
- [17\. 「Opal一強時代」の到来](https://brain-market.com/u/fujin_metaverse/a/#toc_17_0)
- [18\. 今後追加予定のコンテンツ](https://brain-market.com/u/fujin_metaverse/a/#toc_18_0)
- [19\. おわりに](https://brain-market.com/u/fujin_metaverse/a/#toc_19_0)

冒頭から手短に実績だけお伝えさせてください。

✅ **公開からたった1週間で売上1000万円突破**

![](https://image.brain-market.com/store/e809a1d9202985b8080624e3422cf173.png)

✅ **Brainランキング6日連続不動の1位（再び1位獲得）**

![](https://image.brain-market.com/store/e945c1b597b788cf7814d7ac6956ef29.png)

✅ **イケハヤ氏、迫氏ら業界著名人も「公認」のクオリティ**

![](https://image.brain-market.com/store/ab381c664473902b6b05ca033f366c71.png)

![](https://image.brain-market.com/store/e6c32840b01a5493272f9c17c6ba6328.png)

今、この瞬間も購入者は増え続け、XのタイムラインはOpalの話題で埋め尽くされています。

![](https://image.brain-market.com/store/bfc6ffabdec56c1dbd4f957149ea6c45.png)

![](https://image.brain-market.com/store/8fbcf09d1e1b9118039e9c76b766849c.png)

### 1\. 衝撃の事実をお伝えします

どうも、Fujinです。

単刀直入に言います。

**もしあなたが、まだChatGPTやGeminiのチャット画面にポチポチとプロンプトを打ち込んでいるなら、あなたの時間は「搾取」され続けています。**

![](https://image.brain-market.com/store/ef0ae92204e78cd4bc7a852374dda106.png)

2026年、AIのフェーズは完全に変わりました。

「AIと対話する時代」は終わり、「AIをワークフロー（仕組み）として動かす時代」が到来したのです。

その中心にあるのが、今回ご紹介するGoogleのもっとも過小評価されているといっても過言ではないワークフローツール「Opal（オパール）」です。

この教材は、単なるツールの教科書ではありません。

あなたの労働時間を1/10にし、生産性を100倍にするためのAI時代の「産業革命」への招待状です。

もしあなたが

> **「もっと楽をして成果を出したい」**
> 
> **「コピペ作業から永遠に解放されたい」**
> 
> **「寝ている間にコンテンツを量産する仕組みが欲しい」**

そう本気で思っているなら、最後まで読み進めてください。

あなたの人生を覆す、衝撃の事実をお伝えします。

## 2\. なぜ、あなたのAI作業は自動化できていないのか？

あなたは今、こんな悩みを抱えていませんか？

- 毎回同じようなプロンプトを入力するのが面倒くさい。
- AIの回答を待っている間、画面の前でボケーっとしている。
- 「要約して」「翻訳して」と、何度も指示を出し直している。
- 「自動化」と言いつつ、結局自分が手を動かさないと何も進まない。

なぜ、こんなことが起きるのか。

それは、従来のAIが「直列処理（1対1）」しかできないからです。

これまでのチャット型AIは

**あなたが指示を出す（入力）→ AIが答える（出力）**

というキャッチボールでしかありませんでした。 あなたがボールを投げなければ、AIは止まる。つまり、**あなたの時間がAIの操作に奪われ続けている**のです。

これではせっかくのAI自動化時代、もったいなさすぎる。

### 2-1. Google Opalがもたらす「並列処理」という革命

![](https://image.brain-market.com/store/7b13dd7a2e1178c147bd12c4d9e8adc1.png)

そこで登場するのが、Googleがリリースしている次世代ツール「Opal」です。 Opalの真髄は、**「並列処理（Parallel Processing）」**にあります。

イメージしてください。

あなたがたった一つ、「音声ファイル」をポイッとOpalに投げ込む。やることはそれだけ。あとはコーヒーを淹れて待つだけです。

その裏側で、以下の作業が**「同時」に完了します。**

1. **【記事執筆】** 音声を文字起こしし、SEOを意識したブログ記事を作成。
2. **【タイトル考案】** 内容を分析し、クリックしたくなるタイトル案を10個作成。
3. **【画像生成】** 記事の内容にマッチしたサムネイル画像を3パターン生成。
4. **【SNS投稿】** X（旧Twitter）用の、拡散されやすい投稿文を作成。
5. **【動画台本】** ショート動画用に要約した台本を作成。
6. **【YouTubeフルテロップ】**YouTubeの長尺動画用のフルテロップ作成。

これら全てが、**たった1回のクリック**で完結します。

これが、僕が提唱する**「ワンソース・マルチユース」革命**です。 人間が数日かけて行っていたメディアミックス作業が、数分で終わる。

「0→1（創造）」は人間がやる。

「1→100（横展開）」はOpalがやる。

このAI自動化システムを築けた人だけが、2026年の市場を制圧できます。

### 2-2. なぜ「n8n」ではなく「Opal」一択なのか？

![](https://image.brain-market.com/store/d8690d5a104fe26006409f2ac98070f2.png)

「自動化ならn8nやMakeがあるじゃないか」

そう思ったあなたは鋭い。確かにn8nは素晴らしいツールです。

しかし、n8nには**「高すぎる学習コスト（難易度）」と「従量課金の恐怖（コスト）」**という壁があります。 API料金を気にしながらビクビクして自動化なんて、本末転倒ですよね？

だからこそ、まずは**Google Opal一択**なんです。

![](https://image.brain-market.com/store/6c0aef6013c81da8756542e5e297de91.png)

1. **圧倒的なコストパフォーマンス  
	**Googleのエコシステム内で動くため、現時点では基本的に**無料**で利用可能。これが破壊的すぎるわけです。
2. **Googleツールとの最強連携  
	**ドライブ、ドキュメント、YouTube、検索。Googleのエコシステムとシームレスに連携します。
3. **最新モデル使い放題  
	**Gemini 3 Proや動画生成AI「Veo」、画像生成「Nano Banana」など、Googleの最新兵器を最速で実装できます。

「無料」かつ「最強」

これを使わない手はありません

### 2-3. 本講座で手に入る「最強のスキル」

この講座は、Opalの使い方を教えるだけのものではありません。

**あなたが「AI組織」を動かせるようになるための、全ノウハウを詰め込みました。**

文字数にして**9万文字超**。動画講義**3時間超**。

僕が寝る間を惜しんで検証し、エラーと戦い続けて導き出した、どこにも書かれていない、AIすら答えてくれない独自ノウハウをすべて公開します。

### 2-4. 講座のコンテンツ内容

![](https://image.brain-market.com/store/8f1a41500c694b1666070082847f7d43.png)

- **【環境構築】** 月額2,900円を払うな！Google最強AI環境を**「月額1,600円」**で構築する裏技（これだけで年間1.5万円が節約できます）
- **【完全攻略】** 英語だらけのOpalを、小学生でもわかるようにステップバイステップで解説
- **【プロンプト革命】** AIに「自分らしさ」を憑依させる「ナレッジ資本」の概念と、具体的なプロンプト設計術
- **【回避テクニック】** Opal特有のエラーやバグを回避し、安定稼働させるためのデバッグ法
- **【Gemini 3 Pro × Nano Banana Pro】** 最新モデルをフル活用した、テキスト×画像の最新版並列生成システム構築

そして、何より強力なのが**「特典」**です。

### 2-5. 【購入者限定】総額15万円相当の「豪華10大特典」🎁

![](https://image.brain-market.com/store/c9060bf17b29bee6030788302286adac.png)

正直に言います。

この特典だけで、講座代金の元は一瞬で取れてしまうレベルに仕上げました。 僕が開発し、実際に裏側で稼働させているワークフローまでそのままあなたにお渡しします。

ゼロから頭を悩ませて構築する必要はありません。 あなたは「コピペ」するだけで、今日から最強のAIシステムを手に入れることができます。

**==【特典1】==**

**==最新版！音声データから全コンテンツ一撃生成テンプレート==**

![](https://image.brain-market.com/store/40371ee71fd5f8cf82ecaae0b4bdefb9.png)

本講座の核となる、僕の最高傑作です。ポッドキャストなどの音声データを投げるだけで、ブログ記事、SNS投稿、ショート動画台本などを**並列処理で一気に生成**します。旧版からさらにブラッシュアップされた最新モデル版をお渡しします。

**==【特典2】==**

**==Plan & Execute（自律思考型）リサーチテンプレート==**

![](https://image.brain-market.com/store/65d2dedb10387d6f4eb3c64682f877d4.png)

「〜について調べて」と投げるだけで、AIが自ら計画を立て、Web検索と実行を繰り返して**2万文字級のレポート**を作成するリサーチ特化型システム。市場調査や競合分析が全自動で完了します。

**==【特典3】==**

**==YouTubeリンクから台本作成テンプレート==**

![](https://image.brain-market.com/store/53c16548c98fc4b111d9431ceb2098f7.png)

YouTubeの動画URLを貼るだけで、その内容を分析・要約し、別のコンテンツや台本へと再構成する時短テンプレート。インプットとアウトプットのサイクルを爆速化させます。

**==【特典4】==**

**==最強サムネイル生成テンプレート==**

![](https://image.brain-market.com/store/7a6fc20fab39f538cffaf24a28b6f25b.png)

ブログや動画のタイトルを元に、クリック率の高い魅力的なサムネイル画像を自動生成するデザイン特化システム。アスペクト比などの細かい設定も済ませてあるので、即戦力として使えます。

**==【特典5】==**

**==Fujin式 Opalワークフロー設計Gem / GPT==**

![](https://image.brain-market.com/store/1e9c3c8f3fddde577e90b447c406b3cb.png)

![](https://image.brain-market.com/store/314b81e5acfda7df80d1296a9ce01544.png)

「こんな自動化がしたいけど、どう組めばいいかわからない…」 そんな悩みは、このAIエージェントが解決します。やりたいことをチャットで伝えるだけで、Opalの複雑な設計図を自動で描いてくれる、**あなた専属のエンジニア**です。

**==【特典6】==**

**==Fujin式スライド生成Gem==**

![](https://image.brain-market.com/store/4dde9f695cb7f9082a903a73697b7aaa.png)

テキストデータを渡すだけで、見やすく美しいプレゼンスライドの構成案を一撃で出力します。セミナー資料や動画のスライド作成時間を大幅に短縮できる、最強ツールです。

**==【特典7】==**

**==日本語ほんやくんGem==**

![](https://image.brain-market.com/store/3d32e1d04031f68e7d168d24b27a80a6.png)

海外ツールであるOpalを使いこなすための強力なサポーター。英語のプロンプトや情報を、自然で精度の高い日本語に翻訳・最適化してくれる翻訳アシスタントGemです。

**==【特典8】==**

**==15体のAIエージェントによる「超・並列ブレインストーミング」システム==**

![](https://image.brain-market.com/store/a53df3eeb00bfc42b4bfb9d5ad168c60.jpg)

15の異なる視点からアイデアについてブレストしてもらう、Googleの論文をもとにした**誰もやっていない異常なワークフロー**です。

**==【特典9】==**

**==悪魔的成約率「ニューロセールスレター」生成システム==**

![](https://image.brain-market.com/store/de9fefd2b5bd201667fc5c12d4a631ce.jpg)

売るための文章を書くのに、もう頭を悩ませる必要はありません。Opalが勝手に「売れるロジック」で構成し、あなたの代わりに商品のセールスレターを設計します。

**==【特典10】==**

**==Fujin式完全自動プロンプト設計GPT==**

![](https://image.brain-market.com/store/a799593e71f5b8241624bad9264478ee.jpg)

プロンプトエンジニアリングの学習は不要です。このGPTが、あなたの曖昧な指示を「AIが100%理解できる命令書」に変換してくれます。汎用性が高すぎる、一生モノの相棒です。

これでもかというほど特典をご用意しています。

### 2-6. 価格について

この教材には、僕が数ヶ月かけ、数万円のAPIコストを溶かして検証したノウハウの全てが詰まっています。 テンプレートを使えば、あなたは開発時間をショートカットし、今日から「AIによる自動化」の恩恵を受けられます。

動画編集や記事執筆を外注すれば、1本で数千円〜数万円が飛びますよね？

このワークフローを一度組んでしまえば、そのコストは**限りなくゼロ**になります。

その価値を考えれば、10万円でも安いと本気で思っています。

ですが、今回はOpalという革命的ツールを一人でも多くの人に触ってほしい。

AI時代の波に一緒に乗る仲間を増やしたい。

そんな思いから、特別割引として、**19,800円**で提供することにしました。

これで、一生モノの「自動化スキル」と「自分だけのAI組織」が手に入るとしたら？

投資対効果は、計算するまでもないはずです。

### 2-7. さあ、準備はいいですか？

AIの進化は待ってくれません。 手作業で消耗し続ける「使う側」で終わるか。 AIをフル活用して自動化の波に乗る「操る側」になるか。

2026年、ここがあなたの大きな分かれ道になります。

Google Opalという最強のツールを使いこなして、クリエイティブの常識を一緒に覆していきましょう。 本編でお会いできるのを楽しみにしています。

## 3\. 特典を一気に受け取れる購入者通信

![](https://image.brain-market.com/store/64a065309e45cbbffba39e9fcffeb5c3.png)

ご購入ありがとうございます！

本講座を購入してくださった方を対象にした、特別なメルマガをご用意しました！

こちらの購入者限定通信では、

- **本講座のアップデート情報**
- **本講座の特典まとめシート**
- **AIエージェントによる完全自動化のメルマガ**
- **最新AI情報や無料セミナー情報**

などのお知らせをお届けしますので、ぜひご登録ください！

（登録後、ご不要であればすぐに解除できます）

【購入者通信】

[https://my54p.com/p/r/S03uvz9a](https://my54p.com/p/r/S03uvz9a)

また、本講座に関して不明点がある場合は、 [fujin@eternalweb.co.jp](https://brain-market.com/u/fujin_metaverse/a/) 、または[FujinのX](https://x.com/Fujin_Metaverse)のDMまでお気軽にご連絡ください。

## 4\. 【環境構築】Google最強AIを最安で使い倒す裏技のような方法

どうも、Fujinです。

いよいよ始まりました、「Google Opal 完全攻略講座」

この講座に参加してくれたあなたは、間違いなく「先行者利益」を掴み取れる位置にいます。

なぜなら、世の中のほとんどの人がまだ、「チャットボット（ChatGPT）」と戯れている段階だからです。

彼らがAIと「おしゃべり」をしている間に、僕たちはAIを「組織」として動かし、圧倒的な生産性の差をつける。

**0→1（創造）だけをあなたが担い**

**1→100（横展開）はGoogleのAI軍団に任せる。**

そんな「クリエイターの産業革命」を、今日から一緒に起こしていきましょう。

![](https://image.brain-market.com/store/6375bbf22fa60a1e4c31bfcc473dfe7c.png)

さて、記念すべき第1章のテーマは**「環境構築」**です。

> **「うわ、環境構築かよ…地味だなあ」**
> 
> **「早くプロンプト教えてくれよ！」**

そう思った人、正直に手を挙げてくださいw

気持ちは痛いほど分かります。

早く魔法のようなプロンプトを使って、コンテンツを一撃で生成したいですよね。

でも、ちょっと待ってください。

断言します。この第1章を飛ばすと、あなたは年間で数万円単位の損をすることになるかもしれません。

この章では、Googleが提供する最強のAIエコシステムを、

- **通常の半額のコストで**
- **企業レベルの堅牢なセキュリティで**
- **プロフェッショナルな独自ドメイン運用で**

使い倒すための「裏ルート」とも呼べる構築手順を、包み隠さず公開します。

正直、この情報を知っているだけでも、Brainの代金なんて一瞬でペイできてしまうはずです。

準備はいいですか？

### 4-1. 【真実】Google One（個人版）vs Google Workspace（事業用）

まず最初に、お金の話をしましょう。

AIを本格的に使いこなそうと思った時、避けて通れないのが「課金」の壁です。

ChatGPT Plus、Google AI Pro、Midjourney…

優秀なAIツールは、大体どれも**「月額20ドル（約3,000円）」**という価格設定になっていますよね。

これ、「AI税」みたいになってて、地味に痛くないですか？

「月3,000円か…ランチ3回分だな…」

と躊躇してしまう気持ち、めちゃくちゃ分かります。僕も最初はそうでした。

でも、今ではAIツールだけで月額数万円を課金しています。なぜか？

3,000円の投資が、3万円、いや30万円以上の価値を生み出してくれると確信しているからです。

これだけで100倍のリターンが得られるわけです。

動画編集の外注費を考えてみてください。サムネイル1枚作ってもらうだけで数千円、動画編集なら数万円が飛びますよね。

それが、AIを使えば月額3,000円で「使い放題」

そう考えれば、コストパフォーマンスは爆発的に良いわけです。

**ですが！**

「コスパが良いからと言って、無駄金を払う必要はない」

これが僕の信念です。

実は、GoogleのAI（Geminiなど）を使うにあたって、多くの人が知らずに損をしている「罠」があります。

それが**「Google One（個人版）」の契約**です。

### 4-2. 「Google AI Premium」の罠

GoogleのAIをフルスペックで使いたいと思った時、普通に検索して出てくるのが「Google AI Pro」「Google AI Ultra」というプランです。

![](https://image.brain-market.com/store/b6e37af0d32877b4c9735a1f80435ee7.png)

これは、個人のGmailアカウント（@gmail .com）に紐づけて契約するもので、価格は月額2,900円。

「まあ、ChatGPTと同じくらいだし、そんなもんか」

と思って契約してしまう人が9割です。

**でも、僕はこのプランをオススメしません。**

なぜなら、もっと安く、しかも機能が豊富な「プロ用」のプランが存在するからです。

### 4-3. 月額1,600円でプロ環境を手に入れる「裏技」

僕が推奨するのは、**「Google Workspace（事業用）」**のアカウントを取得し、そこでAIを使用する方法です。

![](https://image.brain-market.com/store/5c9a50fe57cdf49346879d5bced9cf99.png)

「え、Workspaceって企業が使うやつでしょ？ 個人でも契約できるの？」

「なんか高そう…」

そう思うかもしれませんが、実はここにとんでもない「バグ」のような価格差が存在します。

![](https://image.brain-market.com/store/4af33300be294be10af6b0f6fce79779.png)

Google WorkspaceのStandardプランと、AI機能を組み合わせることで、

「月額1,600円」で、Googleの最強AI環境を構築することが可能です。

- **Google One（個人版）月額2,900円**
- **Google Workspace（裏技）月額約1,600円**

どうですか？

毎月1,300円、年間で約15,000円以上の差が出ます。

機能は変わらない、いや、むしろWorkspaceの方が高機能なのに、値段はほぼ半額。

これを知らずに個人プランを契約し続けるのは、毎月ドブにお金を捨てているようなものです。

僕はこの方法を1年以上前から実践していますが、浮いたお金で別のAIツールを試したり、美味しいランチを食べたりしています...w

この講座に参加してくれたあなたには、絶対に損をしてほしくない。

だからこそ、まずはこの「Google Workspace」への乗り換えを強く推奨します。

### 4-4. 今回のOpal講座には必須ではないですが...

ここで触れておきますが、今回のOpalを使う時には、このGoogle Workspaceの導入は必須ではありません。

今はこういったサブスク（月額課金プラン）に入っていない人でも、Opalを使うことはできるようになっています。

ただし、最近のAI業界の動きや今後の予測などを踏まえても、GoogleのAIを使える環境にしておくのはめちゃくちゃ重要です。

さらに、今後Opalが正式版になるとサブスク登録者のみしか使えなくなる可能性も十分にあります。

まあ、とりあえずAIに課金するならGoogle Workspaceはあったほうが確実にいいです！

通常のGoogle AI Proとできることはほぼ同じ、むしろ機能としてGoogle Workspaceにしかないものもたくさんあります。

これを選ばない理由、ありますか？

「でもFujinさん、導入が難しそう…」

そう思っているかもしれません。

**大丈夫です。そのために僕がいます。**

次の章からは、PC初心者でも迷わないように、ドメインの取得からWorkspaceの登録まで、動画講義も加えてステップバイステップでナビゲートしていきます。

一緒に、プロの環境を作り上げていきましょう。

### 4-5. 注意点もあります

実はGoogle Workspace版は通常版と少し違います。

具体的には、

- Antigravityが有料版として使えない（制限きつめ）
- OpalのGemへの導入機能が使えない

など、少し対応が遅い機能があります。

ここは少し時間がたてば順次対応していくので、あまり問題ではないと僕は思っています。

ただ、乗り換えを検討されている方は今まで使えていた機能が使えなくなる恐れがあるので、そこは注意していただければと！

### 4-6. Xserverドメイン × Workspace 開通ロードマップ

![](https://image.brain-market.com/store/b8261744765255bcb3ef35da1273ff99.png)

ここからは手を動かすパートです。

Google Workspaceを導入するには、一つだけ「条件」があります。

それは、**「独自ドメイン」を持っていること**です。

「ドメイン…？ なにそれ...？ もう無理…」

アレルギー反応が出た人もいるかもしれませんが、安心してくださいw

やることはシンプルです。

「自分だけのインターネット上の住所（ドメイン）」を借りて、

「ここは僕の家です（DNS設定）」とGoogleに伝える。

これだけです。

この作業、業者に頼むと数万円取られますが、自分でやれば数十分、費用は数百円、もっと安く済ませるなら**「1円」**で終わります。

このスキルは、今後あなたが自分の商品を販売したり、Webサイトを作ったりする時にも必ず役立つ「一生モノのスキル」になります。

ぜひ、この機会にマスターしてしまいましょう。

全体の流れは以下の4ステップです。

1. **Xserverで「ドメイン」を取得する**
2. **Google Workspaceに申し込む**
3. **最難関「DNSレコード設定」を行う**
4. **Gmail開通と初期設定**

一つずつ、丁寧に解説していきますね。

### 4-7. 【STEP 1】Xserverでの「ドメイン取得」の最適解

まずはドメインを取得します。

ドメインというのは「[fujin.jp](http://fujin.jp/)」みたいな、ネット上の住所のようなもののことですね。

ドメインを取得できるサービスはたくさんありますが（[お名前.com](http://xn--t8jx73hngb.com/)、GoDaddyなど）、

僕の結論は**「Xserverドメイン（エックスサーバードメイン）」一択**です。

![](https://img.youtube.com/vi/j1ImT6i_M4Y/mqdefault.jpg)

理由は3つ。

1. **管理画面がシンプルで使いやすい。（これ超重要）**
2. **余計な営業メールや広告が少ない。**
3. **そして何より、安い。**

Xserverドメインなら、キャンペーン中だと「1円」とかでドメインが取れることもあります。

![](https://image.brain-market.com/store/1c7e4ff69bd891007953f85f5e26dede.png)

1円ですよ？ うまい棒より安いです...w

2年目からの更新費も、年間で1,500円〜2,000円程度。月額にしたらランチのコーヒー1杯分以下です。

**どのドメイン（.com / .net / .jp）を選ぶべき？**

![](https://image.brain-market.com/store/86f759b99dea037276e86139301470e1.png)

Xserverドメインのサイトに行くと、好きな文字列を入力してドメインを検索できます。

ここで迷うのが、末尾の「.com」や「.net」をどれにするか問題です。

結論から言うと、なんでもOKなんですが、これからもドメインをしっかり使っていきｒたいのであれば、**「.com」または「.net」**をおすすめします。

- **.com / .net  
	**世界中で使われている定番。信頼性が高い。年間更新費も安い。
- **.jp  
	**日本国内での信頼性は最強だが、少し料金が高い。
- **.xyz / .site など  
	**取得費用は激安（数十円）だが、更新費が高かったり、スパムメールに使われることが多く信頼性が低い場合がある。

迷ったら「.com」でOKです。

自分の名前や、屋号、好きな言葉を入れて検索し、空いているものを取得しましょう。

ここで取得したドメインが、あなたのこれからの看板になります。愛着の湧く名前をつけてあげてください。

### 4-8. 【STEP 2】Google Workspace「Business Starter」の申し込み手順

ドメインを手に入れたら、次はGoogle Workspaceの申し込みです。

Google Workspaceの公式サイトにアクセスし、「利用を開始」ボタンを押します。

ここで注意点が一つ。

プラン選択画面で、色々なプランが出てきますが、

迷わず**「Business Standard」**を選んでください。

- Business Starter（月額800円〜）
- **Business Standard（月額1,600円〜）**
- Business Plus（月額2,500円〜）

※年間プランの場合です。

![](https://image.brain-market.com/store/32b482a6d1c4e591616f7181dac36b23.png)

なぜ、**Business Standard**なのかというと、Business StarterだとAI機能をフルには使えないからです。

逆にAIを使うという目的においては、Business PlusとBusiness Standardはできることが一緒なので、Business Standardで十分です。

あとからもっと機能が欲しくなったら、上げればいいだけの話。まずはスモールスタートでいきましょう。

まずは、会社の基本情報を入力していきます。

![](https://image.brain-market.com/store/c821c4e8c26449f8e5494568e7c02eb0.png)

申し込み画面では、先ほど取得したドメインを入力する欄が出てきます。

ここでXserverで取得したドメインを入力します。

その後、管理者となるユーザー名（自分）とパスワードを設定します。

これが、あなたの新しい「最強のGoogleアカウント」になります。

普段使っているプライベートのGmailとは完全に切り離された、ビジネス専用のアカウントです。

気持ちも引き締まりますよね。

### 4-9. 【STEP 3】最難関「DNSレコード設定（TXTレコード）」の突破法

さて、ここが本講座のハイライトであり、多くの人が挫折する「魔のステップ」です。

DNSレコード設定。

名前からして難しそうですよね。

Google Workspaceを申し込むと、Googleからこう言われます。

「あなたが入力したドメイン、本当にあなたのものですか？証明してください」

この「証明」のために行うのが、DNSレコード設定です。

具体的には、Xserverドメインの管理画面に入って、Googleから渡された「合言葉（TXTレコード）」を貼り付けるという作業になります。

![](https://image.brain-market.com/store/e8a221e7319e2256b0bf9892bb897cbd.png)

1. **Google Workspaceの管理画面（Admin Console）を開く。  
	**「ドメインの所有権を証明」という画面に進み、「TXTレコードで証明する」を選択します。  
	すると、長い謎の文字列が表示されます。これを「コピー」します。
	![](https://stepwill.co.jp/wp-content/uploads/2025/07/google-workspace-standard-18.webp)
2. **Xserverドメインのネームサーバー設定を開く。**
	このネームサーバー設定から購入したドメインを選択し、青いボタンを押していくと設定が完了します。![](https://image.brain-market.com/store/9d965692a4e848a19ab3b9a3f8ecab94.jpg)
3. **XserverドメインのDNSレコード設定を開く。  
	**取得したドメインのメニューから「DNSレコード設定」を選択します。  
	「DNSレコード設定を追加する」ボタンを押し、以下の通りに入力します。
	- ホスト名： 空欄のまま（または @ ）
	- 種別： 「TXT」を選択
	- 内容： さっきコピーしたGoogleの長い文字列をペースト
	- 優先度： 0（そのままでOK）
	![](https://image.brain-market.com/store/d9d18980d3ec6ff73a627eef06f5ee9c.png)![](https://image.brain-market.com/store/43a3f15f9dda9f964da02eb3a118aad3.png)
4. **「確認画面へ進む」→「追加する」を押す。  
	**これでXserver側の設定は完了です。
5. **Google Workspaceの画面に戻り、「所有権を証明」ボタンを押す。  
	**インターネットの世界に設定が反映されるまで、数分〜1時間程度かかります。  
	コーヒーでも飲みながら待ちましょう。  
	ボタンを押して「所有権が証明されました！」と表示されれば、クリアです！

おめでとうございます！

これで、あなたはインターネット上の土地の所有者として認められ、Googleの最強ツールを使う権利を得ました。

一番難しい山は越えましたよ！

### 4-10. 【STEP 4】Gmail開通と初期セキュリティ設定

所有権の証明が終わったら、あとはGmailを使えるようにする設定（MXレコード設定）がありますが、これも手順はTXTレコードと同じです。

Googleが指定する値を、Xserver側にコピペするだけ。

最近のWorkspaceは、ボタン一つで自動設定してくれる機能もあったりするので、指示に従って進めればOKです。

そして、忘れてはいけないのが**「2段階認証」**の設定です。

せっかく最強の城を築いても、鍵が開けっ放しでは泥棒に入り放題です。

管理コンソールの「セキュリティ」設定から「概要」にいき、2段階認証プロセスを「強制」または「推奨」に設定しておきましょう。

![](https://image.brain-market.com/store/1449714a07d9bbe98662feb0f175801c.png)

![](https://image.brain-market.com/store/d001b5a875eda7cadd48a73713596ede.png)![](https://image.brain-market.com/store/71a6e73edc1e25cf010a79c76226c9d2.png)

スマホのGoogle認証アプリなどを使って、ログイン時にワンタイムパスワードを求めるようにします。

これで、誰にも邪魔されず、データ漏洩の心配もなく、心置きなくAIを使い倒せる環境の完成です。

### 4-11. Google Workspaceで早期アクセス機能をオンにする

Google Workspaceでテスト版のAI機能を使用するときに必要になる設定があるので、ご紹介していきます。

まず、Google Workspaceの管理者アカウントにログインし、そのアカウントで管理画面に行きます。

Chromeの下面右上の点9つのところをクリックして、管理というアイコンをクリックするとアクセスできます。

![](https://image.brain-market.com/store/513bb0bb40054385350f10683ec67d2a.png)

このような画面が出てくるので、左の「生成AI」から「Gemini for Workspace」をクリックします。

![](https://image.brain-market.com/store/0497fed42fccddc4ac8e03a86a7b51ad.png)![](https://image.brain-market.com/store/5e8be878f2afe85b5bb5b6dbff61c90f.png)

次に、アルファ版 Gemini 機能の右の「^」のマークをクリックします。

![](https://image.brain-market.com/store/c2a3f80ad291878c1a11471b7ccc9e2f.png)

アルファ版機能というタブが表示されたら、オンをクリックし、チェックボックスにもチェックを入れ、右下の保存をクリックします。

![](https://image.brain-market.com/store/c160991d161bf46fc21d97e01187cee2.png)

これでOKです。

**もう一つあります！**

管理画面の上部の検索バーに「早期アクセス」と入力すると「早期アクセスアプリ」というものが出てくるのでクリックします。

![](https://image.brain-market.com/store/2e7c57c4fbb30449911424b295b40963.png)

次にサービスのステータスの右の「^」のマークをクリックします。

![](https://image.brain-market.com/store/5e11a6e73cd8a360980fefbf21f7fee5.png)

その次に、「オン（すべてのユーザー）」を選択し、保存をクリックします。

  
![](https://image.brain-market.com/store/92c6b8d1dbb188110c754bd8feae665d.png)

これでOKです！

ここで最初に設定しておくとあとが楽なので、やっておきましょう。  

### 4-12. Opalへのログイン

環境構築、お疲れ様でした！

ここまでの作業で、あなたはすでに上位数%の「AIリテラシー強者」です。

普通の人はドメイン取得の時点でお手上げですからね。

さて、いよいよ本丸である**「Opal」**を使えるようにしていきましょう。

Opalは、Googleの最新AIモデル（Gemini 3 Proなど）を使って、複数のタスクを自動で処理させるためのツールです。

いよいよOpalにアクセスします。

https://opal.google/

https://opal.google/

![https://opal.google/](https://opal.google/images/share-card-prod.png)

サイトを開くと、英語のインターフェースが表示されて「ウッ」となるかもしれませんが、大丈夫です。

この講座では動画でわかりやすく解説していきます。

あなたの手元には、Googleの最強AIを、最安・安全・無制限に近い形で使い倒せる環境があります。

ここまでの作業、本当にお疲れ様でした。

慣れない単語も多くて大変だったと思いますが、この「環境構築」こそが、これからのAI時代を生き抜くための最強の武器になります。

次章では、いよいよこの環境を使って、あなたの業務を「自動化ワークフロー」に変換するための設計図を描いていきます。

単なる「AI操作」ではなく、「エンジニアリング思考」を手に入れる章です。

ここからが本当の沼（楽しい意味で）です。

しっかりと休憩を取って、頭をリフレッシュしてから進んでくださいね。

## 5\. 【AI時代の思考法】業務を「ワークフロー」にするために押さえておくべきこと

さて、ここからはワークフローを構築していくときに、必ず押さえておいてほしい考え方について入っていきます。

これはAI時代にうまくAIと共創していくための重要な思考法です。

ということで、さっそく始めていきましょう！

第1章では環境構築についてお話ししましたが、準備はできましたか？

この第2章からがいよいよ本番、業務自動化における「全体像」と、AIを使いこなすための「哲学」について深掘りしていきます。

正直に言いますが、この第2章の内容が、本講座の中で最も重要と言っても過言ではありません。

この考え方をスキップしてツールだけ触ろうとするのは、結構危険です...。

なぜか。

多くの人がAIツールの使い方（ハウツー）ばかりを追いかけて、肝心の「どう設計するか」という思考法をおろそかにしているからです。

ここを理解していないと、いくら高機能なOpalを使っても、宝の持ち腐れになってしまいます。

逆に、ここさえ押さえてしまえば、ツールが進化しようが、新しいモデルが出ようが、あなたは一生食いっぱぐれない「AI自動化マスター」としての地位を確立できるでしょう。

今回は、僕が普段どのようにAIを活用し、ワークフローを構築しているのか。

その脳内をすべて言語化しました！

少し概念的な話も出てきますが、ここを理解するかどうかで、あなたの生産性は10倍、いや100倍変わります。

ぜひ、一言一句逃さずに吸収してください。

### 5-1. なぜ、あなたのAIコンテンツは「無価値」になるのか？

![](https://image.brain-market.com/store/c8d9343e8d89933be6ba55b1a3b609bf.png)

まず最初に、少し厳しい現実の話をします。

自動化の設計図を描く前に、どうしても共有しておかなければならない「前提」があるからです。

今、世の中では猫も杓子も「AI、AI」と言っていますよね。ChatGPTやGeminiを使ってブログ記事を書いたり、リサーチをしたり、YouTubeの台本を作ったりしている人も増えてきました。

> **「AIにリサーチさせて、構成を作って、記事を書かせる」**

これ自体は素晴らしいことです。業務効率化の第一歩です。

皆さんも、すでに何かしらの形でAIを使っているのではないでしょうか。

でも、はっきり言います。

ただ単にAIに「丸投げ」して作ったコンテンツには、**何の価値もありません。**

なぜなら、**「誰でも作れるから」**です。

極端な話、今や小学生でもChatGPTに向かって「最新のAIトレンドについてYouTubeの台本書いて」と頼めば、それなりのものが数秒で出てきます。それを文章から音声にするAI（TTS）にペーストして音声化し、適当な画像を貼り付ければ、YouTube動画が完成してしまいます。

やり方さえ知っていれば、誰でもできる。

これが何を意味するか分かりますか？

**「コモディティ化」です。**

AIが普及すればするほど、AIが作っただけの「そこそこのコンテンツ」が市場に溢れかえります。供給過多になり、価値は大暴落するわけです。

今はまだ、「AIを使える人」が少ないから、先行者利益があるかもしれません。

「AIで作りました！」というだけで、「すごいね」と言ってもらえるフェーズかもしれません。

しかし、これだけ技術が進化しているんです。僕の周りでもAIを使い始めている人は急激に増えています。

遠くない未来、AIを使ってコンテンツを作るなんて「当たり前」になります。

その時、AIに全部任せて作っただけのあなたのコンテンツに、誰が見向きをするでしょうか？

AIで調べれば分かるような「パソコンのエラーの直し方」みたいな記事を、わざわざあなたのブログで読む人がいるでしょうか？

**答えはNoです。**

「AIで自動化だ！」と喜んで、思考停止で量産している人たちは、遠くない未来に必ず淘汰されます。だって、あなたのコンテンツを見る理由がないんですから。

> **「じゃあ、どうすればいいの？」**
> 
> **「自動化しちゃダメってこと？」**
> 
> **「せっかくの自動化講座なのに、意味ないじゃん」**

そう思いますよね。

ここで重要になるのが、僕が提唱している**「0→1は人間、1→100はAI」**という哲学です。

**「0→1」はサボるな。「1→100」を任せろ。**

自動化を進める上で、絶対に守るべき鉄則があります。

それは、「人間がやるべき領域」と「AIがやるべき領域」を明確に分けるということです。

最初から100%の自動化を目指してはいけません。それは不可能ですし、やるべきではありません。

- **0→1（創造・オリジナリティ）： 人間がやる**
- **1→100（展開・スケーリング）： AIがやる**

ここを履き違えてはいけません。

「0→1」の部分、つまり

> **「何もないところからアイデアを生み出す」**
> 
> **「一次情報を拾いに行く」**
> 
> **「独自の体験談や想いを語る」**

ここは、絶対にAIに任せてはいけません。あなたが汗をかいてやるべき部分です。

例えば、僕の場合で考えてみましょう。

もし僕が、ネット上のニュース記事をコピペして、それをAIに「要約して記事にして」と投げただけのブログを公開していたらどうでしょう？

そこには「Fujin」という人間の介在価値はゼロです。元のニュース記事を読めばいいだけの話ですから。

そうではなく、

- 実際にそのゲームをプレイしてどう感じたか？
- 業界の裏事情を知っている自分だからこそ言える考察は何か？
- 過去のWeb3での失敗経験と紐づけた独自の視点は？
- ポッドキャストでの雑談のような、人間味のある語り

こういった「生身の体験」や「思考」こそが、コンテンツの核（0→1）になります。ここはAIには真似できません。AIは「体験」できないからです。

逆に言えば、あなたがこの「0→1」さえ生み出せば、その後の**「1→100」の展開は、すべてAIに任せることができます。**

- その熱い想いをブログ記事に整形する
- SNS用に要約して拡散する
- わかりやすい図解を作る
- 他言語に翻訳して世界へ届ける

これらはすべて「横展開」の作業です。AIの最も得意とする領域です。

多くの人は、この区別がつかずに、最初の「0→1」までAIにやらせようとしてしまいます。

「何かいいアイデアない？」とAIに聞いて、出てきたものをそのまま使う。だから、薄っぺらい、誰にでも書けるようなコンテンツになってしまうんです。

「0→1」は人間がやる。「1→100」はAIがやる。

この役割分担を徹底することが、AI時代に生き残るための唯一の生存戦略であり、本講座の核となる思想です。

### 5-2. 何を自動化すべきなのかを明確にしよう

では、具体的にどうやって業務を自動化していけばいいのか。

思考の整理に入っていきましょう。

まずは、あなたの今の業務を「棚卸し」することから始めましょう。

そして、そのタスクを以下の3つに「仕分け」してください。

![](https://image.brain-market.com/store/71a9f1348277383495dd67cd0f72a1ac.png)

**① クリエイティブ（Creative）**

→ 人間しかしちゃいけない業務（0→1）

ここは、あなたの「聖域」です。

- 企画の立案
- 一次情報の取得（取材、体験、リサーチ）
- 感情や想いを言語化する（収録する）
- 誰かと会って話す

ここは自動化しません。むしろ、AIによって空いた時間をすべてここに投下してください。

僕がポッドキャストで雑談を入れるのも、ここに含まれます。AIには「雑談」の面白さは作れませんから。

あなたがやるべきことに集中する。これがあなたの「価値」になります。

**② オペレーション（Operation）**

→ AIが得意な業務（1→100）

ここが今回の主役、Opalの出番です。

- 音声の文字起こし
- 要約、翻訳
- フォーマット変換（ブログ→SNSなど）
- データの抽出、分類
- 誤字脱字チェック

これらは「作業」です。人間がやる必要はありません。徹底的に自動化し、あなたの手から離してください。

**③ ゴミ（Waste）**

→ そもそもやる必要がない業務

ここが意外と見落としがちですが、一番大事かもしれません。

- 成果に直結しない事務作業
- 惰性で続けている会議や報告
- 誰も見ない資料作成

これは自動化すら不要です。今すぐ捨ててください。

「自動化する」ということは、その業務を維持コストをかけて残すということです。

そもそもやる必要がない「ゴミ」を、高性能なAIを使って効率よく処理することほど、無意味なことはありません。

まずは「やめる」

その上で、残った必要な業務のうち、「自分しかできないこと」以外をAIに任せる。

この順序が重要です。

### 5-3. 【特典】業務仕分けスプレッドシート

> **「そうは言っても、自分の業務がどれに当てはまるか分からない…」**
> 
> **「棚卸しなんて面倒くさい…」**

そんな方のために、今回は**「業務仕分けスプレッドシート」**を用意しました。

これを使えば、あなたのタスクを簡単に見える化し、自動化すべきポイントを一瞬で特定できます。

コピーを作成をして使ってください！

![](https://image.brain-market.com/store/ef86c568b9507099fa51d706cbeb8e8f.png)

【Opal講座特典】業務仕分けスプレッドシート

https://docs.google.com/spreadsheets/d/1fSv5SVwdZMm3S6XIs0UvjUMaxJ6QNDTSNfbHCmLu5No/edit?usp=drive\_link

![【Opal講座特典】業務仕分けスプレッドシート](https://lh7-us.googleusercontent.com/docs/AHkbwyLhqkteepoUfD0wpr0kKvfiQCLouRkSh6crrqHFsTQFwwLsZCJGwJEdLxf-ILOOM9t9ElHWKvMUxyuddeNvbNbIrsS5iFewD0EOCHQFRnBnFGO7pRiw=w1200-h630-p)

この「仕分け」という工程は、地味で面倒に感じるかもしれません。

「早くOpalを触らせろ！」と思うかもしれません。

でも、ここを飛ばしてはいけません。ここが一番大事です。

今の業務フローを見直し、無駄を削ぎ落とし、AIに任せるべき部分を特定する。

この設計図さえできてしまえば、あとはOpalが勝手に働いてくれます。

### 5-4. 【特典解説】「業務仕分けスプレッドシート」の使い方

**STEP 1：業務の「棚卸し」**

まず、シートの「業務・タスク名」の列に、あなたが普段やっている作業をすべて書き出してください。

「動画のカット編集」「サムネイル作成」「リサーチ」「メール返信」といった大きなタスクから、「請求書の保存」「毎朝の数値チェック」といった細かいタスクまで、思いつく限りすべてです。

**STEP 2：「仕分け」**

書き出したタスクを、以下の基準に従って「3つ」に分類します。

1. Creative（人間しかできない：残す）  
	企画、想い（理念）の言語化、現地取材などの一次情報の取得。 これらは、あなたの「魂」が入る部分です。AIには代替できません。むしろ、**ここだけに時間を使うために、他のすべてを自動化します。**
2. Operation（AIが得意：任せる）  
	要約、翻訳、フォーマット変換、データ抽出、単純なライティング。 「正解」や「型」がある作業は、すべてAI（Opal）の方が速く、正確です。これらはあなたが汗をかく仕事ではありません。
3. Garbage（ゴミ：捨てる）  
	「なんとなくやっているが、成果に直結していない」業務。 これらはAIにやらせるまでもなく、**今すぐやめるべき**です。

**STEP 3：自動化の「設計」**

「Operation」に分類されたタスクこそが、本講座で自動化する対象です。シートの「アクションプラン」欄に、どう自動化するかを記入します。

### 5-5. 「ナレッジ資本」の重要性

「0→1」は人間がやると言いましたが、AIに「1→100」を展開させる際にも、重要なコツがあります。

ただ単に

> **「ブログ記事書いて」**
> 
> **「要約して」**

とAIに投げても、

返ってくるのは「綺麗だけど、つまらない優等生のような文章」です。

AI特有の「あの感じ」ですね...。

そこで僕、Fujinが提唱していて、とても重要なのが、**「ナレッジ資本」**という考え方です。

わかりやすく言うと、AIに与える情報量（コンテキスト）を極限まで増やす、ということです。

![](https://image.brain-market.com/store/ca47b6b778d7ca3cd26740593ae0acf7.png)

**AIを使う際、多くの人は入力する情報が少なすぎます。**

「この音声をブログにして」だけでは不十分なんです。

AIに作業を依頼するときは、単に指示を出すだけでなく、**あなたの過去のデータを大量に読み込ませてください。**

- 過去に自分が書いたブログ記事
- バズったSNSの投稿
- 自分の思考をまとめたノート
- 顧客とのやり取りの履歴

これらのデータを「参考資料（ナレッジ）」としてOpalに渡すのです。

Opal上で、Geminiなどのモデルに追加情報として食わせるイメージです。

そうすると何が起きるか？

AIはあなたの文体、思考の癖、好みの言い回しを分析・学習します。

そして、「まるであなたが書いたかのような」アウトプットを出してくるようになります。

これが**「パーソナライズ」**です。

これからのAIの重要なテーマとして、僕は**「ハイパーパーソナライズ」**があると思っています。

パーソナライズを超強化した版みたいな感じですね。これかなり大切なことなんですが、詳しくは今後追記していくかもしれません。

話を戻して、AIはあなたが与えた情報量に比例して賢くなります。

あなたの中に眠っている知識や経験、つまり「ナレッジ資本」をどれだけAIに移植できるか。

これが、これからのコンテンツ制作における勝負の分かれ目になります。

ナレッジ資本を持っている人は強いです。独自のデータがあればあるほど、AIはあなたの最強のパートナーになります。

逆に、自分の中に何も蓄積がない人は、AIを使っても薄っぺらいものしかし作れません。

だからこそ、日頃からアウトプットをし、データを蓄積しておくこと。

それが、AI時代の資産形成に直結するんですね。

僕も過去の記事データを大量に読み込ませているので、AIが生成した記事でも「Fujinっぽさ」が出力されるわけです。

**「ナレッジの量 ＝ AI時代の戦闘力」だと覚えておいてください。**

### 5-6. 【特典】Opalワークフロー設計GPTの使い方

さて、考え方はここまででかなりお伝え出来たので、いよいよOpalのワークフローの作り方に入っていきたいんですが、ここで

**「考え方は分かったけど、実際にOpalのワークフローを組むのは難しそう…」**

と不安になった方もいるかもしれません。

最初から複雑なワークフローを組むのは、確かにハードルが高いです。

でも、安心してください。

そのために、最強の**「チートツール」**を用意しました。

名付けて、**「Fujin式Opalワークフロー設計Gem / GPT」**です。

![](https://image.brain-market.com/store/35e8e69497b7d3f069f6f663f8b16369.png)

‎Google Gemini

Meet Gemini, Google’s AI assistant. Get help with writing, planning, brainstorming, and more. Experience the power of generative AI.

https://gemini.google.com/gem/1c7ovsoc41YB1ygjl1bQVnLQuhX3NNJsT?usp=sharing

![‎Google Gemini](https://www.gstatic.com/lamda/images/gemini_aurora_thumbnail_4g_e74822ff0ca4259beb718.png)

![](https://image.brain-market.com/store/ea418c5a6fca0e117d2b7db981fb9dd3.png)

ChatGPT - Fujin式Opalワークフロー設計GPT【Opal講座特典】

どんなワークフローを作りたいか入力してください。

https://chatgpt.com/g/g-69382ab06a3c819199cee73098f2e623-fujinshi-opalwakuhuroshe-ji-gpt-opaljiang-zuo-te-dian

![ChatGPT - Fujin式Opalワークフロー設計GPT【Opal講座特典】](https://chatgpt.com/backend-api/estuary/content?id=file-2Jm7t1Mt8YY8Lzgw8mwCMP&gizmo_id=g-69382ab06a3c819199cee73098f2e623&ts=490590&p=gpp&cid=1&sig=482b38d281c32dc34e9a9cbe6574852011200d5389e50862a34599fd3bfc1601&v=0)

これは、あなたの代わりに自動化の設計図を描いてくれるAIエージェントです。

使い方は超シンプル。

1. 今のあなたのタスクを箇条書きにする（あるいは業務仕分けシートをコピペする）。
2. それを「Fujin式Opalワークフロー設計Gem / GPT」に投げる。

たったこれだけです。

そうすると、GPTが勝手にあなたの業務を分析し、

> **「このタスクはOpalのこの機能を使えば自動化できます」**
> 
> **「具体的には、こういうノードを繋いでください」**
> 
> **「プロンプトはこのように書いてください」**

と、Opalの構成案を完全回答してくれます。

すごくないですか？

あなたはもう、脳ミソを使って複雑な設計を考える必要はありません。

まずはこのGPTを使って、カンニングしてください。

**プロレベルの自動化設計図が一瞬で手に入ります。**

ただし、これはシンプルなワークフローしか出てこないので、複雑になればなるほど細かなコツが必要になります。

でも、これでも十分なレベルのワークフローは組めるはずです。

使っていくと徐々に、

「この処理とこの処理、繋げられるんじゃない？」といった発見があるはずです。

もしすごいワークフローができたら、僕にも教えてください...w

でも、最初のハードルを越えるためには、こういうチート技をガンガン使っていくべきです。

このGem、GPTには、僕が蓄積してきたOpalのノウハウを学習させてあります。

言ってみれば、僕の脳内をレンタルするようなものです。

ぜひ使い倒して、楽をして結果を出しちゃってください。

### 5-7. Opalが得意なのは「並列処理」である

![](https://image.brain-market.com/store/49f72d7ae366887f575a4d906e777dd0.png)

さて、第2章の最後に、Opalを使う上で最も重要な概念をお伝えします。

これを理解しているかどうかが、Opalの真価を引き出せるかの分水嶺です。

**それは、「直列処理」から「並列処理」への思考転換です。**

今までの仕事のやり方を思い出してください。

例えば、YouTube動画を作る場合。

1. 情報収集をする
2. 台本を書く
3. 収録する
4. 動画編集する
5. サムネイルを作る
6. 投稿する

このように、「Aが終わったらB、Bが終わったらC」と、順番にタスクをこなしていましたよね？

これが「直列処理」です。

前の工程が終わらないと次に進めない。これが最大のボトルネックでした。

> **「台本ができないと撮影できない」**
> 
> **「撮影が終わらないと編集できない」**

だから時間がかかるんです。

人間は体が一つしかないので、基本的にはこれしかできません。

だから、AIを使う時も、ついこの「直列」の癖で使ってしまう人が多いんです。

「要約させて、そのあとで翻訳させて…」といった具合に。

しかし、Opalは違います。

AIは、複数のタスクを同時にこなすことができます。

これが「並列処理」です。

僕がやっているワークフローは、まさにこの並列処理を極めたものです。

僕が目指しているのは、「ワンソース・マルチユース」の究極形です。

1. 【0→1】 自分の声で喋った音声データ（ワンソース）を用意する。
2. 【1→∞】それをOpalに放り込んでコンテンツを量産する。

すると、Opalの中で以下のような処理が「同時に」走ります。

これが「並列」です。

- 処理A： 音声からブログ記事を執筆
- 処理B： 同じ音声からYouTube台本を作成
- 処理C： 同時にX（Twitter）のポストを5パターン作成
- 処理D： インスタ用図解の構成案を作成
- 処理E： 内容を要約してメルマガを作成

Aが終わるのを待つ必要はありません。

情報収集が終わったら、そこから放射状に一気にタスクが走り出す。

音声ファイルという一つの種から、10個も20個ものコンテンツが一斉に芽吹くイメージです。

これが、**「Opalの真の価値」**です。

Opalは、この並列処理を行うために生まれてきたツールだと言ってもいいでしょう。

直列思考のままAIを使っている人は、「チャットボットと会話して終わり」になってしまいます。

これではAIの価値の10%も引き出せていません。

> **「どうすれば並列にできるか？」**
> 
> **「1つの素材から、同時に何を生み出せるか？」**

常にこの視点を持ってワークフローを設計してください。

最初は直列でも構いません。でも、「これとこれ、同時にできるな」と気づいた瞬間、あなたの生産性は爆発的に向上します。

### 5-8. AI自動化のためのマインドセット

![](https://image.brain-market.com/store/8febdffab46873c6a702ee34f7648b6c.png)

第2章では、業務自動化のための設計思想についてお話ししました。

少し熱く語りすぎてしまいましたが、ついて来れていますか？

これらは単なるノウハウではありません。

AI時代を生き抜くための、OS（のアップデートです。

- **0→1は人間、1→100はAI。 楽をする場所を間違えない。**
- **ナレッジ資本を蓄積せよ。 あなたのデータをAIに食わせろ。**
- **直列から並列へ。 AIのパワーで時間をねじ曲げろ。**

このマインドセットを持った上で、次章からの実践編に進んでください。

ただツールを触るだけの作業者になるのか。

それとも、AIを配下に置いてシステムを操る「オーナー」になるのか。

その違いは、この第2章をどれだけ深く理解できたかにかかっています。

この章の内容は、AIツールが変わっても一生使える「本質」です。

あなたはもう、その入り口に立っています。

この調子で、最強の自動化システムを構築していきましょう。

## 6\. 【基本操作】Opalで自動化を始めよう

さて、お待たせしました...！

今回からいよいよ本格的な実践編に入っていきます。

![](https://image.brain-market.com/store/3cd2290ac85516e9f2dbd83b38571e4b.png)

前回までは、マインドセットや環境構築といった「準備運動」の話をしてきました。

でも、皆さんが一番待ち望んでいるのは、

> **「で、結局どうやってその魔法のようなツールを動かすの？」**
> 
> **「Opalの画面、英語ばっかりで意味不明なんだけど、どうすればいいの？」**

という具体的な操作方法ですよね。

分かります。その気持ち、痛いほど分かります。

初めてOpalの画面を開いた時、僕も同じことを思いましたから。

> **「うわ、なんかエンジニア向けの専門ツール来た…」**
> 
> **「これ、文系の僕には無理なやつじゃないか？」**
> 
> **「英語だし、ワークフローとか難しいじゃん」**

そうやって、ブラウザをそっと閉じそうになった瞬間がありました。

**でも、そこで閉じなくて本当によかった。**

もしあそこで諦めていたら、今の「自動化されたコンテンツ量産システム」は存在していなかったからです。

この第3章では、そんな「一見とっつきにくい」Opalというモンスターマシンを、**誰でも乗りこなせるように、徹底的に、かつ分かりやすく解説**していきます。

ここからのOpal講座は動画講義を中心に進めていきます。

もちろん文字でも学習できるようにスクリーンショットも添付しながら書いてありますので、お好きな方でどうぞ！

正直、この章を読むだけでも、Brainの金額以上の価値がある自信があります。

なぜなら、ここにはGoogleが公式には教えてくれない「僕が使いまくって築き上げたノウハウ」が詰まっているからです。

マジでGoogle側からこのOpalに関する情報がなさすぎて、英語でも情報が少ないです...w

ですので、僕が手を動かしまくるしかなかったわけです。

それでは、Opal基本操作編始まります！

覚悟を決めてついてきてください。

### 6-1. Opalのやさしい始め方

まず最初に、Opalの始め方について解説していきます。

動画で見たい方はこちらから！

![](https://img.youtube.com/vi/emOsnjgYRuE/mqdefault.jpg)

まず下記のリンクから、Opalのトップページにアクセスしてください。

https://opal.google/

https://opal.google/

![https://opal.google/](https://opal.google/images/share-card-prod.png)

※URLはブックマーク推奨です！

![](https://image.brain-market.com/store/4dcbfc61fc829a1c188a676824ca366d.png)

Google Chromeは画面右上の方にある☆マークをクリックするとブックマークできます。

画面を開くと、上に「Opal Experiment」というロゴが表示されているはずです。

この「Experiment」という単語、直訳すると「実験」ですよね。

これ、Googleからの非常に重要なメッセージなんです。

Google先生はこう言っているわけです。

**「これはまだ完成品じゃないよ。開発中のベータ版だよ。だからバグもあるし、たまに止まることもあるけど、その代わり最新技術を一番乗りで触らせてあげるよ」**

と。

![](https://image.brain-market.com/store/921a81a655fff157762ba9804c5b265d.png)

実際に使っていると分かりますが、Opalは正直、**動作が不安定な時があります。**

複雑な指示を出すとエラーを吐いて止まったり、画面が固まったりすることも珍しくありません。

普通の人なら「なんだこのポンコツツールは！」と怒ってやめてしまうかもしれません。

しかし、僕たちにとっては、それが逆にチャンスなんです。

今のOpalは、まだ使いこなせる人が限られる。だからこそ、まだこのツールのポテンシャルに気づいて使いこなしている人が少ないわけです。

そこで、この教材があるわけですよ。そう思ったら、すでに購入したあなたは超ラッキーじゃないですか？

多少の不安定さを許容し、それをハックして使いこなすことで、他者には真似できない圧倒的な生産性を手に入れることができる。

もちろんこの不安定さにどう対処するのかもお伝えします！

アクセス方法は簡単です。

「Sign in」または「Try Opal」というボタンをクリックして、Googleアカウントでログインするだけ。

第1章でGoogle Workspaceを契約した方はそのアカウントでログインすることを推奨します。

なぜなら、今後課金者のみしか使えなくなる可能性があるからです。

そうなったときに、無料アカウントでやっているとそのデータが引き継げなくなってしまうかもしれないからですね。

もちろん、個人の無料アカウントでも使えますが、そういったリスクがあるのは理解したうえで使ってくださいね！

### 6-2. Opalにはテンプレートが用意されている

ログインして最初に表示されるのが、ホーム画面です。

ここには、Googleの開発チームが作った「ワークフローのサンプル」がずらりと並んでいます。

![](https://image.brain-market.com/store/dbd02f0929f80a6e948ed9af531ed678.png)

- **Blog Post Writer**（ブログ記事作成）
- **Learning YouTube**（YouTube動画で学ぶ）
- **Product Research**（リサーチアシスタント）

などなど、クリエイターなら使えそうな機能が、すでにテンプレートとして用意されています！

> **「え、これを使えばもう自分で作る必要ないじゃん！」**

そう思ったあなた、半分正解で半分間違いです。

試しに一つ、「Blog Post Writer」をクリックして開いてみてください。

画面いっぱいに、四角い箱（ノード）とそれをつなぐ線が複雑に絡み合った図が表示されます。

![](https://image.brain-market.com/store/daf52c1f4894ee5f8955bb3c9600755e.png)

その中身をよく見てみると…

1. **Get Topic**（お題を入力）
2. **Do Research**（リサーチを実行）
3. **Write Outline**（構成案を作成）
4. **Write Post**（記事執筆）
5. **Create Banner Image**（バナー画像生成）
6. **Display Blog Post**（完成）

という、ブログ執筆フローが組まれています。

しかし、ここで重大な問題に気づくはずです。

**プロンプト（指示文）が、すべて英語なんです。**

Googleはアメリカの企業なので当然ですが、このまま使うと、AIは英語でリサーチし、英語で構成を組み、英語で記事を書いてきます。

でも、僕たちが欲しいのは日本語の情報ですよね。

英語で出力された記事をいちいち翻訳ソフトにかける。

...…なんてことをしていたら、自動化の意味がありません。

もちろん、このテンプレートの中にあるプロンプトを一つ一つ開いて、すべて日本語に書き換えていく…という修正作業を行えば使えます。

それはそれで、Googleの人たちがどういうプロンプトを書いているのかを学ぶ良い教材にはなります。

ですが、僕の結論はこうです。

**「最初は、真っ白なキャンバスから自分で作った方が早いし、理解が深まる」**

既存の複雑なテンプレートを修正するのは、逆にコストがかかったり、うまくいかなかったり意外とストレスが溜まります。

それよりも、まずワークフローの作り方を学んで、自分のやりたいことに合わせて、ゼロから必要なパーツを置いていく方が、結果的に近道です。

というわけで、ホームページにあるテンプレートはお手本として試しつつ、自分だけのワークフローを作っていきましょう。

### 6-3. AIにワークフローを作ってもらおう

それでは、画面右上にある**「+ Create New」**というボタンをクリックしてください。

![](https://image.brain-market.com/store/e6b3f2dacd022dd09ad7a87e5e0862b9.png)

すると、何もない真っ白なキャンバスのような画面が表示されます。

ここから、一つ一つパーツを配置していく…と言いたいところですが、Opalには**初心者の方にはありがたい機能**が搭載されています。

それが、「言葉で指示するだけで、AIが勝手にワークフローの設計図を描いてくれる機能」です。

画面の下部を見てください。チャットのような入力欄がありますよね？

![](https://image.brain-market.com/store/12bf1e2384cfb114fd4c71a235e3e5b5.png)

ここに、あなたが作りたいワークフローやツールの概要を入力するんです。

今回は、動画講義でも実演した、最も基本的かつ強力なワークフローを作ってみましょう。

**「ニュースをリサーチしてブログ記事を作成するワークフロー」**

これをテーマにします。

入力欄に、こう打ち込んでみてください。

**「ニュースをリサーチしてブログ記事を作成するワークフロー」**

そして、Enterキーを「ッターン！」と気持ちよく叩いてください。

数秒待つと…

**バンッ！！**

画面上に、いくつかの箱（ノード）と、それらを繋ぐ線が、自動的に生成されて配置されます。

![](https://image.brain-market.com/store/0fb5c2e052d1105cb029dfa6c55dca66.png)

これ、初めて見た時は本当に感動しますよ。

「え、もうできたの？」って。

プログラミングの知識なんて1ミリもなくても、AIが勝手にシステムの骨組みを作ってくれるんです。

ただし、ここで一つ注意点があります。

**この「自動生成機能」、実は万能ではありません。**

シンプルな指示ならいい感じに作ってくれるんですが、複雑すぎる指示を出すと、エラーを吐いて止まることがよくあります。

僕が作りたいワークフローは入れても作ってくれないですね...w

これで一発で作れたら僕の存在意義がない！

とまでは言いませんが、まあどこかしらのところでやってくるでしょうね。

じゃあ学ばなくていいかというと、そうではありません。

このOpalは完全自動化のワークフローやAIエージェントを構築していく入り口になるからです。

これをAIにつくってもらっていては意味がないわけです。

話を戻しますが...

この機能ではシンプルなものしか作れないので、「最初はシンプルに作らせて、あとから手動で修正・拡張していく」というのが鉄則です。

まずは「ニュースからブログを書く」くらいのざっくりした指示で土台を作らせて、細かい調整は人間の手でやる。

これが一番賢い付き合い方です。

### 6-4. 「ノード」を理解しよう

さて、自動生成された図をじっくり見てみましょう。

![](https://image.brain-market.com/store/ff9fa5a4c9638355365fff789885d518.png)

ここで使われている用語と仕組みを完全に理解しておかないと、あとで必ず躓きます。

逆に言えば、これさえ分かればOpalは何も怖くありません。

**①ノード → 特定の処理をしてくれるもの**

画面にある四角い箱のことです。これを**「ノード」**と呼びます。

一つ一つのノードが、特定の処理を行います。

Opalでは、主に以下の3色のノードが登場します。

🟨**黄色のノード（インプット）**

![](https://image.brain-market.com/store/4319c9f1067aa6d768fa2338e453050a.png)

ここがすべての始まりです。ユーザー（あなた）が、テーマやキーワードなどの情報を入力する場所。

ここでは「 News Topic」と書かれたノードがこれにあたります。

ここに情報を入れることでワークフローが動き出すわけです。

**🟦青色のノード（プロセス）**

![](https://image.brain-market.com/store/6e0d7f907e3c47789bb412cd56c15f1e.png)

ここがAIが働く場所です。

この中には、AIへの具体的な指示（プロンプト）が格納されています。

Geminiがリサーチをしたり、文章を書いたり、要約したり、翻訳したりします。

Gemini以外にも、画像生成AIの「Nano Banana Pro」 や「Veo」もあります！

ここの詳しい話はこの後、がっつり解説していきますよ！

**🟩緑色のノード（Output）**

![](https://image.brain-market.com/store/18a5afed23b79e25a7b776b07fd30b18.png)

最終的に出来上がった成果物が表示される場所です。

ブログ記事の本文や、生成された画像などがここに出てきます。

ここからコピーして、WordPressやBrainに貼り付けるわけです。

### 6-5. ノードを繫げよう

ノードの間にある線もめちゃくちゃ重要です。

ただの線に見えますが、これは「情報の流れ」そのものです。

この線の向き（矢印）に従って、データが運ばれていきます。

例えば、「黄色のノード（テーマ入力）」から出た線が、「青いノード（リサーチ担当）」に繋がっているとします。

これは、「ユーザーが入力したテーマの情報を、リサーチのノードに運ぶよ」という意味です。

この繋がりもかなり重要なんですが、

なぜなら、各ノードのAIたちは、**「必要な材料がすべて自分の元に届くまで、絶対に仕事を始めない」**という頑固なルールを持っているからです。

生成された図をよく見てください。

![](https://image.brain-market.com/store/4bc1675ab66fcb2ad81e6547ab60c009.png)

「ブログ記事執筆ノード」には、「トピックの調査ノード」からの線と、「ニュースのタイトルノード」からの線の、両方が繋がっていますよね。

これは、記事を書くAIがこう言っているからです。

**「最初のお題（テーマ）だけ渡されても書けませんよ！ リサーチ結果も教えてくれないと、どう書けばいいか分からないでしょ！」**

すべての材料が届いて初めて、そのAIが仕事を始めます。

この**「情報の合流」と「順序」**をイメージできるかどうかが、複雑なワークフローを組む時の鍵になります。

### 6-6. EditorモードとAppモード

Opalには、大きく分けて2つの表示モードがあります。

画面上部のタブで切り替えることができますが、それぞれの役割を明確に分けて使いましょう。

**Editor（エディター）画面**

![](https://image.brain-market.com/store/4469be32bb9b0ce4169d2eb97b37181d.png)

今見ている、ノードや線をいじれる画面です。

ここでノードの場所や順序を組み替えたり、AIへの指示（プロンプト）を修正したりします。

基本的にはこの画面で作業することになります。

**App（アプリ）画面**

![](https://image.brain-market.com/store/2874ae68c88e84c4f91af1f3beb329d3.png)

完成したワークフローを、シンプルなツールとして使うための画面です。

タブを「App」に切り替えてみてください。

すると、さっきまでの複雑な配線図が消えて、めちゃくちゃスッキリした入力フォームだけが表示されたはずです。

![](https://image.brain-market.com/store/a00d6b103497dc5e6c3fdcdc169192e9.png)

入力欄と送信ボタンだけ。

これは、あなたが作ったツールを「日常的に使う時」のための画面です。

毎日ブログを書いてもらうときに、いちいち複雑なワークフロー図を見る必要はありませんよね？

必要なのは「テーマを入力する場所」と「スタートボタン」だけです。

**「Editorで作って、Appで使う」**

このサイクルを覚えておいてください。

そして、もしあなたがチームで動いているなら、使う人にはこの「App画面」だけを共有すればいいんです。

彼らは裏側の複雑な仕組みを知らなくても、あなたの作った最強のAIワークフローを使いこなすことができます。

### 6-7. 【実践】ワークフローを起動してみよう

それでは、AIに作らせた「ニュースブログ作成マシーン」を実際に動かしてみましょう。

せっかくなので、普段使いを想定して「App画面」に切り替えて操作します。

入力欄（Topic）に、何かテーマを入れてみましょう。

![](https://image.brain-market.com/store/9669f65e3758ce9fd1e0cf4b55fa5581.png)

今回は「AI自動化の最新トレンド」と入力しました。

皆さんも好きなテーマで構いませんが、今回はテストなので同じように入れてみましょう。

入力したら、右にある送信ボタン（紙飛行機のマーク）をポチッ！

さあ、ここからです。

画面の中央で、幾何学的な図形が美しく回転し始めます。

![](https://image.brain-market.com/store/b1ff813a8c5fb673b22a34b9c66d60d5.png)

**「Thinking...」**

この瞬間、僕はいつもワクワクします。

今、画面の裏側では、Geminiが猛烈なスピードで働いています。

Google検索をして、最新のニュース記事を読み漁り、重要なポイントを抜き出し、構成を練り、そして数千文字のブログ記事を執筆している…。

今までなら、あなたがブラウザのタブを10個も20個も開いて、あっちの記事を読み、こっちの記事を読み、コピペして、まとめて…と、数時間かけてやっていた作業です。

それを、あなたはコーヒーを飲みながら、ただ画面を眺めているだけでいい。

いや、眺めている必要すらありません。別の仕事をしていてもいいし、YouTubeを見ていてもいい。

自分が手を動かすのではなく、優秀なシステムに働かせる。

この快感を一度味わったら、もう昔の作業スタイルには戻れません。

### 6-8. 実際に動いているワークフローを見てみよう

処理が進んでいる最中に、あえて「Editor画面」に戻ってみてください。

App画面でただ待っているだけじゃつまらない。

裏側のEditor画面では、今まさに何が起きているのか？

それがリアルタイムで可視化されているんです。

Editor画面に戻ると、ノードの枠線がアニメーションしているのが分かるはずです。

![](https://image.brain-market.com/store/d3930d132ccc9c7a75b4353533cbcf23.png)

**青っぽい紫っぽい枠がグルグル回っているノード**

**「今、私が仕事中です！！」**と主張している状態です。

例えば「Deep Research」のノードが回っていたら、今まさにAIがネットサーフィンをして情報を集めている最中です。

この「情報の流れ」を目で見て確認できるのが、Opalの隠れた魅力です。

> **「お、今リサーチが終わって、執筆担当にバトンタッチしたな」**
> 
> **「あれ、ここで時間がかかっているな。検索キーワードが難しかったかな？」**

といった具合に、プロセスの進捗が手に取るように分かります。

これみているのも結構面白いです...w

そして、この「裏側を見る癖」をつけておくといいこともあって、エラーが起きた時に即座に対処できます。

Opalはまだ実験版なので、途中で止まることもあります。

その時、どのノードで止まったのかが一目瞭然なんです。

「あ、リサーチのノードでエラーが出たんだ」と特定できれば、そこだけ修正すればいいわけです。

### 6-9. ★超重要テクニック「再開」の方法

ここで、皆さんに必ず覚えておいてほしい、**最強の時短テクニックを伝授します。**

これを知っているか知らないかで、開発効率が10倍変わります。

Opalでワークフローを組んでいると、途中でエラーが出たりすることがよくあります。

例えば、リサーチは完璧だったのに、記事執筆の段階でエラーが出た、とか。

そんな時、多くの初心者は「最初からやり直して」しまいます。

もう一度テーマを入力して、最初のリサーチから全部やり直す。

**これ、絶対にやめてください。時間の無駄です。**

Google検索やDeep Researchには、それなりに時間がかかります。

せっかく集めた素晴らしい情報があるのに、それを捨ててまたゼロからリサーチさせるなんて、もったいなさすぎます。

そんな時は、エラーが出たノード、あるいはやり直したいノードについている「再生ボタン（▶）」を探してください。

ノードの右上あたりに小さく表示されています。

![](https://image.brain-market.com/store/1976ef1bced5581912742ad745f4b968.png)

これを押すと、どうなるか。

**「その前の工程までのデータは維持したまま、そのノードから処理をやり直す」**ことができるんです！

最初からやり直すのと、そこからやり直すのだと、どっちが早いか、明白ですよね？

**この「途中再開テクニック」は、Opalをうまく使っていくときの必須スキルです。**

エラーが出ても焦らない。「そこからやり直せるしいっか」と思える余裕を持ってください。

### 6-10. 生成された記事を見てみよう

そうこうしているうちに、すべてのノードの処理が終わったようです。

緑色のノード（Output）を見てみましょう。

App画面なら、結果がバーンと表示されているはずです。

![](https://image.brain-market.com/store/52b9e4526bd8b03d00fc78e383c03e2c.png)

今回のテーマは「AI自動化の最新トレンド」

出てきた記事を見てみると…

- **タイトル ⇒** 「AI自動化の新時代へ：2025年以降の主要トレンドとビジネス変革」
- **導入 ⇒** 自律型AIエージェントがいかにして業務を変えるか
- **見出し1 ⇒** 24時間365日稼働するデジタル労働力の衝撃
- **見出し2 ⇒** マルチモーダルAIの進化（動画・音声認識）
- **事例 ⇒** パナソニックコネクトの「PX-AI」導入事例など、具体的な企業名入り
- **結論 ⇒** イノベーションと信頼の共存

…どうですか、このクオリティ。

ただ「AI自動化の最新トレンド」と一行入力しただけで、ここまで網羅的で、しかも具体的な事例まで入った記事が一発で生成されました。

これは、単純にChatGPTに「AIトレンドの記事書いて」とチャットするのとは訳が違います。

その決定的な違いは、「Deep Research（深掘り調査）」という工程を挟んでいることにあります。

普通のチャットAIは、ディープリサーチまではやってくれないわけですよ。

これが、「ワークフロー型」の威力です。

### 6-11. 画面操作の仕方

最後に、地味だけど重要な操作テクニックをいくつか紹介しておきます。

ワークフローが複雑になってくると、画面からはみ出してしまって「あれ、あのノードどこ行った？」と迷子になることがよくありますからね。

**①ズームイン/アウト**

![](https://image.brain-market.com/store/e2bd354747f244aae522cd93815b1a73.png)

Macをお使いの方は**Commandキー（⌘キー）**

Windowsをお使いの方は**Ctrlキー**

を押しながら、マウスホイールを回すか、画面右下の「+」「-」ボタンで拡大縮小できます。

全体像を把握したい時は縮小、細かく見たい時は拡大。

基本中の基本ですが、スムーズにできるとストレスが減ります。

**全体表示（Fit to Screen）**

![](https://image.brain-market.com/store/4f7ea5339b70edf7f3f535242706097e.png)

画面右下にある「四角い枠のようなアイコン」を押すと、作ったワークフロー全体が画面に収まるように、一瞬でズーム倍率を調整してくれます。

作業中に迷子になったら、とりあえずこれを押しましょう。ホームポジションに戻れます。

**画面移動（パン）**

![](https://image.brain-market.com/store/7c83d8c5d2cd6f1aad86dc7b151ef9f3.png)

これ、意外と知らない人が多いんですが、**「スペースキー」と「左クリック」を押しながらマウスをドラッグ**してみてください。

カーソルが「手のひらマーク」に変わり、画面を掴んでぐいぐい動かせます。

デザインツールを使っている人にはお馴染みの操作ですが、Opalでもこれが使えます。

いちいちスクロールバーを動かすよりも断然早いです。

左手親指は常にスペースキーの上に。これがプロの構えです...w

いかがでしたか？

最初は「謎の英語だらけのツール」に見えていたOpalが、少し身近な「相棒」に感じられるようになったのではないでしょうか。

今回やったことを整理します。

1. **OpalはGoogleの「実験場」多少のバグは愛嬌だと思って使い倒せ。**
2. **テンプレはお手本。「Create New」で自分のワークフローをゼロから築け。**
3. **「AI自動生成」で土台を作り、手動でカスタマイズせよ。**
4. **「Editor」は設計する場所、「App」は普段使いの場所。使い分けろ。**
5. **ノードと流れを支配せよ。**
6. **エラーが出たら「途中再開（Playボタン）」でスマートに時短せよ。**

これができれば、Opalの基礎操作はばっちりです！

今まで、ChatGPTやGeminiに、毎回毎回チャットで「これやって」「あれやって」と指示を出していたあなた。

今日からあなたは違います。

AIを適材適所に配置し、ラインを組んで、自分がほかの作業をしている間も自動で働かせるワークフローを手に入れたわけです。

今回作ったのは「ニュースからブログを書く」という、シンプルな一本道のラインでした。

しかし、これはほんの序章に過ぎません。

一本道ではなく、並列処理、分岐、そして修正…。

Opalのフル活用はここからです。

## 7\. 【基礎知識】ノードの役割を理解しよう

さて、ここからはかなり具体的な内容へと移っていきます。

第4章で出てきた「ノード」というものについて、徹底解説していきます。

![](https://image.brain-market.com/store/c933647bf46d8989059515646aa288d3.png)

- Opalではどんなデータが生成できるのか？
- それぞれのノードで何ができるのか？
- ノードごとの役割と使い分け
- 高度な設定の使い方

こういったことについて一緒に見ていきましょう。

この章に関しても、50分弱の動画をご用意していますので、そちらで学んでいただくのがおすすめです。

![](https://img.youtube.com/vi/9WwLmMj_pMc/mqdefault.jpg)

時間がない方や、移動中にインプットしたい方は文字とスクリーンショットでもご説明していますので、お好きな方でどうぞ。

テキストの箇所では動画内で話していないけど、追加で押さえておくべきポイントなどについても追記していますので、動画を見て復習としてテキストを読んでいくというのが一番身につくかと思います。

ということで、さっそく始めていきましょう！

### 7-1. インプットノードについて

まず最初は、基本中の基本。 **「User Input（ユーザーインプット）」ノード**です。

![](https://image.brain-market.com/store/3566316d0325a9749102bd05476a8b5e.png)

画面上でいうと、あの**黄緑色のノード**ですね。

> **「え、これってユーザーが文字を入力するだけの場所でしょ？」**
> 
> **「解説するほどのことある？」**

そう思いましたか？ 甘いです。実はここにも、多くの人が知らない、しかし知っているだけでAIの精度を劇的に向上させる「裏技」が隠されているんです。

まず大前提として、このノードがないとワークフローは何も始まりません。 あなたがAIに対して「これについて調べて」「この商品を分析して」と指示を出すための、最初の入り口だからです。

どんなに複雑なワークフローを組む場合でも、**一番最初は絶対にこの黄緑色のノード（User Input）が必要**になります。いきなり青色のGenerateノード（AI生成）から始めることはできません。これは鉄の掟です。

ここからちょっとしたコツなんですが、

実はこのUser Inputノード、**ワークフローの「途中」に挟むことができる**って知っていましたか？

![](https://image.brain-market.com/store/aa708ce0ac49e499baeb7b3583b50a6a.png)

これを知っているかどうかで、作れるワークフローのレベルが天と地ほど変わります。 多くの人は「最初に入力して、あとはAIに丸投げ」しがちですが、それだとAIが変な方向に暴走した時に修正が効きません。

そこで使うのが、このテクニックです。 具体的には、以下のようなフローを組みます。

1. **【Generate】AIに調査させる  
	**まず最初のノードで「最近のAIトレンドニュースを10個ピックアップして」とAIに指示します。
2. **【User Input】ユーザーが選別する（ここにInputノードを挟む！）  
	**AIが出してきた10個のニュースを見て、あなた自身が「お、これは面白そうだな」「これは使えないな」と判断します。そして、**途中に挟んだUser Inputノード**に、深掘りしたいニュースの番号（例えば「1番と3番」など）を入力するのです。
3. **【Generate】AIが深掘りする  
	**次のノードでは、あなたが選んだ番号のニュースだけを対象に、さらに詳しくリサーチして記事を作成させます。

この構成の何がすごいか分かりますか？

AIに全てを丸投げするのではなく、プロセスの途中で**「人間の判断」を介在させることができるんです。**

これを専門用語で**「Human in the Loop（ヒューマン・イン・ザ・ループ）」**と言ったりします。

AIは万能ではありません。時には的外れな情報を拾ってくることもあります。 でも、間にこのUser Inputノードをクッションとして挟むことで、

**「この5つの候補の中から、君が良いと思うものを1つ選んでね」**

**「この構成案でOK？ 修正があるなら指示して」**

みたいな感じで、**AIと対話しながら進めるワークフロー**を組むことができるんです。

この「確認工程」を入れるだけで、最終的なアウトプットのクオリティは確実に担保されます。 「AIに任せたけど、なんか微妙な記事ができちゃった…」という経験がある方は、ぜひこの「中間インプット」を試してみてください。

これだけで、成果物の質がガラッと変わりますよ。

### 7-2. ジェネレートノードの全種類 徹底解説

さて、次はいよいよメインディッシュ。

AIに実際に仕事をさせる「Generate（ジェネレート）」ノードです。 あの青色のノードですね。

![](https://image.brain-market.com/store/24e15d59f091e373d2f916375aecd3c4.png)

ここをクリックすると、ズラッと英語のモデル名が並んでいて、「どれを使えばいいの！？」とパニックになった経験はありませんか？

「Gemini 3 Pro」とか「Flash」とか「Plan & Execute」とか…。

一つひとつ、僕の実体験と検証データをベースに解説していきます。

それぞれのモデルには明確な「得意・不得意」があります。これを理解して使い分けることが重要です。

**【基本の3モデル】迷ったら「Pro」を選べ**

まずは、テキスト生成の基本となる3つのモデルから見ていきましょう。

- **Gemini 3 Pro**
- **Gemini 2.5 Pro**
- **Gemini 2.5 Flash**

![](https://image.brain-market.com/store/619e9b92838fcb6c184df2e604cb1bfb.png)

結論から言います。 基本的には**「脳死でGemini 3 Pro」**を選んでおけばOKです。

なぜなら、現状のモデルの中で**精度が段違いに高い**からです。

思考力、日本語の文章力、文脈の理解度、どれをとってもトップクラス。あえて性能の低いモデルを選ぶ理由はほとんどありません。

以前のモデル（2.5 Pro）も優秀でしたが、3 Proが使える環境なら迷わずこちらを使いましょう。 もちろん、まだ3 Proが対応していない機能がある場合は2.5 Proを使うことになりますが、基本は「Pro」一択です。

では、「Flash」はどういう時に使うのか？

**Gemini 2.5 Flash**の特徴は、その名の通り**「速さ」と「軽さ」**です。

思考の深さよりも、とにかくレスポンスの速さが求められる場面。例えば、簡単な翻訳や、短い挨拶文の作成など、AIに深く考えさせる必要がないタスクであれば、Flashの方がサクサク動いて快適です。

**【Fujinの運用ルール】**

**精度重視・複雑なタスク** → **Gemini 3 Pro**（基本はこれ）

**速度重視・単純作業** → **Gemini 2.5 Flash**（※対応したらGemini 3 Flash）

ちなみに、これらのモデルには今のところ、目立った**「1日あたりの使用回数制限（Daily Limit）」**のような注意書きはありません。

後ほど紹介する画像生成や動画生成には回数制限があるものも多いですが、この基本テキストモデルに関しては、かなり自由に使い倒せる状態です。今のうちにガンガン触って、感覚を掴んでおきましょう。

==※2025年12月23日時点ではまだGemini 3 Proは使えません。使おうとするとエラーが出ます。==

**「Plan & Execute」がヤバすぎる**

これ、最近僕が一番感動した機能です。 リストの中に「Plan & Execute with Gemini 2.5 Flash」という見慣れない名前のやつがいませんか？

![](https://image.brain-market.com/store/3ca04222e2c433e98c79e59664137ffe.png)

直訳すると「計画して、実行する」

これこそが、これからのAIエージェントの基本形になる動きです。

普通のAIだと、「〇〇について調べて」と言ったら、いきなり答えを出そうとしますよね？ でもこのノードは違います。

1. **Plan（計画）  
	**「まず何を調べるべきか？」「どの順番で作業を進めるか？」を自分で計画します。
2. **Execute（実行）  
	**その計画に従って、ウェブ検索（Web Search）などを駆使して情報を集め、タスクを実行します。

まさに、「優秀なアシスタント」のような動きをしてくれるんです。 内部的には「Gemini 2.5 Flash」が動いているようですが、その挙動はFlashとは思えないほど賢いです。

**【実証実験】「調光式サングラス」の販売戦略を作らせてみた**

実際に僕が試した例を紹介しましょう。 「調光式のサングラス（フォトクロミック・サングラス）」という商品をテーマに、競合調査と販売戦略を立案させてみました。

インプットは「調光式サングラスについて調べて」というシンプルなもの。

![](https://image.brain-market.com/store/ef6a41910f73f11a02367e5efe961100.png)

すると、どうなったと思いますか？

![](https://image.brain-market.com/store/fbfb7dba48897e784a3d21d252e13e6c.png)

まず、ノードの上に「％（パーセンテージ）」が表示され始めました。

「今、45％進んでます…」「60％…」みたいな感じで、進捗が見えるんです。

これ、最近のアップデートで実装された神機能なんですが、以前はただ「Thinking...（考え中）」と出るだけでいつ終わるか分からなかったので、精神衛生上めちゃくちゃ良いです...w

そして、待つこと数分。 出力されたレポートを見て、僕は腰を抜かしました。

出てきた情報の質と量が、半端じゃなかったんです。

![](https://image.brain-market.com/store/32ef9ab96e75b161619f45c840b63310.png)

- **技術解説  
	**　調光レンズの仕組み（エレクトロクロミック技術やスマート調光など）の詳細な解説。
- **競合分析  
	**　Ray-Ban、Tom Ford、Oakleyといった有名ブランドだけでなく、あまり知られていないニッチなブランドまで網羅。
- **USP分析  
	**　それぞれのブランドが何を「売り」にしているか（独自の強み）の分析。
- **販売チャネル  
	**　公式サイト、ECモール、実店舗など、どこで売られているかの調査。
- **ターゲット層  
	**　どんな人が買っているのかのペルソナ分析。
- **マーケティング提案  
	**　具体的にどう売ればいいかの戦略提案。

これらが、なんと**約2万5000文字**。

![](https://image.brain-market.com/store/e206a58969dbef9a9dad79c0390ff30b.png)

もう一度言います。**2万5000文字**です。

人間がこれだけのリサーチをして、情報を整理して、2万文字超えのレポートを書こうと思ったら、どれくらいかかりますか？

丸3日？ いや、1週間かかるかもしれません。 それが、**トイレに行っている間に終わっている**んです。

しかも、単にネット上の情報をコピペして羅列するだけじゃなく、「Web Search」機能も組み込まれているので、検索結果に基づいた「提案」までしてくれている。

ただのリサーチツールを超えて、コンサルタントのような働きをしてくれます。

この「Plan & Execute」、ビジネスのリサーチや、ブログ記事の構成案作り、競合分析には、革命的な威力を発揮します。

これが無料で使えるなんて、正直どうかしていますw

皆さんもぜひ、自分の商品や興味のあるテーマで試してみてください。2万文字のレポートが出てくる衝撃、ぜひ味わってほしいです。

**Fujinが作ったPlan & Executeのワークフローここから使えます👇**

[https://opal.google/?flow=drive:/1LO16a2expUAYFUNHeFwG3FpH7HfcxgRj&shared&mode=app](https://opal.google/?flow=drive:/1LO16a2expUAYFUNHeFwG3FpH7HfcxgRj&shared&mode=app)

**「Deep Research」の落とし穴と、最強の回避策**

さて、似たような機能に**「Deep Research（ディープリサーチ）」**というものがあります。 「Deep Research with Gemini 2.5 Flash」という名前の通り、深く調査するためのノードです。

![](https://image.brain-market.com/store/7c371ba24cf0636347abfd05feb79413.png)

名前だけ聞くと「Plan & Executeより凄そう！」と思うかもしれませんが、正直に言います。

**僕はあまり使っていません。**

なぜか？ 理由は2つあります。

1. **モデルが「Flash」であること  
	**裏側で動いているのが「Gemini 2.5 Flash」なので、リサーチの速度は速いんですが、出てくるアウトプットの「考察の深さ」や「日本語の質」がちょっと物足りないんです。3 Proに比べると、どうしても浅い。
2. **機能が「まとめ」に特化していること  
	**Plan & Executeのように「提案」をしてくれるわけではなく、あくまで「情報を集めてまとめる」ことがメインです。

もちろん、ざっくりとした概要を知りたい時には便利ですが、僕たちクリエイターやマーケターが求めているのは、もっと鋭いインサイトですよね。

**【Fujin流：Deep Researchの自作方法】**

じゃあどうするか？ 僕は、**Gemini 3 Proを複数並列で繋いで、自分で「最強のリサーチマシーン」を作っています。**

![](https://image.brain-market.com/store/b5b25d9dde040b4a76cf85cb408dfb04.png)

「え、自分で作るの？」と思うかもしれませんが、簡単です。 やり方はこうです。

1. **計画ノード（Gemini 3 Pro）  
	**最初に「このテーマを多角的に調査するための5つの切り口を考えて」と指示します。
2. **並列処理ノード（Gemini 3 Pro × 3〜5つ）  
	**計画ノードから線を分岐させて、複数のGemini 3 Proを同時に走らせます。
	- **ノードA**「日本の最新ニュースを検索してまとめて」
	- **ノードB**「英語圏のトレンド情報を検索してまとめて」
	- **ノードC**「中国語の市場動向を検索してまとめて」
	- **ノードD**「SNSでの口コミや評判を検索してまとめて」
3. **統合ノード（Gemini 3 Pro）  
	**最後に、これら全てのノードの出力を一つのノードに集めて、「集まった情報を統合して、最強のレポートを作成して」と指示します。

こうやって、Gemini 3 Proという最高峰の頭脳を贅沢に並列で走らせた方が、公式のDeep Research機能よりも圧倒的に質が高く、マニアックな情報が集まります。

「並列処理」は時短にもなるし、視点が偏らないので精度も高い。

この**「並列Gemini 3 Pro」**という構成は、テストに出るレベルで重要です...w

公式の機能に頼るだけでなく、ノードを組み合わせて自分だけの機能を創り出す。これこそが、Opalの醍醐味なんです。

**サムネイル量産システムの構築**

まずは、視覚に訴える「画像生成」です。 ここで選択肢に出てくるのは、主に以下のモデルです。

注意点として画像生成AIには「Daily Limit（1日の生成回数制限）」がかかります。

- **Imagen 4**
- **Nano Banana（Gemini 2.5 Flash Image）**
- **Nano Banana Pro（Gemini 3 Pro Image）**

![](https://image.brain-market.com/store/9255cb3f92f3b2414f26e56e428dab04.png)

**【Imagen 4の評価】**

Googleが誇る高画質モデルです。

ここぞという「決めの一枚」を作る時には良いですが、大量生産には向かないかもしれません。

**【Nano Banana Proの衝撃】**

僕が推したいのは、この「Nano Banana（ナノバナナ）」です。 名前はふざけているように見えますが、実は「Gemini 2.5 Flash」をベースにした軽量・高速な画像生成モデルで、実用性が非常に高いんです。

さらに、「Nano Banana Pro（ナノバナナプロ）」はもっとヤバいです。

特に素晴らしいのが、「テキストの生成能力」です。 例えば、YouTubeのサムネイルを作る時、「どの構図がクリックされるか分からないから、何パターンか試したい」という悩みはありませんか？

今回テンプレートとして配布もしている音声データからさまざまなコンテンツを生み出すワークフローの中で「サムネイル自動量産システム」を構築していて、

ボタンをワンクリックするだけで、**別パターンのサムネイル候補が一気に3枚生成されます。** あとは、その中から一番いいものを選ぶだけ。

**音声生成（AudioLM）**

次は、テキストを音声に変換する「AudioLM」です。 これがあれば、自分の声を使わずにコンテンツを作ることができます。

![](https://image.brain-market.com/store/2a80f088f8d51798b671bd73405946d4.png)

使い方は非常にシンプルですが、ワークフローに組み込むと化けます。

**【全自動ポッドキャスト制作フロー】**

僕が実験的に組んでいるフローはこんな感じです。

1. **【Generate】リサーチ＆ネタ出し（Gemini 3 Pro）** 「最新のAIニュースから、ポッドキャストで話すべきトピックを3つ選んで」
2. **【Generate】台本作成（Gemini 3 Pro）** 「そのトピックについて、3分程度で話せるフリートーク風の台本を書いて。口語体で、少しユーモアも交えて」
3. **【Generate】音声化（Audio LM）** 生成された台本を読み込ませて、音声データ（WAV/MP3）を出力。

これだけで、**「リサーチから収録まで」が全自動で完了**します。 もちろん、イントネーションなどは完璧ではありませんが、ショート動画のナレーションや、サクッとニュースを聞くための自分用ラジオとしては十分なクオリティです。

**注意点**

このノードには明確に「Audio generation has a daily limit（1日あたりの生成制限あり）」という注意書きがあります。 長時間の音声を何本も作ろうとすると制限に引っかかる可能性があります。

これと僕のプレミアムリスナーで配布しているスライド生成Gemと組み合わせると、簡単にYouTubeの動画が作れちゃいます。

### 7-3. 【特典】プレミアムリスナー限定のFujin式スライド生成Gemを配布します

今回特別にFujin式スライド生成Gem ver.1をあなたにプレゼントします！

![](https://image.brain-market.com/store/a1f53009c04b271e18ffca3a26204258.png)

ブログ記事などをインプットして、Canvas機能をオンにすれば一撃でスライドが生成されます👇

[https://gemini.google.com/gem/1kiZMAxOn0gxg1r1w3MiidDiI8H1vMXkf?usp=sharing](https://gemini.google.com/gem/1kiZMAxOn0gxg1r1w3MiidDiI8H1vMXkf?usp=sharing)

ぜひ活用してください。

**動画生成（Veo）**

話題の動画生成AI「Veo」も、このノードから利用可能です。 SoraやKlingといった強力なライバルがいますが、Google純正の環境で使えるのは大きなメリットです。

![](https://image.brain-market.com/store/c66ec6f60006097021a3f25f512ba8ea.png)

ただし、現状（執筆時点）での評価は「まだ実務レベルにはもう一歩」といったところ。

- **生成できる秒数が短い**
- **回数制限が厳しい（こちらもDaily Limitあり）**
- **動きの制御が難しい**

「テキストからいきなり長編映画を作る」なんて夢のようなことは、まだできません。 しかし、使い道はあります。

**【おすすめの活用法】ブログのアイキャッチ動画**

ブログ記事やnoteの冒頭に、静止画ではなく「ちょっと動くGIFのような動画」があると、滞在時間が伸びますよね。

Gemini 3 Proで記事を書かせた流れで、「この記事の内容を象徴するような、5秒程度の動画クリップを作って」とVeoに指示を出す。

これなら、制限内でも十分に活用できますし、コンテンツの質を一段階上げることができます。

特に、Gemini 3 Proと組み合わせて「動画生成用のプロンプト」を先に作らせてからVeoに投げるのがコツです。

「夕暮れ時のシネマティックなエモい街並み、夕日が水たまりに反射している、シネマティックなライティング」のように、具体的かつ視覚的な言葉をAIに用意させることで、映像クオリティが段違いに変わります。

**音楽生成（Lylia）**

これ、意外と知られていない機能なんですが、**「Lylia（リリア）」というモデルがあります。**

これは「楽器の音楽（インストゥルメンタル）」を生成するAIです。 ボーカルなしのBGM専用ですね。

動画制作をしていると、「著作権フリーのいい感じのBGM」を探すのに何時間もかかったりしませんか？ Lyliaを使えば、その手間がなくなります。

> **「この動画の雰囲気に合わせて、悲しげだけど希望を感じさせるピアノ曲を作って」**
> 
> **「アップテンポで疾走感のある、テクノポップ風のBGMを作って」**

このように指示するだけで、**世界に一つだけのオリジナルBGM**が生成されます。

Suno AIなどの歌モノ生成AIが流行っていますが、YouTubeのバックグラウンドで流すなら、歌のないLyliaの方が使い勝手が良い場合も多いです。

Googleが音楽生成モデルを出していること自体を知らない人も多いので、これを使っているだけで「おっ、こいつ詳しいな」と思われるかもしれません...w

### 7-4. アウトプットノードの選び方と落とし穴

AIに仕事をさせたら、最後はその結果を受け取る必要があります。

それが「Output（アウトプット）」ノード。**緑色のノード**です。

![](https://image.brain-market.com/store/ecb5d6d3088a82cb191ccfe75dde3ff5.png)

「ただ結果を表示するだけでしょ？」

いや、ここにも知っておかないと時間を無駄にする「落とし穴」があります。

**Manual Layout（マニュアルレイアウト）**

一番シンプルな形式です。

![](https://image.brain-market.com/store/bf238affc1676d86bb89dace0a93c9ff.png)

AIが生成したテキストが、装飾なしでズラズラっと表示されます。

「デザインなんていらない、とにかくテキストデータだけくれ！」という場合や、ここからコピーして別のエディタに貼り付ける前提なら、これで十分です。

ただ、長文になると読みづらいので、確認用としては少しストレスが溜まるかもしれません。

**【Fujinのイチオシ】Webpage with Auto Layout（ウェブページ・ウィズ・オート・レイアウト）**

**結論から言うと、基本はこれ一択でOKです。**

僕も9割以上これを使っています。

![](https://image.brain-market.com/store/4ff9b8e7986bb154d25a79fb7b02e3cd.png)

何がすごいって、AIが出力したテキストを解析して、勝手に「いい感じのWebサイト風デザイン」に整形してくれるんです。

先日、このノードのデザイン機能にサイレントアップデートが入りました。 例えば、ニュースまとめを作らせたら…

- **見出し**が綺麗にデザインされ
- **画像**が適切な位置に配置され
- **アコーディオン**（クリックで開く詳細）がついたり

まるで「プロが作ったブログ記事」のような見た目で出力されるんです。

前まではこんな感じのデザインでした👇

![](https://image.brain-market.com/store/bdd06e05007b21966b66961032ffaa2c.png)

さらに最強なのが、「タブ機能」です。 例えば、先ほどの「サムネイル量産システム」のアウトプットを一つにまとめるとします。

- **タブ1：** 生成されたブログ記事本文
- **タブ2：** その記事を宣伝するためのX（旧Twitter）ポスト案
- **タブ3：** 生成されたサムネイル画像一覧

これらを一つの画面で、タブを切り替えながらスマートに確認できるんです。

![](https://image.brain-market.com/store/cb4efe985e483a6d3663baf1825fa474.png)

テンション上がりませんか？ この画面をそのままスクショしてSNSに投稿するだけでも、「AIですごいもの作りました！」という実績アピールになります。

自動でアニメーションがついたりもするので、見ていて楽しいのもポイントです。

**Google連携系（Docs / Slides / Sheets）**

Googleのエコシステムならではの連携機能ですが、現時点では「要注意」です。 僕の実体験ベースで、ぶっちゃけた評価をお伝えします。

![](https://image.brain-market.com/store/af5a0caf88afb384f2836d4541158f40.png)

**① Save to Google Docs（ドキュメント保存）**

便利そうに見えますが、**最近エラーが頻発しています。** 保存されたはずなのにファイルの中身が空だったり…。

![](https://image.brain-market.com/store/69ef752673cb500e7a7a7fb6b257a8fb.png)

「保存されてると思ったらされてなかった！」という悲劇を防ぐためにも、現状では**Web Page Layoutで出力して手動でコピペ**した方が、確実かつ安全です。

**② Save to Google Slides（スライド保存）**

「これでプレゼン資料作りから解放される！」と思った方、ごめんなさい。

期待して使うと、ガッカリします。 生成されるのは、「真っ白な背景に、黒い文字が箇条書きされただけの、超シンプルなスライド」です。

デザイン性は皆無。画像の配置も適当。 結局、後から手直しする手間を考えると、今のところ実用レベルではありません。

※ちなみに、僕のBrain教材の特典で「スライド生成専用のGem」を配布しているので、そちらを使った方が100倍綺麗なスライドが作れます。気になる方はチェックしてみてください！（6-3 【特典】プレミアムリスナー限定のFujin式スライド生成Gemを配布します に記載してあります！）

**③ Save to Google Sheets（スプレッドシート保存）**

これは、用途によっては使えます。 **データ分析系**のタスクですね。

例えば、「競合商品100個の価格と特徴をリストアップして」といった指示で、行ごとにデータを整理して保存していく処理なら便利です。

**【Outputノードの表示優先順位の謎】**

Outputノードを複数並べた場合（例えば、テキスト出力と画像出力を同時に行う場合）、プレビュー画面にはどれが表示されるのか？ これ、結構悩みますよね。

**僕の検証結果では、「一番下のノード」または「処理が最後に終わったノード」が優先して表示される傾向にあります。**

もし「あれ？画像が表示されないぞ？」と思ったら、ノードの配置を下に動かしてみるか、ちゃんとタブ切り替え機能がついているか確認してみてください。

**「Asset Node」の活用術**

最後は、AIに専門知識や素材を与える「Asset（アセット）」ノードです。

![](https://image.brain-market.com/store/f961ba4b306834b77df45f56134ab75c.png)

AIは賢いですが、あなたの会社の内部事情や、手元の独自データまでは知りません。 そこで、このAssetノードを使って情報を注入してあげるわけです。

ここにも、「これを知らないと損をする」というポイントがあります。

**Upload File と My Drive**

**①Upload File（PCに入っているファイルのアップロード）**

PDFやテキストファイルを直接アップロードする方法です。 基本中の基本ですが、僕はあまり使いません。 なぜなら、「ファイルの中身を更新したら、またアップロードし直さないといけないから」です。

マニュアルなどの資料は頻繁に更新されるもの。その都度アップロードし直すのは、単純に面倒ですよね。

**② From My Drive（Googleドライブ連携）** **【Fujinの絶対的なおすすめ】**

そこでこれです。迷ったらこれ一択です。 Googleドライブに入っているドキュメントを指定して読み込ませます。

**これの何が最強かと言うと、「同期」されるんです。**

例えば、Googleドキュメントで「自社商品の仕様書」を作っておいて、それをAssetとして読み込ませるとします。 仕様に変更があった時、元のGoogleドキュメントを書き換えれば、**AI側の知識も勝手にアップデートされる**んです。

わざわざファイルを上げ直す必要がありません。 常に最新の情報をAIに参照させたいなら、絶対にGoogleドライブ連携を使うべきです。

**ただし、ここはエラーが発生することもかなり多いので、そういう場合はPDFにしたりなどして対応しています。**

**YouTube連携**

これ、意外と使っていない人が多いんですが、めちゃくちゃ便利です。 Assetノードの「YouTube」タブに、**動画のURLをペーストするだけ**。

![](https://image.brain-market.com/store/bdb90de32f96494d541f635dcdab72b9.png)

これだけで、**その動画の中身（字幕データなど）をAIが読み取ってくれます。**

> **「この1時間の解説動画をもとに台本作成して」**
> 
> **「この対談動画の内容を元に、ブログ記事を書いて」**

なんてことが、URLを貼るだけで一瞬でできちゃうんです。 わざわざ文字起こしツールを使う必要すらありません。

**【やらないほうがいいこと】動画ファイルの直接アップロード**

逆に、おすすめしないのが「動画ファイル（mp4など）の直接アップロード」です。 「File Upload」から動画ファイルを上げることもできるんですが、**処理がめちゃくちゃ重くなる**上に、精度の向上も微妙です。

動画の内容を理解させたいなら、一度YouTube（限定公開でもOK）にアップしてURLを貼るか、テキストデータに変換してから読み込ませる方が、圧倒的にスムーズです。

**Drawing（ドローイング）**

画面にお絵かきができる機能です。

![](https://image.brain-market.com/store/901bcba0ed9ee4745af9a6bb955c494d.png)

…正直、「何に使うのこれ？」って感じです...w

色が変えられたり、保存できたりと無駄に高機能なんですが、今のところ実用的な使い道は見つかっていません。

もし面白い使い道を見つけた方がいたら、ぜひ教えてください...！

### 7-5. 【コラム】3分でわかる！「RAG（ラグ）」ってよく聞くけど何？

![](https://image.brain-market.com/store/853c1e3307e464aae6c4a2b02d7dde55.png)

さて、この章で「Asset Nodeを使って情報を注入する」という話をしましたが、ここで一つ、最近AI界隈でよく耳にする**「RAG（ラグ）」**という言葉について解説しておきたいと思います。

「RAG…？ ラグ？ カーペットのこと？」

と思った方、安心してください。めちゃくちゃ簡単に説明します。

実は、このOpalというツールの「Asset Node」を使うことこそが、**まさに「RAG」そのもの**なんです 。

**AIは「知ったかぶり」の天才**

まず、普通のChatGPTやGeminiを想像してみてください。 彼らはインターネット上の膨大なデータを学習していますが、完璧ではありません。

知らないことを聞かれると、平気な顔をして「嘘」をつくことがあります（これをハルシネーションと言います）

また、当然ですが**「あなたの会社の社内ルール」や「昨日会議で決まったこと」**なんて、AIは知りようがありませんよね。

**RAG ＝ 「AIが知らない情報」を渡すこと**

そこで登場するのが **RAG（Retrieval-Augmented Generation）** です。 日本語に訳すと「検索拡張生成」なんて難しい言葉になりますが、わかりやすく解説します。

- **普通のAI  
	**何も見ずに、自分の記憶力だけでテストを受ける。 → うろ覚えの知識だと、間違える可能性がある。さらにあなた独自の知識についての質問だったら答えられない。
- **RAGを使ったAI  
	「教科書」を見ながら**テストを受ける。 → 手元の資料に答えが書いてあるので、正確に答えられる。

この「教科書」にあたるのが、Opalにおける**「Asset Node（アップロードしたファイルやGoogleドライブ）」**なんです。

**なぜOpalのRAGの再現は最強なのか？**

通常、このRAGのシステムを自分で作ろうとすると、プログラミングの知識が必要だったり、データベースを構築したりと、かなり面倒な作業が必要です。

でも、Opalならどうでしょう？ **「Asset Node」にGoogleドライブのファイルを指定して、線を繋ぐだけ。**

たったこれだけで、

> **「自社のマニュアルを完璧に記憶したAI」**
> 
> **「過去の議事録を全て把握しているAI」**

といった、**あなた専用の最強AI**が爆誕するわけです。

この感覚を掴むと、Asset Nodeの使い方が一気に面白くなるはずです。ぜひ、Googleドライブにあなたならではの情報を詰め込んで、AIをパワーアップさせましょう！

### 7-6. 【まとめ】ノードを制する者は、AI時代を制す

![](https://image.brain-market.com/store/9b6b6836b67155d844c986627ca792fd.png)

はい、ということでこの章ではOpalの「全ノード」を一挙に解説してきました。

長くなったので、特に重要なポイントだけおさらいしましょう。

1. **User Inputは「途中」に使え！  
	**最初に置くだけじゃなく、プロセスの途中で挟んで「Human-in-the-Loop」を実現。これでAIの暴走を防ぎ、精度が爆上がりする。
2. **Generateは「Gemini 3 Pro」を信じろ！  
	**基本はこれ。リサーチなら「Plan & Execute」の2万5000文字出力がヤバい。Deep Researchは自作の並列処理で再現可能。
3. **マルチモーダルで「制作会社」になれ！  
	**「Nano Banana Pro」でサムネ量産、「AudioLM」で音声化。これらを組み合わせれば、一人でコンテンツを量産できる。
4. **Outputは「Web Page Layout」が最強！  
	**見やすいし、テンションが上がる。Docs連携などのバグには気をつけろ。
5. **Assetは「Googleドライブ」で同期しろ！  
	**ファイルをいちいち上げ直すな。常に最新情報をAIに食わせろ。YouTubeのURL貼り付けも活用しろ。

どうでしょうか？

なんとなく使っていたノードのポテンシャル、感じていただけたでしょうか。

そして実は… 今回紹介しきれなかった「アドバンスドセッティング（詳細設定）」など、さらにマニアックで強力な機能もまだまだあります。

次章ではそちらの解説をしていきます。

## 8\. 【応用知識】ノードの詳細設定を使いこなそう

実は、Opalには**「Advanced Settings（詳細設定）」**という、普段は隠されている設定項目が存在します。

![](https://image.brain-market.com/store/d2961248df71c929171734ccc5a998c7.png)

ここを理解し、使いこなせるかどうかで、ワークフローの出力できるクオリティに差が付きます。

正直なところ、僕自身も最初は「デフォルト設定で十分でしょ」と思っていました。

しかし、この詳細設定の中身を一つひとつ検証していくうちに、その考えが間違いだったことに気づかされました。

この章では、Opalの各ノードに隠された「詳細設定」を徹底的に深掘りしていきます。

動画で学びたい方はこちらからどうぞ。

![](https://img.youtube.com/vi/hWn6nXd_ABI/mqdefault.jpg)

それでは、Opalのノードの詳細設定について一緒にみていきましょう！

### 8-1. 「Advanced Settings（詳細設定）」とは？

まず大前提として、この「Advanced Settings」がどこにあるのかを確認しておきましょう。

Opalのキャンバス上に配置した各ノードをクリックすると、右側に設定パネルが開きますよね。その一番下、見落としそうな場所にひっそりとあるのが「Advanced Settings」です。

![](https://image.brain-market.com/store/e411e981199de8f51566324b1cdaef48.png)

ここをクリックして展開することで、初めて詳細なパラメータ設定が可能になります。 一度展開しておけば、他のノードに移っても開いた状態が維持されるので、Opalを開いたらまずはここをクリックする癖をつけておくことを強くおすすめします。

なぜなら、デフォルトの設定はあくまで「誰でも簡単に使える」ように調整されたものであり、「特定の目的に特化させる」ためには、この詳細設定が不可欠だからです。

ここからは、各ノードごとにどのような設定が可能で、それがどうワークフローに役立つのかを詳しく解説していきます。

### 8-2. インプットノードで入れることができるデータ

ユーザーが情報を入力するこの場所ですが、詳細設定を開くと**「Input Type（入力タイプ）」**という項目が現れます。

![](https://image.brain-market.com/store/c43123a4a7d65a890db02c56957b4d28.png)

デフォルトでは「Any（何でも）」になっていますが、ここを変更することで、入力データの質を担保し、エラーの起きにくいシステムを構築することができます。

僕の場合は音声データを入れることが多いので、それに限定してもいいのですが、特に設定していないのでここは好みですね。

ここで選択できるタイプは以下の通りです。

- **Any（任意）  
	**テキスト、画像、ファイルなど、形式を問わず何でもOK。基本はこれでいいと思います！
- **Audio（音声）  
	**音声データのみを受け付けます。議事録作成のときとかこれでもいいかもですね。
- **Image（画像）  
	**画像データのみを受け付けます。画像解析や、画像編集ワークフローを作る際に必須です。
- **Text（テキスト）  
	**文字列のみを受け付けます。最も一般的な入力形式です。
- **Upload File（ファイルアップロード）  
	**PDFやドキュメントファイルのアップロードを強制します。資料の横展開ワークフローなどで使えるかも。
- **Video（動画）  
	**動画ファイルのみを受け付けます。

### 8-3. インプットにはYouTube動画も入れられる

そして、User Inputのプラスマークから追加できる機能の中で、僕が最も衝撃を受けたのが「Add YouTube Video」です。

![](https://image.brain-market.com/store/58b72a7cd414b945527793f704ae036c.png)

これ、単にYouTubeのリンクを貼り付けるだけの機能だと思っていませんか？

実はOpalは、入力されたYouTubeのURLから、**動画の中身（音声や映像の内容）をAIが自動的に理解し、コンテキストとして読み込んでくれる**んです。

これまでは、YouTube動画の内容をAIに処理させようと思ったら、

1. 別のツールで文字起こしをする
2. テキストデータをコピーする
3. AIに貼り付ける

という面倒な手順が必要でした。

しかし、OpalならURLをポンと入れるだけ。

Googleサービスだからこそできる連携ですね！

動画内で語られている内容をベースに要約させたり、議論させたり、関連するブログ記事を書かせたりといったことが、一瞬で可能になります。

僕のような情報発信者にとって、リサーチやコンテンツの再利用（リパーパス）にかかる時間を大幅に短縮してくれる、まさに神機能と言えるでしょう。

裏技的な使い方としては、競合チャンネルの動画を入れて分析してもらい、自分のコンテンツを作っていくというワークフローもできます。

**▼特別に公開します！**

[https://opal.google/?flow=drive:/1GUoW4sRfeR5ppxeCoN3\_FFvq05OaODOO&shared&mode=app](https://opal.google/?flow=drive:/1GUoW4sRfeR5ppxeCoN3_FFvq05OaODOO&shared&mode=app)

### 8-4. ジェネレートノードの詳細設定

次は、Opalの頭脳とも言える「Generate」ノードです。

Gemini 2.5 Flash、2.5 Pro、3.0 Proなどを選択できるこのノードですが、詳細設定にはアウトプットの質を左右する極めて重要な項目が含まれています。

一つずつ見ていきましょう！

### 8-5. GeminiノードのSystem Instruction

- Gemini 2.5 Flash
- Gemini 2.5 Pro
- Gemini 3 Pro

これらのノードには、**System Instruction（システムインストラクション）**というものがあります。

![](https://image.brain-market.com/store/82dc7e4c64cca033df1bdb2ed410f8d7.png)

いわゆる「システムプロンプト」を設定する場所です。

通常のプロンプトが「何をさせるか」という指示だとすれば、システムインストラクションは「AIが何者で、どう振る舞うべきか」という**人格やルールの設定**にあたります。

詳細設定を開くと、デフォルトで「OKから始めないでください」「Outputだけを出力してください」といった記述が入っていることがあります。

これは、AIが余計な前置き（「はい、承知しました。以下が回答です…」など）を出力して、後続の処理を邪魔しないようにするための配慮です。

ここを編集することで、例えば、

> 「あなたはプロの編集者として、厳格な口調で修正案を出してください」
> 
> 「出力は必ずJSON形式のみにしてください」
> 
> 「SRTファイル（字幕データ）の形式を厳密に守ってください」

といった高度な制御が可能になります。

特に、僕がよく使う「SRTファイルの生成」のような、フォーマットが命となるタスクでは、ここで厳しくルールを定義しておくことで、精度の高いアウトプットが安定して得られるようになるわけですね。

### 8-6. GeminiノードのReview with User

この「Review with User（ユーザーと一緒に確認）」というチェックボックス、これめちゃくちゃ強力です...！

![](https://image.brain-market.com/store/8fe197ece9884bd1b1b63861a9520420.png)

AI自動化ツールはよくもわるくも、「一度スタートしたら、最後までノンストップで突き進んでしまうこと」でした。

途中でAIが微妙な生成結果を出しても、そのまま次の工程に進んでしまい、最終的に使い物にならない成果物が出来上がる…なんてことは日常茶飯事です。

しかし、この機能を使えば、**AIの処理を一旦停止させ、人間の目によるチェックを挟むこと**ができます。

具体的なフローはこうです。

1. Geminiが文章を作成する。
2. 処理が一時停止し、プレビュー画面が表示される。
3. ユーザー（あなた）が内容を確認し、必要であればその場で修正を加える。
4. 「OK」と入力すると、その内容が次のノードに渡される。

これができることの意味は計り知れません。 例えば、ブログ記事の自動生成フローにおいて、構成案の作成まではAIにやらせて、その構成案を人間がチェック・修正してから、本文の執筆に進ませる、といったことが可能になります。

「全自動」は魅力的ですが、クリエイティブな作業においては「半自動」の方がクオリティが高くなるケースが多々あります。

この「Review with User」は、AIのスピードと人間の判断力を融合させる強力な機能です。

これを使いこなせば、Opalは単なる自動化ツールを超えて、あなたの頼れるAIエージェントへと進化します。

### 8-7. Plan & Executeノードの3つのモード

複雑なタスクを処理するための「Plan & Execute」ノード。

![](https://image.brain-market.com/store/3067c5192016f7c404656988ca1c927c.png)

ここでは、AIがどのようにタスクを遂行するかという「戦略」を選択できます。詳細設定にある「Strategy（戦略）」という項目です。

これには3つのモードがあり、タスクの性質に合わせて使い分けることで、処理効率と精度が劇的に変わります。

**①All at Once（一括実行）**

すべての指示や処理を一度に行います。

プロンプトが長くても、AIが一気に読み込んで処理を開始するので、スピード重視の場合に向いています。単純なリサーチや、手順が決まりきっているタスクであれば、これが最も高速です。

**②Go in Order（順次実行）**

指定された手順を、上から順番に一つずつ実行していきます。

「まずWeb検索をして、その結果を要約し、その要約を元にメールの下書きを作成する」といったように、前の工程の結果が次の工程に必須となるような、依存関係のあるタスクに最適です。

ロジカルに一段階ずつ着実に進めてほしい場合は、このモードを選びましょう。

**③Think as I Go（考えながら実行）**

これが最も高度で、面白いモードです。 AIが「現在どのような状況か」「ゴールに辿り着くために、次は何をすべきか」を**自律的に思考（Thinking）しながら**処理を進めます。

例えば、「最新のAIトレンドについて調査し、レポートをまとめて」という抽象的な指示を出したとします。

このモードであれば、AIはまず検索を行い、情報が足りなければ別のキーワードで再検索し、十分な情報が集まったと判断してからレポート作成に移る、といった柔軟な動きを見せてくれます。

まさに「エージェント」的な挙動を実現するモードで、不確実性の高いタスクや、AIに裁量を持たせたい場合に威力を発揮します。

この「戦略」の選択肢があること自体が、Opalの設計思想の深さを物語っています。

### 8-8. Deep Researchノードの要約モード

Google検索のパワーを活用する「Deep Research」ノード。

ここにはシンプルですが、後続の処理に大きな影響を与える設定があります。

![](https://image.brain-market.com/store/5ec8925d3de67ad383b7f6460e3c3452.png)

通常、Deep Researchは膨大な検索結果を取得します。 情報量が多いのは良いことですが、そのまま次のノード（例えば文章生成を行うGemini）に渡すと、入力トークン数が多すぎて処理が遅くなったり、AIが重要な情報を見落としたりする原因になります。

そこで役立つのがこのチェックボックスです。

これをONにすると、Deep Researchノードは検索結果をそのまま渡すのではなく、**要点を短くまとめた要約文**として出力してくれます。

「詳しい検索ログはいらないから、結論と重要な事実だけを次の工程に渡したい」というケースでは、この設定が非常に有効です。ワークフロー全体の軽量化と高速化にも繋がります。

### 8-9. 画像と動画生成ノードの縦横比設定方法

さて、ここから多くのクリエイターにとって、解決策を知れば歓喜するポイントです。

画像生成AI（Imagen 4・Nano Banana等）や動画生成AI（Veo）を使う際の設定について解説します。

**アスペクト比の設定**

僕も含め、多くの人がここで躓いていたはずです。

「プロンプトに『16:9』って書いてるのに、なんで正方形の画像が出てくるんだ！」と。

実は、Opalにおけるアスペクト比の制御は、プロンプトではなく**詳細設定で行うのが正解**でした。

Advanced Settingsを開くと、アスペクト比を選択するプルダウンメニューが存在します。

![](https://image.brain-market.com/store/3895ce538f5d0c5a8f908b6900a568df.png)

- **1:1（正方形）**: インスタグラムの投稿やアイコン用。
- **16:9（横長）**: YouTubeのサムネイル、ブログのアイキャッチ、プレゼン資料用。
- **9:16（縦長）**: TikTok、YouTubeショート、スマホの壁紙用。
- **4:3 / 3:4**: 従来の写真比率など。

これを知っているかどうかで、生成される画像の使い勝手は天と地ほど変わります。 特に、YouTubeのサムネイルを自動生成させたいのに正方形で出てきては使い物になりませんよね。

ここで「16:9」を指定することで、確実に横長の画像を生成させることができます。

これは動画生成AIである「Veo」でも同様です。 最近はショート動画の需要が爆発的に伸びていますから、Veoで「9:16」の縦型動画を生成できる設定は、クリエイターにとって必須の知識です。

**Disable Prompt Expansion（プロンプト拡張の無効化）**

![](https://image.brain-market.com/store/83af49de0a88b227f3cbce137980a9cb.png)

画像生成AIには、ユーザーが入力した短いプロンプトを、AIが勝手に解釈して「高画質、詳細な描写、美しい光…」といった修飾語を付け足す「プロンプト拡張」という機能が備わっていることが多いです。

基本的にはクオリティアップに貢献してくれるありがたい機能ですが、自分の意図した構図や要素を厳密に守らせたい場合には、これが邪魔になることがあります。

その場合、この「Disable Prompt Expansion」にチェックを入れることで、AIによるお節介な修正を無効化し、**自分のプロンプトを忠実に再現させる**ことができます。

こだわりの強いプロンプトエンジニアの方や、特定のスタイルを維持したい場合には、この設定を活用してみてください。

### 8-10. Output Nodesの詳細設定

最後に、生成された成果物を出力するノードの設定を見ていきましょう。

ここにも、実務で役立つ地味ながら強力な機能が隠されています。

**Web Page Layoutのモデル選択**

![](https://image.brain-market.com/store/ef19fccb6a92edc11fde079dbac5a638.png)

生成結果をWebページのようなレイアウトで表示するノードですが、ここでも使用するモデル（2.5 Flash Lite, 2.5 Flash, 2.5 Proなど）を選択できます。

単純なテキスト表示なら軽量なモデルで十分ですが、複雑なコーディング結果を表示したり、インタラクティブなUIを構築したい場合は、より高性能な「2.5 Pro」などを選ぶことで、表示崩れを防ぎ、リッチな体験を提供できます。

**ファイルタイトル自動設定の重要性**

Googleドキュメント、スライド、スプレッドシートに出力するノードには、詳細設定の中にタイトルを入力する欄があります。

![](https://image.brain-market.com/store/398e4a947df8cf96c6325b38b33c4d4a.png)

これ、一見なんてことない機能に見えますが、自動化において「ファイル名」は非常に重要です。 ここを設定していないと、Googleドライブの中に「無題のドキュメント」が無限に増殖していくことになります。

後から探すのが大変ですし、管理も煩雑になりますよね。

「整理整頓までが自動化」です。この設定を忘れないようにするだけで、運用の快適さが段違いになります。

ということでこの章では、各ノードの詳細設定について見ていきました。

かなり重要な設定が隠れていることもあるので、しっかりチェックする習慣をつけておきましょう。

## 9\. 【実践】音声データからコンテンツを無限に生み出す、Fujin式最強AIワークフロー公開します

![](https://image.brain-market.com/store/65032e120b4eba82eb756c4cb8e9f73a.png)

さて、この章のテーマは、皆さんが首を長くして待ち望んでいた（と僕が勝手に確信している）アレです。

そう、僕のコンテンツ制作の裏側を支える、心臓部とも言える仕組みについて。

**「音声データからコンテンツを無限に生み出す、僕の秘伝のAIワークフロー」**

これについて、ついに全貌を完全公開してしまおうと思います。

いやー、やっと来ましたよ。

ここはね、いよいよ僕の「秘伝のタレ」とも言えるワークフローを皆さんにシェアできる時が来ました。これ、本当に解説したかったんですよ。ずっとウズウズしていました。

僕が毎日使っているこのワークフロー、まだ発展途上ではあるんですが、現時点でも相当な「革命」を僕の作業環境に起こしています。

ブログ記事、X（旧Twitter）のポスト、そしてサムネイル画像や字幕ファイルまで。これら全てが、たった一つの音声データから全自動で生まれているとしたら、信じられますか？

今回は、僕が構築したこの最強のワークフローについて、その中身を徹底的に解剖していきたいと思います。

Opalだからこそ実現できた並列処理の凄さ、そして各ノードに込めたこだわりを余すことなくお伝えします。

これから紹介する内容は、単なるツールの使い方解説ではありません。

**「AIをどう組み合わせれば、人間の作業を極限まで減らしつつ、クオリティの高いアウトプットを出せるのか」**

という、AI時代のクリエイティブの神髄に迫るものです。

かなり濃い内容になっていますので、ぜひ最後まで付いてきてください。

![](https://img.youtube.com/vi/IQnqT7nzkBs/mqdefault.jpg)

### 9-1. テンプレートの使い方

![](https://img.youtube.com/vi/5L_sdrtY3oM/mqdefault.jpg)

実は今回配布しているテンプレート、初期状態では**完全に「Fujin」に最適化された仕様**になっているんです。僕の口調、僕のジャンル、僕の思考回路で動くように作られています。

なので、これを皆さんが自分の武器として使いこなすためには、**「あなた仕様」にカスタマイズ（チューニング）**する必要があります。

「えー、難しそう…」と思いましたか？ 大丈夫です。実はやり方さえ分かれば、驚くほど簡単なんです。

まず、多くの人が最初にぶつかる壁がこれです。

> 「テンプレートを開いても、プロンプト（指示文）が編集できない！」

そうなんです。配布されたリンクから開いた状態は、いわゆる「プレビュー版」になっています。閲覧専用モードみたいなものですね。このままでは、中身を書き換えることができません。

そこで必要になるのが、画面の右上にある**「Remix（リミックス）」**というボタンです。

このボタンをポチッと押してみてください。「Remixing...」という表示が出て、少し待つと画面が切り替わります。プロジェクト名の横に「Remix」という文字が付けば成功です。

この状態になれば、ロックが解除され、全てのプロンプトや設定をあなたの好きなように書き換えることができるようになります。

ぜひ試してみてください！

### 9-2. 毎日の発信を支える「全自動コンテンツ生成ワークフロー」の全体像

▼**【究極奥義】音声が資産に変わる「ワンソース・マルチユース」全コンテンツ一撃生成システム**

https://opal.google/?flow=drive:/1a0sGrbPTOVG9qGJ2ocMFAP6GFcEG\_fSS&amp;shared&amp;mode=app

https://opal.google/?flow=drive:/1a0sGrbPTOVG9qGJ2ocMFAP6GFcEG\_fSS&amp;shared&amp;mode=app

![https://opal.google/?flow=drive:/1a0sGrbPTOVG9qGJ2ocMFAP6GFcEG_fSS&amp;shared&amp;mode=app](https://opal.google/images/share-card-prod.png)

まず、このワークフローが一体何をしているのか、その全体像からじっくりとお話ししましょう。

僕の毎日のルーティンは、このワークフローの「スタートボタン」を押すことから始まります。

PCを開き、Opalの画面を立ち上げ、「Upload from device」からポッドキャストの音声データを選択する。

![](https://image.brain-market.com/store/0a14494acb49b1292918ad1dbba6fb2b.png) ![](https://image.brain-market.com/store/e18514597f3367ae5fadd9a31e708e03.png)

僕がやる作業は、本当にこれだけなんです。あとは放置。コーヒーを淹れて飲んでいる間に、裏側では複数のAI（Gemini）たちが一斉に走り出します。

あるAIはブログを書き始め、別のAIはタイトルを考え、また別のAIは画像を生成し、さらに別のAIはXの投稿文を作り、同時に字幕データの作成も進んでいる。

**これらが「同時並行（パラレル）」で行われているんです。**これがOpalの最大の強みです。

Google Workspace Studioのような従来のオートメーションツールでは、基本的に「Aが終わったらB、Bが終わったらC」という「直列処理」しかできませんでした。

![](https://image.brain-market.com/store/7f320a7cd63bd12e858d6038c9b5209f.png)

文字起こしが終わるのを待って、ブログを書いて、それが終わってからXのポストを作って……とやっていたら、日が暮れてしまいます。

しかし、Opalは違います。全てのタスクが一気に走り出す。まさに「全自動コンテンツ生成フロー」です。

![](https://image.brain-market.com/store/53d36da5a8bb38b4bbe840e7afee10f8.png)

僕のYouTubeの概要欄やブログ記事、Xのスレッド投稿などが、なぜ毎日これだけの量と質で安定して発信できているのか。その秘密が全てここに詰まっています。

では、この工場の内部構造を、入口から一つずつ、ノード（処理の単位）ごとに詳しく見ていきましょう。

### 9-3. インプットと文字起こし

まず最初の入り口、インプットノードです。ここには収録したポッドキャストの音声データを入力します。

そして、その直後に繋がっているのが全ての土台となる「文字起こしノード」です。

![](https://image.brain-market.com/store/05295f8ed8ab52f03872fe2de408c19f.png)

ここではモデルとして「Gemini 2.5 Pro」を選択しています。プロンプトは至ってシンプルに設定しています。

**ポッドキャストの文字起こし：全文を文字起こししてください**

これだけです。変に「要約して」とか「綺麗に整えて」といった凝った指示は出しません。まずは素材そのものを、可能な限り正確にテキスト化する。ここが全ての生成物の源流になりますから、純粋なデータとして抽出することが重要なんです。

このシンプルなノードから、なんと4つもの処理ラインが分岐して伸びていくことになります。ここから、いよいよ各コンテンツへの加工が始まります。

### 9-4. ブログ記事生成 AIにナレッジを渡す方法

さて、ここからがこのワークフローの心臓部であり、最も複雑に作り込んだ「ブログ記事の生成プロセス」です。

ここで僕がこだわっているのは、単に内容をまとめるだけじゃなく、**「いかに僕（Fujin）らしい文章にするか」**という点です。

AI特有の「無難で綺麗なだけの文章」なんて、誰も読みたくないですからね。

そのために、僕は3段階のプロセスを経て記事を完成させています。

**ステップ① 初稿の生成（Gemini 2.5 Pro）**

まず、文字起こしデータを元に、Gemini 2.5 Proにブログ記事の初稿（ドラフト）を書かせます。

ここで使っているプロンプトは、僕が以前Googleの「Gem（ジェム）」機能を使って作り込んでいたプロンプトを、そのままOpalに移植しています。

![](https://image.brain-market.com/store/0a9db909eb3f9426d3074eab1f32c363.png)

> **【プロンプト】**
> 
> 目的と目標:
> 
> 【文字起こし】の内容を基に、読みやすいブログ記事を作成する。
> 
> \* 台本は、言い回し、内容、構成をユーザーの意図を汲み取りながら調整する。
> 
> \* 作成する台本の文字数は5000字とする。
> 
> \* 冒頭は「どうも、Fujinです。」、文末は「じゃあね！」を必ず入れる。
> 
> \* 小見出しを入れる。
> 
> 【ナレッジ】の言葉使いなどをまねしながら作成する。
> 
> \* 不自然にならないように細かく改行する。
> 
> \* ですます調にする。
> 
> 振る舞いとルール:
> 
> 1) 初期設定:
> 
> a) ユーザーの入力内容を正確に理解する。
> 
> b) 入力内容の要点、伝えたいメッセージ、ターゲットとする視聴者を明確にする。
> 
> 2) 台本作成:
> 
> a) ユーザーの入力内容をベースに、冒頭のフックとなる部分を作成する。
> 
> b) 論理的で分かりやすい構成を考案する。
> 
> c) 各セクションのタイトルや見出しを適切に設定する。
> 
> d) 飽きさせないように、適度な改行や空白を入れる。
> 
> e) 5000字程度の文字数で、内容が薄くならないように情報を整理する。
> 
> f) 必要に応じて、具体的な例え話やデータ、引用などを加える。
> 
> g) 視聴者の興味を引きつけ、行動を促すような表現を用いる。
> 
> h) 作成した台本をユーザーに提示し、フィードバックを求める。
> 
> i) フィードバックに基づいて、台本を修正する。
> 
> 3) 言葉遣い:
> 
> a) ターゲットとする視聴者に合わせた適切な言葉遣いを心がける。
> 
> b) 丁寧語、謙譲語、尊敬語を適切に使い分ける。
> 
> c) 口語的な表現を取り入れ、親しみやすさを演出する。
> 
> d) 誤字脱字、文法的な誤りがないように注意する。
> 
> e) テキストを太字で強調し、かつ鉤括弧で囲む場合は、「\*\*強調したいテキスト\*\*」 のように、鉤括弧の内側にあるテキストのみを太字にすること。
> 
> 全体的なトーン:
> 
> \* 明確で分かりやすい言葉遣いを心がける。
> 
> \* ポジティブで、ユーザーをサポートするような友好的な態度で接する。
> 
> \* 専門用語は避け、誰にでも理解できる言葉で説明する。

そして、ここで最も重要なのが、「ナレッジ（知識データ）」の注入です。

プロンプトの設定画面に、過去の僕のブログ記事をまとめたPDFファイル「ブログ記事アーカイブ.pdf」を読み込ませています。そして、プロンプト内でこう指示しています。

**『ブログ記事アーカイブ』の言葉使いなどをまねしながら作成する。**

この指示があるかないかで、出力のクオリティは天と地ほど変わります。

0からAIに「それっぽい文章」を書かせるのではなく、過去の自分のデータを教師データとして与え、「この人になりきれ」と命じる。これが、AIに「自分」を憑依させるための必須条件なんです。

もし皆さんがこれを実践するなら、まずは自分が過去に書いた文章（なければ今から書いてください、1記事でもいいので、自分が100%書いた純度100%の記事）をPDF化して、ナレッジとして読み込ませてください。

ここをサボると、ただの「AIが書いた無機質な要約」になってしまいます。

**ステップ② プロによる多角的なフィードバック**

初稿ができたら、それで終わりではありません。ここからがOpalならではの面白いところです。生成された初稿データを、さらに2つの別のノードに分岐させて流します。

それぞれのノードには、特定の分野の「プロ」としての役割を与えています。

![](https://image.brain-market.com/store/1da3b2dd12addb49c90827316e0f2420.png)

1\. **SEOのプロ（Gemini）**

> **【プロンプト】  
>   
> **あなたはSEO対策のプロです。
> 
> 【ブログ記事初稿】この内容を確認して改善点を洗い出してください。

2\. **プロのブログライター（Gemini）**

> **【プロンプト】  
>   
> **あなたはプロのブログライターです。
> 
> 【ブログ記事初稿】この内容を確認して、もっと読者を惹きつけて、最後まで読んでもらえるようなブログ記事にするために、改善点を洗い出してください。
> 
> Fujinの権威性に関しては触れないでください。

この2人の「AI専門家」に、AIが書いた初稿を徹底的にダメ出しさせるわけです。

人間がやる推敲やレビュー作業を、AI同士でやらせる。この「フィードバックループ」を自動化できるのが、フロー型ツールの真骨頂です。

自分一人で書いていると気づかない視点を、AIが補完してくれます。

**ステップ③ 修正と統合（ブログ記事の完成）**

そして、最後にこれら全ての情報を統合する「ブログ記事完成ノード」が待ち構えています。ここには以下の**5つのインプットが全て集結します。**

![](https://image.brain-market.com/store/3a14f3b7b9f3fb010e0f6f7ee959126f.png)

1. ポッドキャストの文字起こしデータ（原典）
2. Geminiが書いた初稿（ドラフト）
3. SEOプロからの改善案（フィードバックA）
4. プロライターからの改善案（フィードバックB）
5. ブログ記事アーカイブ（ナレッジ）

これら全てを受け取り、最終的なブログ記事を書き上げます。

> **【プロンプト】**
> 
> あなたはプロのライターです。
> 
> 【ブログ記事初稿】このブログ記事の全体像は崩さず、下記のルールに確実に従ったうえで、【ライティングのプロ】【SEOのプロ】のフィードバックをもとに書き直してください。
> 
> \# ルール
> 
> \*【文字起こし】の内容を基に、読みやすいブログ記事を作成する。
> 
> \* 台本は、言い回し、内容、構成をユーザーの意図を汲み取りながら調整する。
> 
> \* 作成する台本の文字数は5000字とする。
> 
> \* 冒頭は「どうも、Fujinです。」、文末は「じゃあね！」を必ず入れる。
> 
> \* 小見出しを入れる。
> 
> \* 【ナレッジ】の言葉使いなどをまねしながら作成する。
> 
> \* 不自然にならないように細かく改行する。
> 
> \* ですます調にする。
> 
> \* 明確で分かりやすい言葉遣いを心がける。
> 
> \* ポジティブで、ユーザーをサポートするような友好的な態度で接する。
> 
> \* 専門用語は避け、誰にでも理解できる言葉で説明する。
> 
> 3) 言葉遣い:
> 
> a) ターゲットとする視聴者に合わせた適切な言葉遣いを心がける。
> 
> b) 丁寧語、謙譲語、尊敬語を適切に使い分ける。
> 
> c) 口語的な表現を取り入れ、親しみやすさを演出する。
> 
> d) 誤字脱字、文法的な誤りがないように注意する。
> 
> e) テキストを太字で強調し、かつ鉤括弧で囲む場合は、「\*\*強調したいテキスト\*\*」 のように、鉤括弧の内側にあるテキストのみを太字にすること。

プロンプトでは、「初稿の全体像は崩さずに、2人の専門家からのフィードバックを反映し、かつFujinの文体ルールを厳守してリライトせよ」と指示しています。

さらに、ここでもう一度「どうも、Fujinです」「じゃあね！」といった基本ルールを念押しします。フィードバックを反映する過程で、元のルールが崩れることがあるからです。

こうやって何重ものフィルターを通し、検証を重ねることで、ようやく「僕が書いた」と言えるレベル、あるいはそれ以上のクオリティのブログ記事が出来上がるんです。

### 9-5. 【超重要】太字とカギカッコの「バグ」回避テクニック

ここで一つ、ブログ記事生成において皆さんに共有しておきたい**㊙テクニックがあります。**これを解決するのに、僕はかなりの時間を費やしました。

GeminiなどのLLMで記事を書かせていると、強調表示（太字）のマークダウン記号（アスタリスク2つなど）が、カギカッコの外に出てしまうという現象に悩まされたことはありませんか？

本来ならこうなってほしいですよね。

**「強調したいテキスト」**

なのに、AIは時々こういう出力をします。

\*\*「強調したいテキスト」\* \*

わかりますか？ アスタリスクがカギカッコの外側にあるんです。

これだと、ブログサービスによっては太字として認識されず、記号がそのまま表示されてしまいます。これが記事中に何箇所もあると、手作業で修正するのは地獄です。「強調したいテキスト」という部分に限って、AIはなぜか丁寧にカギカッコをつけてくるんですよね。

![](https://image.brain-market.com/store/8d5cda432148875881907ed155e3be91.png)

そこで僕は検証を重ね、プロンプトに以下の絶対ルールを加えました。

テキストを太字で強調し、かつ鉤括弧で囲む場合は、「\*\*強調したいテキスト\*\*」 のように、鉤括弧の内側にあるテキストのみを太字にすること。

「カギカッコを外せ」と言ってもつけてくるなら、いっそ「中に入れろ」と指示する。

この逆転の発想でルールを明記したところ、エラーが劇的に減りました。これはGeminiのクセを理解した上でのハックです。地味ですが、毎日の修正作業をゼロにする強力なテクニックなので、ぜひコピペして使ってください！

### 9-6. タイトル生成とサムネイル 画像比率の指定方法

ブログの本文という「中身」ができたら、次はそれを読者に届けるための「パッケージング」です。つまり、思わずクリックしたくなる「タイトル」と、目を引く「サムネイル画像」の作成ですね。

ここも、もちろん全自動です。

**【タイトル生成】10案からベストを選ぶAIコピーライター**

ブログ記事の生成と並行して、タイトル生成のノードも走らせています。ここでは、Geminiに「あなたはVoicyやポッドキャストに特化した超一流のコピーライターです」という役割（ロール）を与えています 。

![](https://image.brain-market.com/store/378f7061ce27a7de35b6ed0c9943bf35.png)

プロンプトの指示は具体的です。

> **【プロンプト】**
> 
> prompt\_settings:
> 
> role: "あなたはVoicyやポッドキャストに特化した、超一流のコピーライターです。"
> 
> goal: "【文字起こし】から、リスナーが思わず再生ボタンを押したくなる魅力的なタイトルを10個作成してください。"
> 
> constraints:
> 
> length\_max: 40文字以内
> 
> language: 日本語
> 
> format: 文字列のみ（かぎ括弧などの装飾は極力避ける）
> 
> copywriting\_principles:
> 
> \- "ベネフィット提示: リスナーが得られるメリットを明確にする"
> 
> \- "情報の空白（Curiosity Gap）: 「答え」を隠して「知りたい」と思わせる"
> 
> \- "具体性: 数字や固有名詞を入れてリアリティを出す"
> 
> \- "対立・逆説: 常識を覆すような視点を入れる"
> 
> \- "問いかけ: リスナーの当事者意識を刺激する"
> 
> output\_rules:
> 
> \- 抽象的な表現（例：「〜について」「〜の考察」）は避ける。
> 
> \- 嘘や釣りタイトル（中身と乖離したもの）は禁止。
> 
> \- 漢字・ひらがな・カタカナのバランスを整え、視認性を高める。
> 
> output\_example:
> 
> input\_summary: "毎日忙しいビジネスマンに向けて、朝の時間を活用してインプット効率を最大化する方法について話しています。特に耳からの学習がおすすめ。"
> 
> generated\_title: "忙しい人ほど「耳」を使う？朝15分で人生が変わるインプット術"

以前の僕はどうやっていたかと言うと、まずNotebookLMで音声を読み込ませて、そこから20個くらいのタイトル案を出させていました。そして、それを自分の目で確認し、良いものを組み合わせたり、言葉を削ったりして、ようやく1つのタイトルを決めていたんです。

でも今は、Opalのワークフロー内で完結させています。

さらに、タイトルの生成だけで終わらせず、その後に「ブログタイトル完成ノード」を繋いでいます。ここでは、「生成された10個の案の中から、最も効果的なものを1つだけ選択してください」と指示しています 。

![](https://image.brain-market.com/store/eddffe00da439d58dd275a831bbfb8b8.png)

これで、「案出し」から「決定」までが自動化されました。

ただ、ここはまだ改善の余地があると思っています。

例えば、過去に僕が発信して実際に再生数が伸びたYouTube動画やボイシーのタイトルを厳選して、「これが伸びるタイトルの法則だ」というデータをナレッジとして読み込ませる。

そうすれば、Geminiがその法則を学習し、より精度の高い、クリック率を稼げるタイトルを提案してくれるようになるはずです。

ここは後ほどご紹介するGemini 3 Pro対応バージョンの解説の際にお伝えします。

**【画像生成】プロンプトの罠と「Advanced Settings」の秘密**

次に、決定したタイトルを元に、サムネイル画像を生成するためのプロンプトをAIに書かせます。そして、そのプロンプトを画像生成AI（Imagen 4）に渡すわけですが……。

![](https://image.brain-market.com/store/2ae22d25a0761888aa58f2beb9be2940.png)

ここで多くの人がハマる、巨大な「罠」があります。それが**「アスペクト比（画像サイズ）」の問題です。**

ブログやYouTubeのサムネイルとして使うなら、画像は横長の「16:9」である必要があります。

だから僕は最初、プロンプトの中に一生懸命書いていたんですよ。

**「確実な画像比を16対9にしてください」**

**「横長の画像にしてください」**

って。

でも、何度やっても正方形（1:1）の画像が出てくる。

「なんでだよ！」と、正直かなりイラつきました...w

プロンプトをどれだけ工夫しても、AIが無視するんです。

結論を言います。

**プロンプトで指示してはいけません。**

画像生成ノードの設定画面にある「Advanced Settings（詳細設定）」を開いてください。ここの**「Aspect Ratio（アスペクト比）」**という項目で、直接「16:9」を選択するんです。

![](https://image.brain-market.com/store/0efb7b5185ea53c83ddfc6590acf8e11.png)

ここを設定しないと、いくらプロンプトの中で書いても無駄です。逆に言えば、ここさえ設定しておけば、プロンプトにサイズ指定を書く必要すらありません 。

これはOpalで画像生成をする際の鉄則です。この設定を見つけてからは、ストレスフリーで完璧なサイズのサムネイルが生成されるようになりました。

### 9-7. X（旧Twitter）ポスト生成 140字の制限とナレッジの重要性

ブログと並行して、X（旧Twitter）への投稿文も生成しています。

ここでも、文字起こしデータから直接内容を抽出して作成させています 。

![](https://image.brain-market.com/store/852918f8736ba330f46efcba99f6fdf0.png)

このノードで僕が以前「Gem（ジェム）」機能で作っていた「Xポスト作成くん」のプロンプトをそのまま移植しているんですが、ここで最も重要なのが、やはり「ナレッジ」です。

インプットの中に「Xポストアーカイブ.pdf」というファイルを入れているのが分かりますか？ 。

Xのような短文メディアでは、独特の「空気感」があります。改行のタイミング、絵文字の使い方、言い回しのリズム。これらは一般的な「要約」のプロンプトだけでは再現できません。

だからこそ、過去の僕のポストをまとめたPDFを読み込ませて、「この文体や形式を模倣してください」と指示するんです。これがあるのとないのとでは、出力されるポストの「Fujinっぽさ」が雲泥の差になります。

**あえて「一発出し」にする理由**

ブログ記事の生成では、「SEOのプロ」や「ライター」によるフィードバックループ（推敲ノード）を挟みましたが、Xのポストに関してはあえてそれをやっていません。

**なぜかというと、140字（あるいはスレッド形式）という厳しい文字数制限がある中で、何度もAIに修正をさせると、かえって構成が崩れたり、文字数カウントがおかしくなったりすることがあるからです。**

ナレッジさえしっかりしていれば、今のモデル（Gemini）なら一発出しでも十分クオリティの高いものが作れます。変にこねくり回すより、良質な教師データを与えて一発で決めさせる。これがX運用における僕の結論です。

### 9-8. 字幕（SRT）ファイル生成 動画制作を超時短する

最後に紹介するのが、動画制作者なら誰もが一度は絶望したことがある作業。

そう、「字幕（SRT）ファイル」の作成です。

![](https://image.brain-market.com/store/ea85d0f5cbfcabe37a9581fac8504081.png)

SRTファイルというのは、単なるテキストデータではありません。

**「どのタイミングで、どの文字を表示するか」という時間情報（タイムコード）がセットになったファイルです 。**

![](https://image.brain-market.com/store/0cd202449e1572f8d51b09dcd805bc4c.png)

これを手作業でやるのは地獄です。でも、Opalならこれも全自動です。

**なぜ「文字起こしデータ」を使わないのか？**

SRT生成ノードへの入力線は、「文字起こしされたテキスト」からではなく、「元の音声データ（Audio）」から直接繋がっています 。

これ、めちゃくちゃ重要です。

文字起こしされた後のテキストデータには、「時間」の情報が含まれていません。だから、文字起こしテキストをSRT生成ノードに入れても、正確なタイムコードを作れないんです。

「音声データ」そのものを渡すことで、AIは「この波形のここからここまでが、この単語だ」と認識し、正確なタイムコード付きのファイルを生成できるわけです 。

**ブラッシュアップノードで精度を高める**

さらに、生成されたSRTファイルをそのまま使うのではなく、**「SRTブラッシュアップ」**というノードを通しています 。

![](https://image.brain-market.com/store/79067db3b7b0c154670c888ed43aec33.png)

ここでは以下のような指示を出しています。

> **【プロンプト】**
> 
> 【SRTファイルの生成】この内容を確認し、話されている内容の一人称をFujinに統一し、その他表記があいまいだったり怪しい箇所を{{"type": "tool", "path": "embed://a2/tools.bgl.json#module:search-web", "title": "Search Web"}}を用いて調べ、修正してください。
> 
> タイムコードはいじらず、YouTubeテロップとして読みやすいように不要な文字は削除してください。

SRTファイルは長時間の音声だと生成に時間がかかりますし、精度もまだ100点とは言えません。

でも、ゼロから手打ちする労力に比べれば、修正作業だけで済むのは本当に「神」です。

ちなみに、このSRTファイルの結果は、アプリの画面上には表示させたくないので（邪魔になるから）、出力結果ノードには繋がず、コンソール（裏側の処理画面）から直接ダウンロードするようにしています。

こういう細かい使い分けができるのもOpalの魅力ですね。

### 9-9. 並列処理の強力さ

さて、ここまで見てきてどう感じましたか？

「なんか難しそう…」と思いましたか？

それとも「これ全部自動でやるの！？」と驚きましたか？

![](https://image.brain-market.com/store/4cc9f451d634c3c785a5d07edbb50f3d.png)

**このワークフローの凄さは、これら全ての処理が「同時並行（パラレル）」で進むことにあります。**

1. 文字起こしをする
2. ブログの下書きを書く
3. SEO担当がチェックする
4. ライター担当がチェックする
5. ブログを清書する
6. タイトルを考える
7. タイトルから画像を作る
8. Xのポストを作る
9. 字幕データを作る

これらをもし、ChatGPTなどのチャット画面で一つずつやろうとしたらどうなるでしょう？

「まずは文字起こしして」→待つ→「次はブログ書いて」→待つ→「修正して」→待つ…

日が暮れてしまいます。しかも、それぞれの工程で過去のデータをコピペして渡す作業が発生します。

ブログ記事を作るだけでも、5つのインプット（文字起こし、アーカイブ、初稿、フィードバックA、フィードバックB）をコピペしてまとめる必要があるんです。想像しただけでゾッとしますよね。

しかし、Opalのワークフローなら、最初の音声データをポイっと入れるだけ。あとは12個のノード（＝12人のAIスタッフ）が一斉に働き出し、コーヒーを飲んでいる間に全ての成果物が完成しているんです。

Google Workspace Studioのような従来のツールでは、基本的に「Aが終わったらB」という「直列処理」しかできませんでした 。それでは、このスピード感と多角的な生成は不可能です。

Opalだからこそできる「並列処理」

これこそが、生産性を爆発させる鍵なんです。

### 9-10. 出力結果のデザインをよくする方法

処理が終わると、「Wepage with Auto Layout」というノードによって、綺麗にレイアウトされたウェブページ形式で出力が表示されます。

これらが一つの画面に美しくまとまって出てきます。最近のアップデートでデザインも洗練されて、すごく見やすくなりました。

![](https://image.brain-market.com/store/bec621fb7fe57e1e9bc7ee978f5625c7.png)

あとはこれをコピーして、noteに貼り付けたり、Xに投稿したりするだけ。画像も右クリックで保存すればそのまま使えます。

字幕ファイル（SRT）だけはコンソール画面から確認する必要がありますが、それ以外のコンテンツ制作は全てこの一画面で完結します。

### 9-11. ワークフローは人によって全然違う

今回お見せしたワークフロー、実はまだ完成形ではありません。

この動画の後、僕はここにさらに**「ショート動画の台本作成」のノードを追加しようと計画しています。**

ポッドキャストの内容を要約して、1分間のショート動画にするための台本も、この一連の流れの中で自動で作ってしまおうというわけです。

ワークフローは、一度作って終わりではなく、出力結果を見ながら微調整（チューニング）を繰り返して育てていくものです。

「なんか今日のブログ、文体が硬いな」と思ったら、プロンプトの指示を少し変えてみる。

「Xのポスト、ちょっと長すぎるな」と思ったら、文字数制限のルールを加えてみる。

そうやって自分だけの「AI社員」を育てていく感覚。これがたまらなく面白いんです。

このワークフローを使えなくなったら、僕はもう日々の発信活動を続けられないかもしれません...w

それくらい、僕の生活に欠かせないインフラになっています。

> **「コピペ作業がなくなった」**
> 
> **「考える時間が減った」**

その小さな感動が、やがてあなたのクリエイティブを劇的に変えるはずです。

## 10\. 【実践】YouTube字幕自動化！高精度SRTファイル自動生成ワークフロー

この章では、音声データから自動で「SRTファイル（字幕ファイル）」を作成する、最強のワークフローについて解説していきたいと思います。

動画編集をしている方なら痛いほど分かると思うんですが、テロップ入れって本当に時間がかかりますよね。でも、今回紹介する方法を使えば、その手間を劇的に、いや革命的に削減できるかもしれません。

今回は僕が実際に組んでいるフローを徹底的に解剖していきます。

![](https://img.youtube.com/vi/XiXCT5XwDRY/mqdefault.jpg)

▼**YouTube字幕テロップ完全自動化！SRTファイル自動生成システムワークフロー**

[https://opal.google/?flow=drive:/1RcFbzE7uZ5eyWFeH0MuvYpbVOCYnhQe8&shared&mode=app](https://opal.google/?flow=drive:/1RcFbzE7uZ5eyWFeH0MuvYpbVOCYnhQe8&shared&mode=app)

### 10-1. 「最強字幕生成」ロジック

まず前提として、「SRTファイル」について軽く触れておきます。

これはYouTubeなどの動画プラットフォームや動画編集ソフトで読み込める「字幕データ」のことです。

![](https://image.brain-market.com/store/160f6c71f35fef0661f8009b6168fcd6.png)

音声の「どのタイミング」で「何の言葉」を表示するか、という情報がセットになっています。

これさえあれば、動画編集ソフト（Premiere Proなど）に読み込むだけで、テロップが自動で配置されます。

つまり、これまで手作業でやっていた「文字起こし」→「配置」→「タイミング調整」という地獄のような作業から解放されるわけです。

今回のワークフローは、このSRTファイルを音声データを入れるだけで全自動生成することを目的としています。

**3段階のAI処理**

僕が組んでいるワークフローは、大きく分けて3つのAIノード（処理の塊）を繋げています。

![](https://image.brain-market.com/store/4a37cf71e869a9b52f4a1501036e0b4a.png)

それぞれの役割と、具体的にどんな指示（プロンプト）を出しているのか、詳しく解説します。

**①音声データの準備**

まず最初に、処理したい音声データをインプットします。

ここで重要なのが、このノードに「どういったデータが必要か」という説明書きを入れておくこと。そうすると、プレビュー画面でスタートした時に、その説明が表示されるので迷わずに済みます。

**②Gemini 2.5 Proによる「SRTの土台作り」**

最初の処理は、音声データをテキスト化し、SRT形式にする工程です。

ここでは「Gemini 2.5 Pro」を使用しています。

![](https://image.brain-market.com/store/3d8677e5688b2035386f5c98cbf2904c.png)

具体的なプロンプトの指示内容は以下の通りです。

> 【音声データ】から話している内容とタイミングを完璧に一致させたSRTファイルを作成してください。 40文字程度ごとに自然に区切ってください。長くならないようにしてほしいです。

正直なところ、AIは「5秒ごと」「40文字程度ごと」といった細かい秒数指定を完璧に守ってくれるわけではありません。ただ、ここで重要なのは、まず「SRT形式として破綻していないデータ」を出力させることです。

**③洗練とWebサーチの活用**

ここが今回のワークフローの肝です。

単純に文字起こししただけだと、固有名詞が間違っていたり、誤字脱字があったりします。例えば、僕の名前「Fujin」が「風神」と漢字変換されてしまうことがよくあります。

そこで、2つ目のノードで内容を修正・洗練させます。ここでの指示はかなり具体的です。

> 【SRTファイルを生成】この内容を確認し、話されている内容で風神はFujinに統一し、その他表記があいまいだったり怪しい箇所を【Search Web】を用いて調べ、修正してください。
> 
> タイムコードはいじらず、YouTubeテロップとして読みやすいように「で、その、この、えー」などのような不要な文字は削除してください。

**このWebサーチ機能が、Opalのようなワークフローツールの最大の強みです。**

![](https://image.brain-market.com/store/469d831466d29ae6f382e94ed61c47b6.png)

通常の文字起こしツールでは、知らない単語は適当な当て字にされて終わりですが、この機能を入れることで、AIが自らネット検索を行い、「あ、これはこういう用語だな」と判断して修正してくれます。

これがあるのとないのとでは、最終的な精度に雲泥の差が出ます。

※**フィラーの削除**

「タイムコードはいじらず、テロップとして読みやすいように『えー』『その』『この』といった不要な言葉は削除してください」と指示します。これによって、そのまま動画に出せるクリーンなテキストになります。

**④可読性の向上（フォーマット調整）**

さらに最近、もう一つノードを追加しました。

![](https://image.brain-market.com/store/d121f26812828e01cd02555e24ac09ba.png)

これは、YouTubeのテロップとして画面に表示した時の「読みやすさ」を整えるための工程です。

> 【SRTテキストの洗練】このデータの各セクションごとに、20文字以内で改行してYouTubeのテロップとして読みやすいように整えてください。タイムコードはいじらないでください。

この「タイムコードはいじらない」という指示が、めちゃくちゃ重要です。

なぜなら、この段階では音声データを参照せず、前のノードで作られたテキストデータだけを処理しているからです。ここでAIが気を利かせてタイムコードをいじってしまうと、映像と字幕のタイミングがズレてしまい、使い物にならなくなります。

文字の見た目は整えてもいいけど、時間は絶対に変えるな、と釘を刺しておくわけですね。

### 10-2. なぜ公式サイトのGeminiではなく、Opalなのか？

![](https://image.brain-market.com/store/65a195ef315d659b4fca583f898c052d.png)

ここで一つの疑問が浮かぶかもしれません。

「Gemini 2.5 Proを使っているなら、普通にブラウザ版のGeminiに音声ファイルを投げればいいのでは？」と。

そっちはGemini 3 Proにも対応していますしね。

結論から言うと、**ブラウザ版ではSRTファイルの作成ができません。**

公式サイトで使えるGeminiには、入力できるデータ量や処理方法に制限（リミット）がかかっていることが多いんです。

実際にやってみても、長時間の音声データの内容をすべて正確に読み込んで、完全なSRTファイルとして出力するのは苦手な傾向があります。途中で要約してしまったり、データ量が多すぎて処理しきれなかったりするんですね。

一方で、Opal経由で使用する場合、おそらく裏側がAPIを通しているので、API経由で利用することになります。

**APIはブラウザ版に比べて制限が少なく、自由度が圧倒的に高い。**

だからこそ、長尺の動画であっても、今回のように精密なSRTファイル生成が可能になるんです。

ここまでで、以下の流れが完成しました。

1. 音声データを入れる
2. GeminiがSRT形式に変換する
3. Webサーチを駆使して固有名詞や誤字を修正する
4. テロップ用に改行などを整える（時間はズラさない）

これで、理論上は完璧なSRTファイルが出来上がるはずです。

しかし、AI開発は「理論通り」にいかないのが面白いところであり、難しいところ。

後半では、実際にこれを動かした時の挙動、エラーが出た時の「バイブコーディング的」なデバッグ方法、そしてGoogleドキュメントへの書き出しとPremiere Proへの連携について、泥臭い実戦部分を解説していきます。

### 10-3. SRTファイル生成のデバッグ方法

さて、ここから実際にワークフローを動かしてみましょう。

まず音声データをアップロードするわけですが、ここで超重要なポイントがあります。

**ファイル形式は必ず「.mp3」にする**

![](https://image.brain-market.com/store/795b76a2a49c4918d37cc15544863678.png)

「.wav」などの高音質な非圧縮ファイルは、データ量が大きすぎてAIが処理しきれず、エラーの原因になります。

「音質が悪くなると文字起こしの精度が下がるのでは？」と心配になるかもしれませんが、関係ありません。AIが「言葉」として認識できればいいので、圧縮されたMP3で十分なんです。iPhoneで録音したデータなどでも問題ありませんが、とにかく「データを軽くする」ことを意識してください。

もしエラーが出たら、まずはMP3への変換や圧縮を疑ってみるのが鉄則です。

**生成プロセスとデバッグの極意**

実行ボタンを押すと、ノードが順番に処理を開始します。

SRTファイルの生成はそれなりに時間がかかりますね。

ここで僕が必ずチェックしている「デバッグのポイント」があります。

**①尺（時間）の整合性チェック**

![](https://image.brain-market.com/store/1d7beb86b44d2171dbb4b6df661e4223.png)

生成されたSRTファイルのテキストを見て、一番最後のタイムコードを確認します。

例えば、元の音声が「15分」あるのに、SRTファイルの最後が「13分」で終わっていたら、それは明らかにおかしいですよね。

「ということで、今回はこの辺で終わりにしたいと思います」という僕のいつもの締め台詞が、13分の時点に来ていたら、ラスト2分が消失していることになります。

これを発見したら、「あ、生成が途中で止まってるな」「データ量が多すぎたかな」と判断し、調整に入ります。

**②ノードごとの出力確認**

もし最終結果がおかしい場合、どの段階で狂ったのかを特定する必要があります。

コンソールタブを見て、ノード1（生成）は大丈夫か？ ノード2（洗練）でバグったか？ を順に見ていきます。

実際にあった例として、ノード2までは完璧だったのに、ノード3（フォーマット調整）を通した瞬間にタイムコードがズレたり、テキストが消えたりすることがありました。

「タイムコードはいじらず」と指示していても、AIが勝手なことをする場合があるんです。

そういう時は、そのノードの指示文を書き換えたり、場合によってはノードごと削除して作り直したりします。

この、エラーを見て、仮説を立てて、プロンプトを微調整して、また回す...という繰り返し。

これこそがまさに「バイブコーディング」です。

赤いエラー表示が出ると嫌な気分になりますが、そこを根気よく「いい感じ」になるまで調整していくのが、AI使いこなしの醍醐味でもあります。

**Googleドキュメントへの保存の癖**

ワークフローの最後には「Save to Docs」というノードを繋げて、Googleドキュメントに自動保存するように設定しています。

SRT形式は特殊なレイアウトなので、普通のテキストファイルよりもドキュメントの方が見やすいからです。

ただ、ここにも注意点があります。

**Opalの仕様なのか、「一つのワークフローにつき、一つのドキュメントしか作られない」という現象が起きることがあります。**

![](https://image.brain-market.com/store/fe8bbacf6e1902df8bb08ca4031f3fa4.png)

例えば、同じワークフローを使って「英語版」と「中国語版」を作ろうとしても、同じドキュメントに上書きされたり、混ざったりしてしまうことがあるんです。本当は別々のファイルで保存してほしいんですが、ここの制御がまだ甘い部分があります。

さらに、バグでドキュメントへの保存自体が失敗することもあります。

そんな時はどうするか？

**原始的ですが、「コンソールから直接コピー」が最強です。**

コンソール画面に出ている生成結果をクリックし、「Ctrl + A（全選択）」→「コピー」。

これを手動で保存するのが、結局一番確実で早かったりします。

### 10-4. SRTファイル化からPremiere Proへの連携

コピーしたテキストを、どうやってSRTファイルにするのか。

実際にやってみましょう。

![](https://image.brain-market.com/store/3f9bb344c735821b8abae6de7774f3d3.png)

1. **コードエディタを開く  
	**Antigravity、Cursor、VS Codeなど、何でもいいのでエディタを開きます。
2. **新規ファイル作  
	**拡張子を「.srt」にしてファイルを作ります。（例：text.srt）
3. **ペースト＆保存  
	**先ほどコピーしたテキストを貼り付けて保存します。

これで、PC上にSRTファイルが生成されました。

あとはこれを動画編集ソフトに入れるだけです。今回はAdobe Premiere Proを例にします。

1. Premiere Proを開く。
2. 「ファイル」→「読み込み」から、作成したSRTファイルを選択。
3. または「キャプション」パネルから読み込み。

![](https://image.brain-market.com/store/bf9f1a761ab9d39d608f0edb186cfc36.png)

![](https://image.brain-market.com/store/72edc9a2ccb15cd1bc58237602d65d11.png)

これだけで、タイムライン上にズラッと字幕データが並びます。

「どうも、Fujinです」といったセリフが、音声に合わせて自動で配置されているのを見ると、感動しますよ。

もちろん、完璧ではありません。

AIが作ったものなので、微妙な間のズレや、意図しない改行が含まれていることもあります。

**ですが、「ゼロから手打ちする」のと「ある程度出来上がったものを調整する」のとでは、労力が天と地ほど違います。**

微調整は人力でやる必要がありますが、ベースが出来上がっているだけで、編集時間は大幅に短縮されます。

### 10-5. 動画制作の未来は「半自動化」にある

今回紹介したワークフローを使えば、動画編集の中で最も面倒な「テロップ入れ」の作業を、AIに肩代わりさせることができます。

1. **Opalでワークフローを組む**
2. **MP3で軽くして投げる**
3. **エラーが出たら調整する**
4. **最後は手動で連携して仕上げる**

完全に全自動とはいきませんが、この「半自動化」の仕組みを持っているかどうかで、クリエイティブに割ける時間は大きく変わってきます。

Remotionのようなツールを使っている人は、SRTファイルを読み込ませるだけでバイブコーディングで動画が完成しますし、Premiere Pro派の人も作業効率が爆上がりします。

ぜひ皆さんも、このワークフローを参考に、自分だけの「AIアシスタント」を構築してみてください。

最初は難しく感じるかもしれませんが、一度組んでしまえば、その後の動画制作が驚くほど楽になりますよ。

## 11\. 【実践】ショート動画台本作成を完全自動化！ゼロからのワークフロー構築術

この章では、ショート動画の台本作成を完全自動化する「最強のノード」を、ゼロから皆さんと一緒に作り上げていきたいと思います。

あなたは、ショート動画の台本作り、楽しんでいますか？それとも苦しんでいますか？

正直なところを言ってしまうと、台本を作る作業ってめちゃくちゃカロリーが高いんですよね。

限られた秒数の中で、視聴者の興味を一瞬で掴む「フック」を作り、飽きさせない「展開」を考え、納得感のある「オチ」をつける。

これを毎回ゼロベースで脳みそをひねって考えていると、いくら時間があっても足りません。「あー、もう台本考えるだけで1日終わっちゃったよ…」なんてこと、よくありますよね。

そこで今回は、僕が実際にワークフローを作っている様子をお見せしながら、ショート動画の台本を音声データから制作するワークフローをいっしょに作っていきたいと思います！

それでは、早速やっていきましょう！

![](https://img.youtube.com/vi/qzvyfwfBTo0/mqdefault.jpg)

### 11-1. まずはテスト環境を作ろう

ワークフロー構築における最初の、そして最も重要な鉄則をお伝えします。 それは、「いきなり本番環境をいじらない」ということです。

![](https://image.brain-market.com/store/b347bf0d5e7a46914e6e2fd449fc0617.png)

既存のメインで稼働しているワークフローの中に、いきなり新しい機能を組み込もうとすると、もし失敗した時に全体がエラーを吐いて動かなくなってしまうリスクがあります。

せっかく順調に動いていたシステムが、ちょっとした変更で台無しになる。これはエンジニアリングの世界でもよくある悲劇ですが、AIワークフローでも同じことが言えます。

なので、まずは「テスト用のワークフロー」を別途作成して、そこでしっかりと動作検証（PoC）を行ってから、安全だと確認された段階で本番環境に実装する。これがプロのやり方です。

今回も、まずは新しいワークフローを用意して、そこに必要な要素を一つひとつ配置していくところからスタートします。

基本的には、音声データをインプットして、そこから台本を生成するという流れを作りたいので、まずはテスト用にシンプルな構成で組んでいきます。

### 11-2. ノードのプロンプトの書き方

AIに良いアウトプットを出させるために、プロンプトと同じくらい、いやそれ以上に重要なものがあります。 それは「良質なデータ（Few-Shot事例）」を与えることです。

今回、テスト環境を構築するにあたって、僕が過去に作成したショート動画の台本アーカイブをGoogleドライブから引っ張り出してきました。

![](https://image.brain-market.com/store/6cefb207bb7cf774c459ca211489da8f.png)

これは僕が以前、Web3ゲームの発信をしていた時に実際に使っていた台本たちです。AIに書かせたものではなく、僕が自分の頭で構成を練り、一言一句こだわり抜いて書き上げ、そして実際に動画化して「再生数が伸びた」という実績のある、いわば「生きたデータ」です。

用意するのは、大体5つくらいの台本があれば、AIはそのパターンを学習するのに十分かなと思います。今回は「台本1」から「台本5」までを用意しました。

### 11-3. データの「整形」がAIの理解度を左右する

ここで一つ、非常に重要なテクニックがあります。それはデータの「見せ方（フォーマット）」です。 ただテキストをベタ打ちで羅列するのではなく、AIが構造を理解しやすいように「見出し」をつけてあげることが重要です。

![](https://image.brain-market.com/store/4396b7b79cd92f29787a7027dacfbb28.png)

AIは賢いですが、どこからどこまでが「1つの台本」なのかが分からないと、情報を混同してしまいます。

具体的には、各台本の冒頭にシャープ（#）をつけてマークダウン形式にするなど、視覚的・構造的な区切りを明確にしてあげます。

「# 台本1」「# 台本2」といった具合ですね。こうすることで、AIに対して

> **「ここからここまでが1つのセットだよ」**
> 
> **「ここで次の事例に切り替わるよ」**

ということを伝えてあげるわけです。

もしこの区切りが曖昧だと、AIが「前の台本のエンディングと次の台本のオープニングが繋がっている文章」だと誤認してしまい、文脈がおかしいアウトプットが出てきてしまうリスクがあります。AIに認識させるための「優しさ」みたいなものですね。

### 11-4. ジャンルが違っても使えるのか？

今回用意したナレッジデータは、再生数が伸びた順に上から並べてペーストしているんですが、一つ懸念点があります。

**それは、このデータが「ゲーム紹介用」の台本だということです。**

しかし、僕が今回作りたい、そして今後量産していきたいのは「AI解説用」の台本なんですよね。

ゲームとAI。ジャンルが違います。 「ジャンルが違うデータを使っても大丈夫なの？」と疑問に思う方もいるかもしれません。普通ならAI用の台本データを集めるべきです。

でも、ここであえて「ゲーム用の伸びた構成」を「AIジャンル」に転用（Transfer Learning的なアプローチ）ができるのか。それを検証することこそが、今回のワークフロー構築の最大の肝になります。

もしこれが上手くいけば、「過去に別ジャンルで成功したノウハウ」を、新しいジャンルに無限に横展開できることになりますからね。

僕はいつもこうやって、

> **「できるかわからないけど、とりあえずやってみる」**
> 
> **「検証してデータを取る」**

というスタンスでAIと向き合っています。今回はその検証プロセスも含めて、皆さんに共有していきたいと思います。

### 11-5. 「メタ・プロンプト戦略」

さて、データの準備ができたら、次はいよいよワークフローの心臓部となる「Generate Node（生成ノード）」の設定です。

ここにどんなプロンプトを入れるかで、出力される台本のクオリティが決まります。ここがないと何も始まりません。

音声データは単なる素材として入れればいいだけですが、それをどう料理し、どう味付けするかはこのノード次第です。

今回はモデルとして、Gemini 3 Pro…ではなく、あえて「Gemini 2.5 Pro」を選択して進めていきます。（※収録時点での利用可能状況を考慮）

![](https://image.brain-market.com/store/0fbcac198ef0b29002d8b3dd61d89934.png)

ここで皆さんに質問です。プロンプト、自分でゼロから書いていませんか？ 「あなたはプロの脚本家です…」みたいに、キーボードをカタカタ叩いていませんか？

もしそうなら、今すぐその手を止めてください。 今回のジェネレートノードに入れるプロンプト、どうするかというと…

**僕は、プロンプト自体もGemini（AI）に書いてもらっています。**

実は、これが一番効率的で、かつ精度が高いんです。AIのことはAIが一番よく知っている。AIに指示を出すための言語（プロンプト）は、AIに生成させるのが最適解なんです。

具体的に、僕はGemini（チャット画面の方）に対してこんな風に指示を出しています。

![](https://image.brain-market.com/store/e3f7db53bf96eb6161eab7204826536f.png)

まず、「添付資料は過去伸びたショート動画の台本です」と伝え、先ほどのゲーム実況の台本データを渡します。

そして、「これをもとに、ユーザーが入力したデータから、ショート動画台本を生成するための『ジェム用のプロンプト』を書いてください」とオーダーします。 Opalのノード一つひとつは「ジェム（Gem）」のようなものだと捉えていいので、「ジェム用のプロンプト」という言葉を使っています。

> 【プロンプト】
> 
> 添付資料は過去伸びたショート動画の台本です。これをもとにユーザーが入力したデータからショート動画台本を生成するためのGem用のプロンプトを書いてください。
> 
> 添付資料のテーマはゲームですが、インプットするデータの主なテーマはAIなので、それにチューニングしてください。

ここで非常に重要なのが、先ほどの「ジャンル違い」の問題を解決するためのインストラクションです。ただ「プロンプトを書いて」と言うだけでは不十分です。

僕はこう付け加えました。 「添付資料のテーマはゲームになっていますが、今回インプットするデータの主なテーマはAIなので、その構成やノウハウをAIジャンルに転用できるようにチューニングしてください」

これをしっかり伝えてあげることが、成功の鍵です。

こう指示することで、AIは以下のように思考します。

> 「なるほど、ユーザーは『ゲームの話』をしたいわけじゃないんだな。この台本データから学ぶべきは、『ゲームの内容』ではなく、『視聴者を惹きつける構成』や『フックの作り方』『情報の出し方のテンポ』といった構造的な部分なんだな。それを抽出して、AIの話題に当てはめればいいんだな」

この「構造の抽出と転用」をAIに肩代わりさせること。これこそが、僕が実践しているプロンプトエンジニアリングの極意です。

本当にね、プロンプトとか全部ね、ゼロから自分で書いてる人なんていないですよ、マジで。

トップ層はみんな、AIに下書きを書かせているんです。

いかにこうやって「いい感じのプロンプト」をAIに書いてもらえるか、という「指示出しの指示出し（メタプロンプト）」のスキルの方が、今は圧倒的に重要なんです。

僕は普段、この「プロンプトを作成するための専用のGPT」や「プロンプト生成用ジェム」を別途作って運用していますが、今回は誰でも再現できるように、通常のGeminiのチャット画面を使って生成しています。

### 11-6. 生成されたシステムプロンプトの確認

指示を送信すると、Geminiがあっという間に「ジェム用システムプロンプト」を生成してくれました。

中身を見てみましょう…おお、いい感じです。かなり精度が高い。

![](https://image.brain-market.com/store/a79a728fabbc322af5354792e80bbbe2.png)

例えば、「ヤバすぎる」とか「〇〇円稼いだ」といった、僕がゲーム実況動画で視聴者の足を止めるために使っていた特有の「煽り構文」や「パワーワード」を、しっかりとAIジャンルでも使えるように抽象化してくれています。

「ゲーム系の構図をAIジャンルに転用してくださいね」という指示がしっかりと効いています。

さらに驚くべきは、「Suno」などの具体的なツール名を挙げた「ワンショットプロンプト（出力例）」まで勝手に組み込まれている点です。

これは「Few-Shot Prompting」の一種ですが、「こういう入力が来たら、こういう形式で出力してね」という具体例をプロンプトの中に含めることで、出力の形式崩れを防ぎ、精度を劇的に安定させる効果があります。

これをGeminiが自律的に判断して入れてくれている。賢すぎますね。

動画の最後まで見てもらうためのテクニックである「情報の寸止め（重要な結論を引っ張る技術）」なんかも、しっかりとプロンプトの指示に含まれています。

「これこれ！こういうのが欲しかったんだよ！」という要素が全部入っています。やっぱりAIに書かせるのが正解ですね。

### 11-7. Opalへの実装をしてみよう

最高のプロンプトが手に入ったので、これをコピーして、OpalのGenerate Nodeのプロンプト入力欄にペーストします。

![](https://image.brain-market.com/store/75e2ac1b05efc5a27e8afe31a655edbc.png)

内容を軽くチェックして、微調整が必要なら行いますが、今回はこのままいけそうな完成度です。レビュー機能もありますが、今回は不要でしょう。

さて、ここからがOpal操作のハイライトです。インプットの設定です。

プロンプトの中に、「どこから情報を引っ張ってくるか」を定義する必要があります。ここで登場するのが、Opalの最強機能であり、絶対に覚えて帰ってほしい機能、「アットマーク（@）」です。

**これ、本当に重要です。テストに出ますよ。もう一回言います、重要です。**

![](https://image.brain-market.com/store/7dba7943899a3c38766378c139e19cad.png)

プロンプトの入力欄で、キーボードの「@」を押してみてください。すると、画面上にアセットやツールを選択するポップアップメニューが出てきます。

ここで、前のノードから流れてくるデータ（今回は「User Input」という黄色いノード）を選択することで、ノード同士を論理的に接続することができるんです。

具体的には、プロンプトの冒頭を以下のように書き換えます。 「ユーザーから提供された @\[User Input\] を踏まえて…」

画面上でクリックして選択すると、プロンプトの中にチップのような形で埋め込まれます。これで、「前のノードに入ってきたデータが、ここに代入されるんだな」という動的なパイプラインが完成します。

さらに今回は、先ほどGoogleドライブから読み込んだ「ショート動画台本アーカイブ（過去の成功事例）」も、知識（ナレッジ）として参照させたいですよね。

なので、「@」を押して、リストから「ショート動画台本アーカイブ」を選択します。

![](https://image.brain-market.com/store/12b841c136cfb27e28e9e25e38c92bec.png)

「この資料の内容の言い回しや口調を真似て作成してください」という指示も加えます。

これで、「ユーザーが入力した最新のネタ（User Input）」と「過去の成功法則が詰まったアーカイブ（Knowledge）」の2つを掛け合わせて、最強の台本を出力する環境が整いました。

最後に、出力形式を指定します。シーン指定、テロップ、音声（台本）といった要素が含まれるように調整します。 あとは、ノードの端っこにある「チョボ（接続点）」をドラッグして、次のアウトプットノードに繋げば、テスト環境の完成です。

理論上はこれで完璧です。あとは再生ボタンを押すだけ。

…と、ここまでは順調だったんです。まるで教科書通りの展開でした。 しかし、ここからが本当の戦いでした。

実際に動かしてみると、予想外のエラーが連発。「あれ？うまくいかない…なんで？」 現場では何が起きていたのか。

![](https://image.brain-market.com/store/644f22f83d134283b46e3e131d64c440.png)

赤い警告表示と共に、Gemini 2.5 Proを使っているにも関わらず、「View details（詳細を見る）」を確認すると「良いレスポンスがGeminiから得られませんでした」という、なんとも無慈悲なメッセージが表示されました。

![](https://image.brain-market.com/store/5906ed9d2dafbf4ceb53f6ffed4e672f.png)

なぜなのか？プロンプトは完璧なはず。参照データも入れた。 ここからは、僕が実際に行ったトラブルシューティング（原因切り分け）の様子を、思考プロセスそのままにお届けします。

### 11-8. 【重要】エラーの原因を特定しよう

最初に疑ったのは、プロンプトの「出力フォーマット」の指定です。

「タイトル案を出して」とか「構成案を出して」といった細かい指定をしすぎているのが、AIの処理を混乱させている原因かな？と仮説を立てました。 そこで、一旦「出力フォーマット」の記述を削除し、よりシンプルな指示にして再実行してみました。

![](https://image.brain-market.com/store/eaa34c0a42bd7e94494c75e3661f5bec.png)

結果は…またしてもエラー。進捗バーは進むものの、最後の最後でコケる。

「うーん、これじゃないのか」

次に考えたのは、「プロンプト自体の構造がおかしいのではないか？」という点です。人間が見て分かりやすくても、AIにとっては解釈しづらい構造になっている可能性があります。

そこで、Geminiのチャットに戻り、もう一度プロンプトを投げ直してこう指示しました。 「下記のプロンプトをYAML（ヤムル）形式に書き換えて」

![](https://image.brain-market.com/store/83bc74e87395f808c6379577097f0904.png)

YAML形式というのは、データの構造を表現するのに適した形式で、AIにとっても非常に読みやすい（パースしやすい）と言われています。構造化データにすれば、AIが誤解なく指示を読み取ってくれるはずです。

出てきたYAML形式のプロンプトをコピーし、Opalのノードに貼り付け、インプット設定（User Inputへの紐付け）も再度確認して、再トライ。

![](https://image.brain-market.com/store/11d743089eb804a890182108da84bc53.png)

…それでもダメ。エラーは消えません。 「なんでだろう？かなり綺麗なプロンプトになったはずなのに」

次に疑ったのは、「モデル」と「入力データの重さ」の相性です。

Gemini 2.5 Proではなく、より軽量で高速な「Gemini 2.5 Flash」に変えてみたらどうだろう？処理落ちしているだけかもしれない。 そう思ってモデルを変更してみましたが、結果は変わらず。

ここでハッと気づいたのが、「音声データから直接生成させているのが無理があるのではないか？」という根本的なワークフロー設計の問題です。

今回のテストでは、音声ファイル（Audio）を直接ジェネレートノードに突っ込んで、「これ（音声）を聞いて、台本を書いて」と指示していました。 Opalはマルチモーダル対応ですが、音声データを解析しつつ、複雑な台本構成を考えるというのは、処理負荷が高すぎるのか、あるいはOpal内でのデータの受け渡しがうまくいっていない可能性が高い。

そこで、間にワンクッション挟むことにしました。 「文字起こし（Transcribe Audio）」のノードを追加する作戦です。

![](https://image.brain-market.com/store/071e8f686742e3eb147c4e8da15e4232.png)

音声データを一度テキストデータに変換し、そのテキストをプロンプトに渡す。これなら、AIは「テキストを読んでテキストを書く」だけになるので、処理は確実に軽くなるはずです。

### 11-9. PDF読み込みの「罠」

文字起こしノードを追加し、テキストデータとして渡すように変更して再挑戦。 しかし、それでもなぜか「ショート動画台本」の生成部分でエラーが出続けます。

文字起こしまでは成功している。でも、生成で止まる。 ここでようやく、真の原因が見えてきました。消去法で残ったのは、「Googleドライブから読み込んでいたPDFファイル」です。

![](https://image.brain-market.com/store/83728efed798c521e57b50d6639d110c.png)

「ショート動画台本アーカイブ」として読み込ませていたPDFファイルの参照。どうやら、このドキュメントの内容をプロンプト内で展開しようとすると、トークン数が溢れるのか、あるいはOpal側の読み込みエラーなのか、処理が止まってしまうようでした。

「こいつが悪いってことですよ」

つまり、Opal上で外部ドキュメントを動的に参照させるのは、現時点では不安定な場合があるということです。

原因が分かれば、対処は早いです。これを「仕様だから無理」と諦めるわけにはいきません。

僕は大胆な解決策を取りました。 「ドキュメントファイルを読み込ませるのをやめて、その中身（ノウハウ部分）をテキストとして直接プロンプトの中に書き込む」ことにしたのです。

「20代で2億円稼いだ」といった具体的な言い回しの例や、台本構成の黄金ルールを、外部ファイルに頼るのではなく、プロンプトという一つのテキストの中に「内包」させてしまうんです。

ファイル参照のリンク（@\[Doc\]）を削除し、代わりにその中身をコピペしてプロンプトの一部にしてしまいました。 「このプロンプトさえ読めば全ての情報が入っている」状態にしたわけです。

その結果…

![](https://image.brain-market.com/store/cbe51d9aeea2b97869b8662b2793129c.png)

成功しました！ エラー表示は消え、画面右側には綺麗に構成されたショート動画の台本が出力されました。

結局、外部ファイル参照がエラーのトリガーだったんですね。これはもうしょうがない。ツールの癖を見抜いて、運用でカバーするのが使い手の腕の見せ所です。

### 11-10. ワークフロー、ついに完成。

いくつものエラーを乗り越え、ついに安定して稼働するワークフローが完成しました。 最終的な構成は以下のようになりました。

1. **Input Node  
	**ユーザーからの音声データを受け取る。
2. **Transcribe Node  
	**受け取った音声をテキストに文字起こしする。
3. **Generate Node  
	**文字起こしされたテキストを入力とし、プロンプト内に直接書き込まれた「成功台本のノウハウ」を参照して、新しい台本を生成する。

非常にシンプルですが、余計な外部参照を削ぎ落とした分、これが一番確実で強力な構成です。

本来ならここからさらに「ブラッシュアップ用ノード」などを繋げて、生成された台本をさらに推敲させるステップを入れてもいいんですが、今回は基礎編ということで、まずはこのシンプルな形で運用していこうと思います。

### 11-11. 「@」をうまく活用しよう！

今回の検証を通じて、エラー解決の鍵となったのも、そして効率化の鍵となるのも、やはりOpalの「アットマーク（@）」機能の使い方でした。

先ほども少し触れましたが、この「@」からは、データの参照だけでなく、様々な外部ツールを呼び出すことができます。画面下部に出てくるメニューを見てみましょう。

**Web Search（ウェブサーチ）**

これを組み込めば、Google検索を行って最新情報を取得し、それを台本に反映させることができます。時事ネタを扱うショート動画なら必須ですね。

**Get Web Page**

特定のURLを指定して、そのWebページの中身を読み込ませることができます。参考にしたい記事がある場合に便利です。

**Google Maps / Weather**

地図情報や天気情報の取得もできます。旅行系の動画や、現地の天気に合わせたコンテンツを作るなら使えるかもしれません。

**Code Execution（コード実行）**

これは上級者向けですが、Pythonコードを実行させることができるのかも!?

例えば、複雑なデータ集計や計算をPythonで行い、その結果をワークフローに組み込む。そんな高度な自動化も、この「@」一つで可能になるんです。可能性を感じますよね。

画面右側のメニューからもツールを呼び出せますが、「@」で呼び出すショートカットを覚えておいたほうが圧倒的に作業が早いですし、思考を止めずに構築できます。

「Opalを使う＝@を使いこなす」と言っても過言ではありません。今回の動画で、これだけは絶対に覚えて帰ってください。確実に、作業効率が変わります。

### 11-12. 完成したノードをメインワークフローに組み込んでみる

テスト環境（サンドボックス）で成功したこの「ショート動画台本生成ノード」

これをテスト環境だけで終わらせてはもったいないです。

ノードを選択してコピーし、メインで使っているワークフロー（例えば、ポッドキャストの文字起こしやブログ作成を行っている既存のもの）を開きます。

![](https://image.brain-market.com/store/4f4293fcbfb8887a2024141a5ee8542e.png)

そこにペーストすると、先ほどの設定がそのまま引き継がれたノードが出現します。 あとは、入力元を繋ぎ変えるだけです。

今回は、ポッドキャストの文字起こしをしているノードの下に配置しました。 そして、プロンプト内の入力参照を「@\[User Input\]」から「@\[ポッドキャスト文字起こし\]」に書き換えます。

これで何ができるようになったか分かりますか？

僕はただポッドキャスト用の音声を一つアップロードするだけ。 それだけで、自動的にブログ記事用のテキストが生成されると同時に、その内容を要約し、再構成された「ショート動画用の台本」までもが自動で生成されるようになったんです。

一つの素材から、ブログとショート動画などが全自動で生まれる「最強のワークフロー」が爆誕しました。

### 11-13. エラーの対処法とブラッシュアップの方法

今回は、Google Opalを使ってショート動画台本を自動生成するノードの作り方を、綺麗事抜きのエラー解決プロセスも含めて、かなりディープにお見せしました。

> 「PDFが読み込めない」
> 
> 「音声から直接生成できない」

といったトラブルもありましたが、一つひとつ仮説を立てて検証し、結果的に

> 「プロンプトにノウハウを内包する」
> 
> 「文字起こしを挟む」

という解決策に辿り着きました。

この泥臭い検証こそが、AIを使いこなすための近道です。一発でうまくいかなくても、そこには必ず理由があります。それを解き明かす過程を楽しんでください。

そして、今回完成した、僕の過去の「伸びる台本」のナレッジが注入されたこのワークフロー。 実はこれ、完成版を皆さんにお渡ししたいなと思っています。

構造化されたプロンプトも入っていますし、もうこのまま使えるレベルに仕上がっていますからね。ぜひ使ってみてほしいです👇

![](https://image.brain-market.com/store/f644f3c94ee963cd6fb1c26dc04b745b.png)

[https://opal.google/?flow=drive:/1a0sGrbPTOVG9qGJ2ocMFAP6GFcEG\_fSS&shared&mode=app](https://opal.google/?flow=drive:/1a0sGrbPTOVG9qGJ2ocMFAP6GFcEG_fSS&shared&mode=app)

僕もこれから、このワークフローを使ってショート動画の方もガンガン攻めていきたいと思っています。 ここまで自動化できれば、あとは「何を話すか」というクリエイティブな部分に全力を注げますから。

今回の章では、

- **エラーが出た時の具体的な思考プロセスと対処法**
- **外部ファイル読み込みの注意点（PDFの罠）**
- **超重要な「@」を使った動的連携の使い方**

について、かなり詳しくお話ししてきました。 特にエラー対処の部分は、僕が普段どうやってAIと対話しながら検証しているのか、その裏側が見えたんじゃないかなと思います。

ぜひ、この振り返りを参考に、あなただけの最強ワークフローを組んでみてください。 そして、もし面白い使い方が見つかったら、ぜひ僕にも教えてください！

## 12\. 【最新版】Gemini 3 ProとNano Banana Proに対応したFujin式最強AIワークフローがやばすぎる

さて、この章では第7章でご紹介したワークフローのアップデート版、つまりGemini 3 ProとNano Banana Proに対応したワークフローについて解説していきます。

これによって何が変わったのか？

音声データ一本から、ブログ記事、そしてショート動画の台本だけでなく、**サムネイルまでも一撃で生み出すことができるようになります。**

まず僕がやったのは、ワークフロー内に存在する全てのテキスト生成ノードを、最新の「Gemini 3 Pro」に書き換えたのです。

音声の文字起こしテキストを受け取る最初のノードから、ブログ記事の本文を書くノード、タイトルを考えるノード、構成案を作るノード、そして後述する画像生成のためのプロンプトを作成するノードに至るまで。

一つ残らず、全てのモデル設定を「Gemini 3 Pro」に変更しました。

さらに、画像生成エンジンとして組み込んだのが「Nano Banana Pro」です。

![](https://image.brain-market.com/store/5f2a90cc674a046695ec13f637e7c6c5.png)

これまでの画像生成AIとは一線を画す、圧倒的な文脈理解能力と描写力を持ったこのモデルを、ワークフローの中に3つ並列で組み込みました。

「Gemini 3 Pro」×「Nano Banana Pro」

この現行最強のタッグを組ませることで、驚くほどスムーズに処理が流れ、かつ出力されるテキストや画像のクオリティも段違いに向上するはず。この「安定感」こそが、日々の運用を自動化する上では何よりも重要なスペックなんです。

![](https://img.youtube.com/vi/jtU7YVOIOI4/mqdefault.jpg)

**==▼テンプレートはここからどうぞ==**

[https://opal.google/?flow=drive:/1Bd8GEsH0BrvrR7exLzAEoqJrSHmiIpT6&shared&mode=app](https://opal.google/?flow=drive:/1Bd8GEsH0BrvrR7exLzAEoqJrSHmiIpT6&shared&mode=app)

### 12-1. ナレッジのアップデートもしてます

今回のアップデートでは、単にモデルを変えただけではありません。AIに「Fujinらしさ」を理解させるための「ナレッジ（知識データ）」の扱い方も大幅にブラッシュアップしました。

具体的には、過去のVoicy（ボイシー）の放送データをまとめたスプレッドシートやドキュメントを、知識データとしてAIに読み込ませています。

![](https://image.brain-market.com/store/bc6a616c8a925cda017401504372dc13.png)

このデータシートには、例えば5月から6月にかけて僕が話した内容が詳細に記録されています。

「Web3ゲームの未来」について熱く語った回や、「最新テックトレンド」について解説した回の文字起こしデータなどが蓄積されているわけです。

ここは最新版にアップデートした方がいいので、対応予定です。

これを今回のワークフローに「参考資料」として接続することで、AIは何ができるようになるのか？

それは、単に今回の音声を文字にするだけでなく、「Fujinという人間が普段どんな言葉選びをし、どんな視点で物事を語っているのか」という文脈を深く理解できるようになるんです。

### 12-2. クリック率を支配する「タイトル生成」のプロンプト革命

このナレッジベースの効果が最も顕著に表れるのが、「ブログタイトル生成」のパートです。

これまでは単純に「この内容を要約して、いい感じのタイトルをつけて」くらいの指示でした。

しかし今回は、プロンプトを以下のように徹底的に改良しました。

> **「この文字起こしデータを元に、ナレッジベースにある過去データのタイトル傾向を参考にしながら、リスナーが思わず再生ボタンを押したくなるような魅力的なタイトルを10個作成してください」**

ここで極めて重要なのが、**「SRTファイル（今回の字幕データ）以外は、全てナレッジとして読み込ませている」**という構成にしている点です。

![](https://image.brain-market.com/store/090e8389b5e15e6c632b0369b407c280.png)

つまり、AIは「今回の音声データ」という素材と、「過去の成功したタイトル事例」という秘伝のレシピの両方を持った状態で、最適なタイトルを料理してくれるわけです。

これにより、「AIっぽさ」が抜けない堅苦しいタイトルや、中身を説明しすぎるだけの退屈なタイトルではなく、人間味があり、フックの効いた、ついクリックしたくなるタイトルが生成されるようになりました。

### 12-3. サムネイル生成のコツ

さて、ここからが今回のハイライトであり、僕が最もこだわった部分です。

多くの人が自動化でやりがちなミスがあります。それは、「ブログのタイトルをそのまま画像生成AIのプロンプトとして投げてしまう」ことです。

でも、これだと絶対に良いサムネイルは作れません。

![](https://image.brain-market.com/store/f28aed4ef90e2e379d90578ce58c1dff.png)

なぜなら、「動画のタイトル」と「サムネイルに必要な文字情報」は、その役割が全く違うからです。

タイトルは検索対策（SEO）や、内容の正確な説明が求められます。

一方でサムネイルは、YouTubeのタイムラインなどで一瞬で視線を奪い、

「なんだこれ？」「気になる！」と思わせるインパクト

つまり「視覚的なフック」が必要です。タイトルと同じ文章が画像に書いてあっても、情報は重複するだけで効果は薄いんですね。

そこで僕は、タイトル生成と画像生成の間に、**「サムネイル専用のコピーライティングを行うノード」**を新たに追加しました。

### 12-4. 「プロのサムネイルデザイナー」につくってもらう

まず、Gemini 3 Proに対して、明確なペルソナ（役割）を与えます。

「あなたはYouTubeのプロのサムネイルデザイナーです。インプットされる動画のタイトルを元に、サムネイル画像に入れるべきワードの候補をいくつか出してください」

具体的には、以下の3つの要素を構造化して出力させます。

![](https://image.brain-market.com/store/ef3b1e4f67d1c442ab70a72620c09dd8.png)

1. メインコピー  
	視線を掴むための、短く強烈な大きな文字。
2. サブコピー  
	メインコピーを補足し、内容への興味を惹く文字。
3. キャッチコピー  
	クリックを誘うための煽り文句や、ベネフィットを伝える言葉。

この工程を挟むことで、「ブログタイトル完成」というノードから直接画像を作るのではなく、一度「サムネイル構成案」というクッションを挟むことができます。これによって、デザインとしての完成度が飛躍的に高まります。

### 12-5. 「Nano Banana Pro」による画像生成フローの全貌と運用ロジック

コピーライティングノードが完成したら、いよいよ「Nano Banana Pro」による画像生成です。

今回のワークフローでは、生成された3つのコピー案（案1、案2、案3）それぞれに対して、3つの画像生成ノードを並列で走らせる仕組みにしています。

**ここでプロンプトに必ず入れている、非常に重要な一文があります。**

それは、**「参照画像のようなデザインで」**という言葉です。

![](https://image.brain-market.com/store/d1303f1e56364cb617b609cce6ea32de.png)

単に「参考にして」と書くよりも、「〜のようなデザインで」と断定的に指示することで、AIは参照画像（僕が普段使っているサムネイルのデザインスタイル）へのリンク度合い、つまり再現性を強めてくれます。

これにより、AIが勝手にトンチンカンなデザインを作ってしまうリスクを抑え、僕のチャンネルの世界観に合った画像を生成させることができます。

さらに、人物の指定も重要です。

参照画像のデザインを引き継ぎつつも、被写体がブレないように、

「人物は日本人女性にしてください」

といった具体的な属性指定も忘れずに入れています。もちろん、ここは発信者のキャラクターに合わせて「日本人男性」でも「アメリカ人男性」でも、あるいは「ロボット」でも自由にカスタマイズ可能です。

### 12-6. 「3枚同時生成」システムでガチャを自動化する

画像生成AIを使っている方なら分かると思いますが、AIはどうしても「ガチャ要素」があります。

プロンプトが完璧でも、AIの機嫌次第で、指がおかしかったり、文字が崩れていたり、構図が微妙だったりすることがあります。一発で完璧な画像が出ることは稀です。

以前は、一枚出力しては「うーん、違うな」と思って再生成ボタンを押す…という作業を手動で繰り返していました。

しかし、これは自動化の理念に反します。

だからこそ、このワークフローでは「最初から3枚の画像を同時に生成する」ように組んでいます。

- 画像生成ノード01：コピー案1を使用（アスペクト比 16:9）
- 画像生成ノード02：コピー案2を使用（アスペクト比 16:9）
- 画像生成ノード03：コピー案3を使用（アスペクト比 16:9）

これらは全て同時に処理が走ります。

こうして出力された3枚があれば、確率論的にどれか1つは必ず「使える」クオリティのものが含まれています。

ワークフローが完了した時点で、フォルダには既に「選抜候補の3枚」が出来上がっている状態。

あとは、人間がその中から一番良いものを選ぶだけ。あるいは、YouTubeの機能を使って3枚をABテストにかけ、クリック率が一番高いものを探るという運用も可能です。

「選ぶだけ」の状態にする。これが時短の極意です。

**※Nano Banana Proが使えるようになったので、第13章に追記しました！（2025/12/20）**

### 12-7. ショート動画のジレンマ。映像どうする？

このワークフローは、ブログとサムネイルだけでは終わりません。

**同時に「ショート動画の台本」も生成しています。**

![](https://image.brain-market.com/store/becbc9dd64e8f25d3ad3aeea7e45d000.png)

ポッドキャストのような長い音声データ（10分〜20分）は、情報の宝庫です。ここから要点を抜き出し、切り口を変えれば、1分のショート動画なら余裕で3本分くらいのネタが作れます。

ワークフロー内では、音声データから要点を抽出し、TikTokやYouTubeショート向けに構成された台本を自動で書き起こすノードも稼働しています。

ただ、ここで一つ大きな課題にぶつかります。

「台本はできても、それに合わせる映像素材をどうするか問題」です。

YouTubeの長尺動画なら、このワークフローで作ったブログ記事の内容をスライド資料（PowerPointやGoogleスライド）に落とし込んで、それを画面に映しながら喋れば動画として成立します。僕が普段やっているスタイルですね。

しかし、TikTokやYouTubeショートのような縦型動画の世界では、静止画のスライド資料をただ流すだけというのは、あまり相性が良くありません。視聴者はもっと動きのある、視覚的にリッチでテンポの良い映像を求めているからです。

### 12-8. VEO 3などの動画生成AIの可能性とコストの壁

一つの解決策として、このワークフローの最後に「Generate Node」を追加し、「Veo 3」や「Veo 3.1」といった最新の動画生成AIを繋ぐ方法があります。

アスペクト比を「9:16（縦型）」に指定して、台本の内容に合わせた映像クリップを生成させるわけです。

技術的にはこれで解決可能です。Opal上でVeoを呼び出し、動画を生成することはできます。

しかし、現状では\*Daily Limitの壁があります。

高品質な動画生成AIは、1日の生成回数制限が厳しかったりします。ショート動画を量産するために、何回も動画生成AIを回すのは、現時点では少し現実的ではないかもしれません。

今のところの最適解は、

1. 台本まではAIで完全自動生成する。
2. 映像部分は、既存のフリー素材（Pexelsなど）を使うか、あるいは自分が喋っている映像を自撮りする。

というハイブリッドな運用になりそうです。もちろん、今後動画生成AIのコストが下がれば、ここも完全に自動化できる未来が待っています。

### 12-9. 入力素材は「独り言」で十分

![](https://image.brain-market.com/store/16837f1120cee092e9ad5ad2452386b6.png)

ここまで読んで、「すごいシステムだけど、そもそも元になるポッドキャストのデータなんて持ってないよ」と思った方もいるかもしれません。

**安心してください。このワークフローの入力データは、何でも大丈夫です。**

ブログ記事のテキストデータからスタートしてもいいですし、YouTubeの動画URLでもいい。

そして、僕が一番おすすめするのは「スマホのボイスメモ」です。

- 朝のニュースサイトを見ながら、気になった記事について感想をぶつぶつ呟く。
- 散歩中にふと思いついたアイデアを、忘れないように喋って録音する。
- 今日あった出来事や学びを、日記代わりに3分だけ話す。

こんな「独り言」レベルの音声データで十分なんです。

それをこのワークフローに放り込めば、Opalが勝手に文字起こしをし、文脈を整え、タイトルを付け、見出しを作り、サムネイルまで用意して、立派なコンテンツに仕立て上げてくれます。

最初はマイクに向かって喋ることに慣れが必要かもしれませんが、慣れてしまえばこれほど楽なことはありません。

台本なんて要らないんです。僕もポッドキャストは台本なしで、収録ボタンを押してからその場のノリと熱量だけで喋っていますから...w

「喋るだけ」でコンテンツができる。この快感を一度味わうと、もう手作業での執筆には戻れません。

### 12-10. X、Threads、そして図解生成もできるようにしたい

![](https://image.brain-market.com/store/1c949aaf122a8fb82fa7363bb8a1c436.png)

この「Opal」ワークフローは、これで完成ではありません。まだまだ進化の途中です。

今後は、生成されたコンテンツをさらに別のプラットフォームへ展開する仕組みを組み込んでいく予定です。

次は、音声データから「Threads（スレッズ）の投稿作成」を行うノードを追加します。

単純に同じ文章をXと同じマルチポストするのではなく、プラットフォームごとの「文化」に合わせたチューニングを行います。

- **X向け  
	**拡散性を意識した、短く、パンチが効いていて、箇条書きを活用したキャッチーな文章。
- **Threads向け  
	**Instagramの文化圏に合わせた、少し情緒的で、共感を呼ぶような柔らかい文章。

といった具合に、Gemini 3 Proにそれぞれのペルソナを与え、並列で投稿文を生成させるイメージです。

これが実装されれば、音声一つからブログ、動画、X、Threadsと、全方位にコンテンツを拡散できるようになります。来年にはここを完全に自動化して、SNS運用をさらに加速させたいと考えています。

さらに、「図解の生成」も視野に入れています。

ブログ記事の内容を要約し、それを視覚的にわかりやすい図解（インフォグラフィック）の構成案に落とし込み、画像生成AIで出力する。

ブログ記事から重要なポイントを3つ抽出し、それぞれの図解を作成するノードを派生させる。

これが実現すれば、

1. **音声データを入れる。**
2. **ブログ記事ができる。**
3. **サムネイルができる。**
4. **ショート動画台本ができる。**
5. **XとThreadsの投稿文ができる。**
6. **解説用の図解が3枚できる。**

これら全てが、ワンクリックで完了する世界がやってきます。

アウトプットの数は、たった一つの音声データから10個以上に膨れ上がるでしょう。

### 12-11. 自動化でクリエイティブを加速せよ

今回は、Gemini 3 ProとNano Banana Proを搭載した最新の「音声データからのコンテンツ生成ワークフロー」について、かなり詳細に解説しました。

![](https://image.brain-market.com/store/5b7a7996096d0c6312e7ff3adfc086c8.png)

Opalの画面で見ると、ノードが複雑に絡み合い、難しそうに見えるかもしれません。

しかし、やっていることの本質は非常にシンプルです。

**「面倒な単純作業や、AIが得意な変換作業は全てAIに任せ、人間は『何を話すか』『何を伝えるか』というコアなクリエイティブ部分に集中する」**

これに尽きます。

エラーが出ても怖がることはありません。プロンプトを修正し、ノードを繋ぎ直せばいいだけです。

そうやって試行錯誤しながら、自分だけの「最強の秘書」を育てていく過程こそが、AI時代のクリエイターの楽しみ方であり、醍醐味なんじゃないかなと思います。

今回のワークフローのテンプレートは、Gemini 3 Proが使えるようになったタイミングを見計らって、講座購入者限定のメールマガジン登録者限定で配布しようと思っています。

もし興味がある方は、ぜひメルマガに登録しておいてください。きっと、あなたのコンテンツ制作に革命が起きるはずです。

[https://my54p.com/p/r/S03uvz9a](https://my54p.com/p/r/S03uvz9a)

## 13\. 【革命】Opalワークフローを超簡単に組む方法

この章では、Opalワークフローを超簡単に組む方法について解説していきます。

これまでOpalのワークフローを組むのって、結構大変だったじゃないですか？ ノードを繋いだり、プロンプトを細かく調整したり…。 「便利そうだけど、自分にはちょっとハードルが高いな」と感じていた方も多いと思います。

でも、安心してください。 この章で紹介する方法を使えば、「**誰でも、一瞬で、超高度なワークフローを構築できる**」ようになります。

実は最近、OpalがGeminiの中に統合されたんですが、このアップデートと、今回僕が特典として配布する「**あるツール**」を組み合わせることで、とんでもないことが起きるんです。

「**え、こんなに簡単にできちゃっていいの？**」

そう思わずにはいられない、驚きの新機能と具体的な活用術について、ステップバイステップで徹底解説していきます。

今回の記事を読み終わる頃には、あなたも自分だけのオリジナルAIエージェントを爆速で作れるようになっているはずです。 ぜひ最後まで付いてきてください！

![](https://img.youtube.com/vi/9AvHOwgDwEo/mqdefault.jpg)

### 13-1. Opalのワークフロー設計、まだ手動でやってるの？

さて、本題に入る前に少しだけ状況を整理しておきましょう。

僕の講座でも解説してきましたが、Opalの魅力はなんといっても「**複雑なタスクを自動化できるワークフロー**」にあります。 ただ、これを作るのが結構骨の折れる作業でした。

実は僕も、このワークフロー設計の動画をたくさん撮り溜めていたんですが、Opalの進化スピードが速すぎて、編集が追いつかないくらいなんです...w

そこで今回は、初期リリース段階の締めくくりとして、「**最も効率的で、最も簡単なワークフローの組み方**」を皆さんだけにこっそり教えちゃいます。

使うのは、以下の2つだけ。

1. 今回僕が配布する「**Fujin式Opalワークフロー設計Gem**」
2. 新しくなった「**Gemini（Opal統合版）**」

この2つを組み合わせるだけで、プログラミング知識ゼロでも、複雑な処理を一瞬で自動化できるようになります。

### 13-2. 【特典】「Fujin式Opalワークフロー設計Gem」とは？

まず、今回の肝となるのが、僕が独自に開発した「**Fujin式Opalワークフロー設計Gem / GPT**」です。

![](https://image.brain-market.com/store/cedd291b3cf419af329800257020874e.png)

**▼****Fujin式Opalワークフロー設計Gem【Opal講座特典】**

[https://gemini.google.com/gem/1c7ovsoc41YB1ygjl1bQVnLQuhX3NNJsT?usp=sharing](https://gemini.google.com/gem/1c7ovsoc41YB1ygjl1bQVnLQuhX3NNJsT?usp=sharing)

![](https://image.brain-market.com/store/4bbfe6395624cfe800df7a62f0014de3.png)

**▼****Fujin式Opalワークフロー設計GPT【Opal講座特典】**

[https://chatgpt.com/g/g-69382ab06a3c819199cee73098f2e623-fujinshi-opalwakuhuroshe-ji-gpt-opaljiang-zuo-te-dian](https://chatgpt.com/g/g-69382ab06a3c819199cee73098f2e623-fujinshi-opalwakuhuroshe-ji-gpt-opaljiang-zuo-te-dian)

これは何かというと、「**作りたいワークフローのアイデアを投げるだけで、Opal用の完璧な設計図を一発で出力してくれるAI**」です。

僕がこれまで培ってきたプロンプトエンジニアリングのナレッジを、このGemの中にすべて詰め込みました。 いわば、僕の脳内にある「**ワークフロー設計のノウハウ**」をAIに移植したようなものです。

これを使うとどうなるか？ 百聞は一見にしかず、実際にやってみましょう。

**ステップ①作りたいものを「言葉」にする**

まず、この特典のGemにアクセスして、あなたが作りたいワークフローを言葉で伝えます。 今回は例として、こんなオーダーを出してみましょう。

![](https://image.brain-market.com/store/5340374df720bdd4e20f04139bea23b2.png)

「**ニュース記事から、バズる鋭い考察を考えてくれて、さらにポッドキャストのアイデアとか台本を出力してくれるようなワークフローを組んでほしい**」

これを入力して、送信ボタンをポチッと押すだけ。

**ステップ②AIが設計図を一瞬で構築**

すると、Gemがものすごい勢いで思考を開始します。

![](https://image.brain-market.com/store/b03e1092cfea2897226b7a612f886993.png)

- **1行要約**：ニュース記事から逆張りや深掘りの視点を抽出する
- **ターゲット**：テック系インフルエンサー、情報感度の高いビジネスパーソン
- **ユーザー入力**：ポッドキャストのターゲット、ペルソナ、トーン

こんな感じで、まずは概要をバシッと定義してくれます。さらにすごいのが、ここからです。

![](https://image.brain-market.com/store/0cc7d9cc2e4951ed31374eaa01634d48.png)

- **最小構成**：まずはGemini 2.5 Flashでテキストを抽出する
- **標準構成**：Gemini 2.5 Proを使って、切り口を3案ブレストする
- **拡張構成**：さらにGemini 3 Proモデルを使って、人間味のある台本を執筆する

このように、使うべきモデル（FlashやPro）の選定から、処理のステップまで、完璧な設計図を提案してくれるんです。 「**考察と執筆のプロセスは分けた方が品質が上がりますよ**」といった、プロレベルのアドバイスまで勝手にしてくれます 。

![](https://image.brain-market.com/store/f6956e362f6229565c8e924d1fab0c0b.png)

正直、これだけでも十分すごいんですが、ここからが本番です。

**ステップ③「魔法のテンプレート」を入手する**

Gemとの対話で「**あ、これいいな**」という構成が決まったら、こう伝えてください。

> 「**このまま使える入力テンプレートを出してください**」

すると、AIが謎のコードのようなテキストを出力します。 これが、「**魔法のテンプレート**」です。

![](https://image.brain-market.com/store/eaa36e13bdb68e01e7a292f592fba585.png)

実はOpal自体にも「**プロンプトからワークフローを作る機能**」はあるんですが、正直に言うと、精度がイマイチなんです 。 期待通りの動きをしてくれなかったり、微妙な挙動になったり…。

でも、この「**Fujin式Gem**」が出力するテンプレートは違います。 僕の方でブラッシュアップを重ねているので、これを次のステップで使うだけで、確実に動作する高品質なワークフローが作れるようになっています 。

このテンプレートをコピーしたら、いよいよGeminiの画面へ移動しましょう。

### 13-3. 【衝撃】Geminiの中に「Opal」がやってきた！

ここからは、最近アップデートされたGeminiの新機能を使っていきます。

※まだアップデートが反映されていない方もいるかもしれませんが、順次ロールアウトされているので、無料アカウントの方も含めて確認してみてください 。

![](https://image.brain-market.com/store/9535611ac9b78122b000268e707db21e.png)

Geminiの公式サイトにアクセスすると、メニューの中に「**Gem（ジェム）**」という項目が増えているはずです。 これ、今までのGemマネージャーとは別物なんです。 なんと、「**この中でOpalの機能が使えるようになっている**」んですよ 。

これ、地味にヤバい変化です。 今まで別々のツールだったものが、完全に統合されたってことですからね。

**ステップ④「New Gem」でペーストするだけ**

手順はめちゃくちゃ簡単です。

1. Geminiの画面にある「**New Gem**」というボタンをクリックします 。
2. チャット入力欄のような場所が出てくるので、そこに「**先ほどコピーした『魔法のテンプレート』をそのままペースト**」して送信してください 。

![](https://image.brain-market.com/store/23b45de9157dc738753697d99643d78e.png)

これだけ。 本当にこれだけです。

するとどうなるか？ 画面上でAIが自動的にプログラムを組み立て始め、一瞬にして「**ノードがつながった完璧なワークフロー図**」が表示されます 。

![](https://image.brain-market.com/store/d51cb87dd2d34d8062ddc15bcd690e3d.png)

すごくないですか？ いちいちパーツをドラッグ＆ドロップして、線を繋いで…なんて作業は一切不要。 ただ「**コピペ**」するだけで、複雑な処理を行うAIエージェントが完成してしまうんです。

あまりの簡単さに、僕も初めてやった時は声が出ましたw

エラーも出ず、確実に動作するワークフローが、たった数秒で手に入る時代になったんです 。

### 13-4. 日本語化と微調整のテクニック

ただし、一つだけ注意点があります。 生成されたワークフローの中身を見てみると、プロンプトや設定が「**英語**」になっていることが多いんです 。

![](https://image.brain-market.com/store/99d4dee50de3acfeb6be8e8881594911.png)

もちろんそのままでも動くんですが、やっぱり日本語で出力してほしいですよね。 そこで、少しだけ手直しをしていきます。

**ステップ⑤Advanced Editorで中身を覗く**

画面右上にある「**Open Advanced Editor**」というボタンをクリックしてください 。 すると、ワークフローの詳細設定画面（ノードエディタ）が開きます。

![](https://image.brain-market.com/store/173c1940ddeb8d3f7533f9d3d75fea7e.png)

ここで、各ノードの中身をいじれるんですが、やることはシンプルです。 「**出力（Output）を担当している最後のノード**」を探してください 。

その中にあるプロンプト（指示文）が英語になっているはずなので、ここを日本語に書き換えてあげればOKです。

「**英語を書き換えるのが面倒くさい…**」

そんな声が聞こえてきそうですが、ここでもAIを使いましょう！

僕の場合は「**日本語翻訳くん**」という自作のGemを使っています 。 英語のプロンプトをそのまま放り込んで「**日本語にして**」と頼むだけで、一瞬で翻訳してくれます 。

![](https://image.brain-market.com/store/ac05dee23b64b76e3c091bb729bff86b.png)

翻訳された日本語のプロンプトを、元の場所にコピペして上書き。 これで、日本語対応も完了です。

**==▼日本語ほんやくん==**

[https://gemini.google.com/gem/1HX7zFYIKFA6ZdtsMSUscHf\_YHOkpIBH1?usp=sharing](https://gemini.google.com/gem/1HX7zFYIKFA6ZdtsMSUscHf_YHOkpIBH1?usp=sharing)

**ステップ⑥モデル設定の落とし穴**

もう一つ、重要なチェックポイントがあります。 それは「**使用するAIモデル**」の選択です。

自動生成されたワークフローでは、デフォルトで「**Gemini 2.5 Flash**」が選択されていることが多いです 。 Flashモデルは爆速でコストも低いんですが、「**深い考察**」や「**クリエイティブな台本作成**」をさせたい場合は、少し物足りないことがあります。

![](https://image.brain-market.com/store/f54ce9b4b168c8f56684d17e4eeb7c5c.png)

なので、より高品質なアウトプットを求めるノードに関しては、手動で「**Gemini 2.5 Pro**」や「**Gemini 3.0 Pro**」などに切り替えておくことをおすすめします 。 この「**ひと手間**」を加えるだけで、最終的なクオリティが段違いになりますよ。

### 13-5. いざ実践！AIエージェントを動かしてみる

さあ、これで準備は整いました。 実際にこのワークフローを動かしてみましょう。

画面上の「**Start**」ボタンを押すと、URLの入力欄が出てきます 。 今回はテストとして、ロイター通信のニュース記事（OpenAIとGoogleのインフラ構築に関する記事）のURLを入れてみます 。

![](https://image.brain-market.com/store/aea39b964fd8c055f63c198e49760bfa.png)

ポチッとな。

すると… 画面上で各ノードが順番にピカピカと光りながら処理が進んでいきます。 Flashモデルを使っている箇所なんかは、本当に一瞬です。 「**HTMLを読み込み中…**」「**テキスト抽出中…**」「**考察生成中…**」

そして、あっという間に最終結果が出力されました！

### 13-6. 驚愕のアウトプット品質

出力された内容を見てみましょう。

![](https://image.brain-market.com/store/468d10bbb6b867dbe3186a9cbbd03eaf.png)

まず、AIが勝手に「**番組のホスト役**」を設定してくれています。

- **名前**：Dr. Evelyn "The Oracle" Vance
- **肩書き**：リードアナリスト兼フューチャリスト、デジタルドーンインスティチュート所属
- **ターゲット**：フリーランスのアニメーター、映像作家、コンセプトアーティスト
- **番組のトーン**：ハイオクタン（超エネルギッシュ）、少し熱狂的

…なんかすごいキャラが出てきましたねw

「**ザ・オラクル（予言者）**」って、中二病心をくすぐるネーミングセンスも抜群です...w

そして、肝心の台本部分。 元記事の内容をただ要約するだけでなく、 「**この記事はクリエイターにとって何を意味するのか？**」 「**なぜ今、インフラ構築が重要なのか？**」 といった独自の考察（インサイト）がしっかりと盛り込まれています。

しかも、口調も指示通り「**人間味のある、熱量のある話し方**」になっています。

これ、僕がやったのは「**URLをコピペしただけ**」ですよ？ それだけで、ペルソナ設定から、深い考察、そして台本作成まで、すべてが自動で完了してしまったんです。

### 13-7. まとめ：今すぐ「作る側」に回ろう

いかがだったでしょうか。 OpalとGeminiの統合、そして「**Fujin式Gem**」の威力を感じていただけたでしょうか。

今回のポイントをまとめると、

1. 「**Fujin式Opalワークフロー設計Gem**」でアイデアを壁打ちする
2. 出力された「**テンプレート**」をコピーする
3. Geminiの「**New Gem**」にペーストする
4. 必要に応じて「**日本語化＆モデル変更**」をする

たったこれだけのステップで、誰でもプロ級のAIエージェント開発者になれてしまうんです。

これまでは「**AIを使う側**」だったかもしれません。 でも、今日からは「**AIを組み合わせて、新しい価値を生み出す側（作る側）**」に回れるんです。 しかも、ノーコードで、遊び感覚で。

最初は僕が配布したGemを使って、簡単なものから試してみてください。 慣れてきたら、自分でゼロから設計してみるのも面白いでしょう。 複数のワークフローを連携させて、もっと巨大なシステムを作ることも可能です。

そして、もし面白いワークフローができたら、ぜひ「**X（旧Twitter）**」で教えてください！ 僕のアカウントをメンションして投稿してくれたら、必ず見に行きます！

メンション付きなら絶対に見つけます 。

良いアイデアや面白い使い方は、僕のリポストでどんどん拡散させていただきます。 みんなで知見を共有して、このAI革命の波を一緒に乗りこなしていきましょう！

## 14\. 【最新】Nano Banana Proでサムネイル一撃3枚生成ワークフロー

![](https://image.brain-market.com/store/f948cb18f2bed531ef831079b1c76ac6.png)

ついに、Opalに待望のアップデートが入りまして、画像生成AI「Nano Banana Pro（Gemini 3 Pro Image）」が、Opalのワークフローの中で使えるようになったんです。

これが何を意味するのか。

結論から言うと、 「高品質なYouTubeサムネイル作成の完全自動化」 が、誰でも、しかも一瞬でできるようになったということです。

今回は、僕が実際に組んだワークフローの実演を交えながら、この衝撃的なアップデートの全貌と、これからのクリエイティブ制作がどう変わっていくのかについて、じっくりと、そして熱く解説していきたいと思います。

クリエイターの方、業務効率化に興味がある方、そして何より「楽してすごい成果物を作りたい」と思っている方は、ぜひ最後までお付き合いください。

![](https://img.youtube.com/vi/HEKo1OzUVp4/mqdefault.jpg)

  

### 14-1. Nano Banana Pro（Gemini 3 Pro Image）の実力

今回主役となる「Nano Banana Pro」ですが、これはGemini 3 Pro Imageのことを指しています。

![](https://image.brain-market.com/store/52644800b65025f41bbb126829ca7c20.png)

このモデルの何がすごいかというと、 「日本語の理解力」と「文字入れの精度」 です。

従来の画像生成AIって、英語のプロンプトじゃないとうまく動かなかったり、画像の中に文字を入れようとすると謎の宇宙語になってしまったりすることが多かったじゃないですか。

でも、Nano Banana Proは違います。

日本語のニュアンスをしっかり汲み取ってくれる上に、サムネイルのような「デザインされた文字」を画像内に違和感なく配置することができるんです。

これがOpalの中で使えるようになった。

つまり、面倒なプロンプトエンジニアリングを何度も試行錯誤しなくても、ワークフローさえ組んでしまえば、誰でもプロ級のサムネイルを一撃で出力できる環境が整ったということです。

### 14-2. 【検証】最新ワークフローでサムネイル自動生成に挑む

それでは、実際に僕が構築したワークフローを使って、その威力を検証していきましょう。

今回やりたいことは非常にシンプルかつ強力です。

「動画のタイトルを入力するだけで、デザインの異なる高品質なサムネイルを3枚同時に生成する」

これを実現します。

### 14-3. ステップ①ワークフローの構築と調整

まずはOpalの画面でノード（処理の箱）を繋いでいきます。

ここで一つポイントなのが、現時点でのOpalの仕様です。

実は、最新の「Gemini 3 Pro」は、まだテキスト処理の連携部分で完全に対応しきれていない部分があります。

なので今回は、テキストの構成や指示出しを行う「頭脳」の部分には、安定している 「Gemini 2.5 Pro」 を採用しました。

![](https://image.brain-market.com/store/91c98c2c2b3b53dce7d400f5fbdf5127.png)

そして、その指示を受けて次に最新の 「Nano Banana Pro」 を配置します。

この「2.5 Pro」と「Nano Banana Pro」のハイブリッド構成こそが、現時点で最強の布陣です。

以前作成したワークフローをベースに、新しいノードを繋ぎ込んでいきます。

### 14-4. ステップ②タイトル入力から生成スタート

準備が整ったので、実際に生成してみましょう。

![](https://image.brain-market.com/store/505401172c45aa96bfe44097e1057bf4.png)

今回のお題となる動画タイトルは、最近僕が出した動画から持ってきました。

「神アプデ 最強ワークフローツールOpalがGeminiアプデ並みの中で使えるように」

このタイトルをインプット欄に入力して、スタートボタンを押します。

さあ、ここからOpalの魔法が始まります。

内部で行われている処理は以下の通りです。

1. サムネコピーの作成：  
	入力されたタイトルをGemini 2.5 Proが分析し、クリックしたくなるような「サムネイル用のキャッチコピー」を3パターン考えます。
2. Nano Banana Proによる描画：  
	生成された3つのパターンに従って、Nano Banana Proが同時に3枚の画像を生成します。

画面を見ていると、ものすごいスピードで処理が進んでいきます。

「コピー作成完了」の表示が出たと思ったら、すぐにNano Banana Proが走り出しました。

画像生成AIって、以前はもっと時間がかかるイメージでしたが、Opal上での動作は驚くほど軽快です。

しかも今回は1枚じゃありません。3枚同時生成です。

Nano Banana Proにはデイリーのリミット（生成枚数制限）があるはずですが、おそらく1日10枚〜数十枚程度はいけるんじゃないかと踏んでいます。

今回はテストで既に1枚作っているので、これで合計4枚目。

エラーが出ることなく、スムーズに進行しています。

### 14-5. ステップ③衝撃の結果確認

「あ、終わった」

本当に数十秒、長くても1分かからないくらいのスピードで完了しました。

出てきた成果物を見た瞬間、僕は思わず叫んでしまいました。

![](https://image.brain-market.com/store/0c14295693e54027e9bbaa6881b4a58b.png)

「うわっ！これやばくないですか、まじで」

画面に並んだ3枚のサムネイル。

これがもう、クオリティが高すぎるんです。

自動生成された画像には、しっかりと日本語で文字が入っています。

しかも、ただ文字が乗っているだけじゃなくて、ちゃんとデザインの一部として成立している。

中身を少し詳しく見てみましょう。

1枚目  
![](https://image.brain-market.com/store/42645e9f45011b4651f37e85adefd0bc.jpg)

2枚目  
![](https://image.brain-market.com/store/75dae01729a677c4c5af3b1915645849.jpg)

3枚目  
![](https://image.brain-market.com/store/9b49f8369e92972c91bb16e4abf50744.jpg)

HTML表示だと少しレイアウト崩れが見えましたが、マニュアルレイアウトモードで確認するとバッチリです。

何より素晴らしいのは、この生成された画像をそのままダウンロードできるという点。

![](https://image.brain-market.com/store/2c6ad3d3b398fa9cd5297e50ffa631a2.png)

ワークフローの最後にダウンロード用のノードを組み込んでいるので、気に入った画像があればワンクリックで自分のPCに保存できます。

Photoshopも、Canvaも開く必要がありません。

タイトルを入れたら、画像が出てくる。ダウンロードして、YouTubeにアップする。

本当にこれだけで完結してしまうんです。

### 14-6. YouTube運用を変える「サムネ3枚同時生成」の威力

「なんで3枚も同時に作る必要があるの？」と思った方もいるかもしれません。

実はこれ、YouTube運用においてめちゃくちゃ合理的な戦略なんです。

YouTubeには今、1つの動画に対して最大3枚までサムネイルを設定して、どれが一番クリックされるかをテストできる「A/Bテスト機能（テスト＆比較機能）」があります。

これまで、この機能を使うためには、デザイナーさんが3パターンのサムネイルを作る必要がありました。

![](https://image.brain-market.com/store/e0a366957b79da1fd34527df02840df3.png)

構成を変えて、色を変えて、文字を変えて…。

正直、1枚作るだけでも大変なのに、3枚なんてやってられないよ、という人が大半だったと思います。

でも、このOpalのワークフローを使えばどうでしょう。

手間は「タイトルを入れるだけ」で変わりません。

それだけで、テイストの違う3枚のサムネイルが勝手に出来上がるんです。

あとは全部ダウンロードして、YouTubeの管理画面に放り込んで、AIに勝負させればいい。

どのサムネイルが一番伸びるか、人間が悩む必要はもうありません。

数字で結果が出るのを待つだけです。

この 「迷う時間をゼロにして、データに基づいた運用を最小コストで実現する」 という点こそが、今回のワークフローの真の価値だと僕は思っています。

### 14-7. ワークフロー自体をコンテンツ化・資産化する

今回紹介したこの「最強サムネイル生成ワークフロー」ですが、あまりにも便利すぎるので、僕の「Opal講座」の特典として配布することにしました👇

[https://opal.google/?flow=drive:/1Z9IJs9NNg9YgdSDS7wIOUKzQUSvTVlj4&shared&mode=app](https://opal.google/?flow=drive:/1Z9IJs9NNg9YgdSDS7wIOUKzQUSvTVlj4&shared&mode=app) 

Opalの素晴らしいところは、作ったワークフローを簡単に共有できることです。

リンクをシェアすれば、他のユーザーも「Remix（リミックス）」という機能を使って、自分の環境にそのワークフローをコピーできます。

Remixボタンを押せば、中身のプロンプトを自分好みに書き換えたり、ノードを追加したりして、自由にカスタマイズが可能です。

例えば、僕のワークフローをベースにして、

> **「もっとポップな色使いにしたい」**
> 
> **「背景を実写風じゃなくてイラスト風にしたい」**

といった調整も、テキストの指示を少し変えるだけで簡単にできます。

さらに言えば、このサムネイル生成機能を、もっと大きなワークフローの一部として組み込むことだって可能です。

例えば、

1. 音声データを入力する
2. 内容を文字起こし・要約する
3. タイトルを自動生成する
4. **（ここに追加！）そのタイトルを使ってサムネイルを3枚生成する**
5. 概要欄のテキストを作成する

というように、動画制作の後工程をすべて全自動化する「スーパーワークフロー」を作ることだって夢じゃありません。  
自分の好きな機能、必要な機能をブロックのように組み合わせて、自分だけの最強ツールを育てていく。  
これこそがOpalを使う醍醐味であり、AI時代における「新しいクリエイティブの形」だと僕は思います。

## 15\. 【並列処理の限界】15体のAIエージェントによる「超並列ブレインストーミング」システム

さて、この章ではOpalの並列処理がどの程度までならいけるのか。

これについて深掘りしていきます。

![](https://img.youtube.com/vi/3xze5TW2z9I/mqdefault.jpg)

▼**15体のAIエージェントによる「超・並列ブレインストーミング」システム****ワークフローはこちら（※動作は重いです。気を付けてください。）**

[https://opal.google/?flow=drive:/1nmHhAx2acEcSEB-o0amMzD8d3sCZilzY&shared&mode=app](https://opal.google/?flow=drive:/1nmHhAx2acEcSEB-o0amMzD8d3sCZilzY&shared&mode=app)

今回僕が作成したワークフロー、一言で言うと **「15人のAIペルソナに同時に思考させて、議論させる」** というものです。

通常、ChatGPTやGeminiを使うときって、1対1の対話ですよね。 「これについて考えて」と投げて、AIが一つ答えを返す。

でも、今回の仕組みは違います。 一つのテーマに対して、 **「性格や専門性の異なる15人の人格（ペルソナ）」** をAIに生成させ、彼ら全員に同時並行で思考させるんです。

イメージとしては、15人の異なる専門家（マーケター、エンジニア、デザイナー、経営者など）を呼び集めて、「せーの」でアイデアを出してもらう感じですね。

これ、Googleの研究でも言われていることなんですが、AIに単一の思考をさせるよりも、複数の視点（マルチペルソナ）で議論させた方が、圧倒的にアウトプットの質が高まるというデータがあるんです。

それを、Opal上で、無理やり再現してみました。

### 15-1. 限界突破のワークフロー

実際にこのワークフローを組んでみたんですが、その構造がもう、タコの足みたいになっています...w

流れとしてはこんな感じです。

1. **ユーザーインプット**
	テーマを入力する（新しい商品のアイデアなど）
2. **ペルソナ生成**
	そのテーマに最適な15人の専門家ペルソナを生成する。
3. **並列思考（ラウンド1）**
	15人がそれぞれの視点で、テーマについて深く思考する。
4. **ファシリテーターによるまとめ**
	15人の意見を、別のファシリテーター役のAIが集約・整理する。
5. **再思考（ラウンド2）**
	まとめられた意見を見て、15人が「さらに」深く思考する。
6. **最終まとめ**
	プロジェクトマネージャー役のAIが、全ての議論を統合して結論を出す。

文字にするとシンプルに見えますが、これを実行するときの負荷がすごいんです。

実際に動かしてみたら、ブラウザの画面が一瞬真っ白になって、ノードが表示されなくなったり、チカチカ点滅したり…。

おそらく、ブラウザ上で並列処理できるAIエージェントの数は、現状だと10〜12人くらいが限界なのかもしれません。 僕は欲張って15人で組んでしまったので、完全に限界突破してましたね...w

でも、その負荷に耐えた先に出てくるアウトプットが、本当にすごかったんです。

### 15-2. 検証してみる

さて、この15人チームに今回はあえて超難問を用意しました。

テーマは、 **「ディズニーランドに対抗する、日本の大型テーマパークの構想」** です。

世界最強のエンタメ帝国、ディズニー。 これに勝てるアイデアなんて、普通に考えたら「無理でしょ」ってなりますよね。 人間が会議でブレストしても、「日本のアニメを集めよう」くらいのありきたりな案で終わってしまうことが多いと思います。

ここからは、実際に出てきたアウトプットの一部を紹介します。 これがですね、読みながら鳥肌が立つレベルでした。

**どんな出力が出てくるのか？**

まず、彼らが定義したコンセプトがこれです。 ディズニーが「完成された物語を提供するコンテンツプロバイダー」だとしたら、僕らは **「ゲスト一人ひとりが主役となる体験を創造するプラットフォーム（OS）」** を作るべきだと。

「テーマパーク」ではなく、「文化と経済圏のOS」を作る。 これが出てくるのすごくないですか？

ディズニーはマス（大衆）に向けた最高品質のエンタメですが、対抗策としてAIが出してきたのは **「究極のパーソナライズ」** でした。

- **リアルタイム・パーソナライゼーション**
	ゲストの行動や生体反応を予測・解析し、一人ひとりにとって「完璧な1日」を動的に生成する。
- **ダイナミック・ライド・プラットフォーム**
	乗る人によってストーリーや動きが変わるアトラクション。

もちろん、日本が誇るアニメやゲームといったIP（知的財産）を活用する案も出ました。 でも、単にキャラを置くだけじゃないんです。

**「IP水平連携プラットフォーム構想」** として、出版社やゲーム会社を巻き込み、パーク全体を「ジャパンカルチャーの聖地」にする。 さらに、メタバースライセンス事業で収益を安定させるという、ビジネスモデルまで提案してきました。

そして面白かったのが、**「魂の庭」** という概念。 熱狂的な祭り（フェス）のような空間と、静寂を感じられる日本庭園のような精神的な空間。 この「動と静」の両極端を体験できる深みこそが、ディズニーにはない魅力になるという分析です。

### 15-3. AIエージェントは「チーム」でこそ輝く

いかがだったでしょうか。 たった一つのプロンプトから、ここまで多角的で、かつ深みのある構想が一瞬で生成される。 これが **「マルチエージェント」** の威力です。

一人の天才AIに頼るのではなく、異なる視点を持つAI同士を対話させ、議論させる。 これって、まさに人間の組織やプロジェクトチームがやっていることそのものですよね。 それを、Opalで数分でシミュレーションできてしまう。

今回の章で重要なのは **「AIを単体で使うな、チームで使え」** という考え方です。

もしこれを、APIを自分で繋いでゼロから構築しようとしたら、そこそこAPI料金がかかります。

でも、Opalを使えば、誰でも簡単に「自分だけの最強ブレストチーム」を持つことができるわけです。

### 15-4. Opal並列処理の最大値

とはいえ、今回の15人並列処理は、正直おすすめしません...w

動画でも言いましたが、画面がチカチカして本当に見づらいですし、いつ止まってもおかしくない状態でした。

もし皆さんが試すなら、まずは5人〜10人くらいのペルソナから始めてみるのがいいと思います。 それでも、十分すぎるほどのクオリティのアウトプットが得られるはずです。

今回の章で言いたかったのは、こんな感じで様々な立場のAIを並列で考えさせて、その後意見をまとめるというのはかなり汎用性が高いんじゃないかということです。

とくに、API料金がかからずに構築できるOpalはこういったワークフローを組みやすいですからね！

これからは人間が考える前に、**「まずAIチームに議論させる」** というのが当たり前の手順になっていくでしょう。

その議論の結果を人間が見て、「お、この切り口面白いな」「ここはもっとこうしよう」と、最終的な意思決定を行う。 つまり、人間は **「プレイヤー」から「監督（ディレクター）」** になっていくわけです。

今回の実験で、その未来がもうすぐそこまで来ていることを確信しました。

Opalはこういった論文の再現のような実験もできるので、いろいろと試してみるといいと思います。

並列処理の限界、ぜひチャレンジしてみてください！w

## 16\. 【応用】悪魔的成約率「ニューロセールスレター」生成システム

特典の**Fujin式完全自動プロンプト設計GPT**を活用してどのようにワークフローを組んでいけばいいのかを解説しています！  

![](https://img.youtube.com/vi/L7bNJdB1IEs/mqdefault.jpg)

今後文字でも追記していきますね！

▼**悪魔的成約率「ニューロセールスレター」生成システム**

[https://opal.google/?flow=drive:/1FGbf6ZC2o-qHAJb4t37PqX2LmsGLwhMg&shared&mode=app](https://opal.google/?flow=drive:/1FGbf6ZC2o-qHAJb4t37PqX2LmsGLwhMg&shared&mode=app)

▼**Fujin式完全自動プロンプト設計GPT**

ChatGPT - Fujin式完全自動プロンプト設計GPT

作りたいGemやGPTのアイディアを入力してください。

https://chatgpt.com/g/g-693a6f0a6f248191b7f67599b8ae8dee-fujinshi-wan-quan-zi-dong-huronhutoshe-ji-gpt

![ChatGPT - Fujin式完全自動プロンプト設計GPT](https://chatgpt.com/backend-api/estuary/content?id=file-SuAPZNa5bpEytLF7tcE831&gizmo_id=g-693a6f0a6f248191b7f67599b8ae8dee&ts=490711&p=gpp&cid=1&sig=3919a6922315855cf25519b3aefc62879499ca4dc46a02cc99fc03909cba12c5&v=0)

## 17\. 「Opal一強時代」の到来

![](https://image.brain-market.com/store/5eaf7530eaefa620f7ec361da69474d0.png)

正直、今回の検証を通して感じたのは、 「もうツールはOpal一強だな」 ということです。

これまで、タスクごとに色々なAIツールを使い分けていた人も多いと思います。

文章ならChatGPTやClaude、画像ならMidjourneyやCanvaのAI機能、といった具合に。

でも、それらが全てOpalという一つのプラットフォーム上で、しかも高度に連携した状態で使えるようになってしまいました。

Nano Banana Proが入ってきたことで、画像生成のクオリティという最後の課題もクリアされました。

スマホ一つあれば、PCがなくても、移動中でも、カフェでも、ハイクオリティなコンテンツが生み出せる。

「超連携」「作業爆速化」「もうPCいらないレベル」

生成されたサムネイルに書かれていたコピーは、あながち大袈裟ではなく、これからの現実を言い当てていると思います。

実際、僕自身も今回のサムネイル生成を試してみて、「あ、これもう手放せないな」と確信しました。

気に入らなければ、もう一度ワークフローを走らせればいいだけ。

ストレスフリーで、かつ生産性が爆上がりする。

まさに「神ツール」と呼ぶにふさわしい進化を遂げました。

## 18\. 今後追加予定のコンテンツ

お疲れ様でした。本編はこちらでいったん終了です。

ですが、GoogleのAI周りの変化も激しいので、教材にはどんどん追記、アップデートをしていきます。

現時点で予定しているのは、

- n8nとの違い
- AIエージェントとワークフロー
- Fujin式AI駆動YouTubeチャンネル運用法

などなど、Opal講座の枠を超えて様々な情報を追記していきます。

アップデートしたらメールでお知らせしますので、購入者限定フォームから登録しておいてください！

[https://my54p.com/p/r/S03uvz9a](https://my54p.com/p/r/S03uvz9a)

特典も同時に届きます。  

## 19\. おわりに

さて、今回の講座動画講義で4時間近く、文字数にすると9万文字越えでしたが、いかがでしたでしょうか。

僕のノウハウをすべて余すところなく詰め込み、特典もモリモリにしました。

今後これだけ大盤振る舞いをすることはないかもしれません...w

というのをリリース日早朝4時に書いているFujnですが、Opalはマジで押さえておくべき自動化ツールです。

これを使いこなせるようになると、次はAIエージェントの構築や、完全自動化ワークフローの構築へと進んでいくことになります。

ワークフローやAIエージェントは、AIの進化とともに作りやすくなっていくとは思いますが、どこを自動化すべきなのかについてはあなたが向き合って考えなければいけません。

あなたの人生ですからね...！

だからこそ、今回はマインドセットの章を入れたわけです。

2026年はさらにAIが盛り上がっていくはずなので、僕もいろいろと準備をしています。

いっしょにAIの大波を楽しみながら乗りこなしていきましょう！

ここまで読んでくれたあなたはもうAI時代大丈夫です。

ぜひこの教材の感想などをXやこのBrainで書いてくださるとありがたいです！

些細なことかもしれませんが、作ってよかったとFujinが思えると思いますので、応援も兼ねて書いてくださるととてもうれしいです。

では、今回はこのへんで。

これからも一緒に歩んでがんばっていきましょう。

じゃあね！